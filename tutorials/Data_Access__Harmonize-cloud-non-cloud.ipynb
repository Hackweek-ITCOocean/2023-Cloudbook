{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmonizing data located within and outside of the NASA Earthdata Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing\n",
    "\n",
    "- Exercise: 30 min\n",
    "-\n",
    "-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial will combine several workflow steps and components from the previous days, demonstrating the process of using the geolocation of data available outside of the Earthdata Cloud to then access coincident variables of cloud-accessible data. This may be a common use case as NASA Earthdata continues to migrate to the cloud, producing a \"hybrid\" data archive across Amazon Web Services (AWS) and original on-premise data storage systems. Additionally, you may also want to combine field measurements with remote sensing data available on the Earthdata Cloud.\n",
    "\n",
    "This specific example explores the harmonization of the ICESat-2 ATL03 data product, currently (as of November 2021) available publicaly via direct download at the NSIDC DAAC, with Sea Surface Temperature variables available from PO.DAAC on the Earthdata Cloud. \n",
    "\n",
    "\n",
    "### Objectives\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# from requests.auth import HTTPBasicAuth\n",
    "\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import os\n",
    "from xml.etree import ElementTree as ET\n",
    "import time\n",
    "import zipfile\n",
    "import io\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine storage location of datasets of interest\n",
    "\n",
    "Find collections with data that is hosted in the cloud.\n",
    "The cloud_hosted parameter can be set to “true” or “false”. When true, the results will be restricted to collections that have a DirectDistributionInformation element or have been tagged with gov.nasa.earthdatacloud.s3.\n",
    "curl “https://cmr.earthdata.nasa.gov/search/collections?cloud_hosted=true”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare datasets of interest - TODO: Teach how to convert a short name to Collection ID\n",
    "\n",
    "# short name = SENTINEL-1A_DP_META_GRD_MEDIUM\n",
    "sentinel_id = 'C1214472336-ASF'\n",
    "\n",
    "# short name = ATL03\n",
    "icesat2_id = 'C1997321091-NSIDC_ECS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the Sentinel dataset, setting the `cloud_hosted` parameter to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'archive_center': 'ASF',\n",
      "  'boxes': ['-90 -180 90 180'],\n",
      "  'browse_flag': False,\n",
      "  'coordinate_system': 'CARTESIAN',\n",
      "  'data_center': 'ASF',\n",
      "  'dataset_id': 'SENTINEL-1A_DUAL_POL_METADATA_GRD_MEDIUM_RES',\n",
      "  'has_formats': False,\n",
      "  'has_spatial_subsetting': False,\n",
      "  'has_temporal_subsetting': False,\n",
      "  'has_transforms': False,\n",
      "  'has_variables': False,\n",
      "  'id': 'C1214472336-ASF',\n",
      "  'links': [{'href': 'https://vertex.daac.asf.alaska.edu/',\n",
      "             'hreflang': 'en-US',\n",
      "             'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'}],\n",
      "  'online_access_flag': True,\n",
      "  'orbit_parameters': {},\n",
      "  'organizations': ['ASF'],\n",
      "  'original_format': 'ECHO10',\n",
      "  'platforms': ['Sentinel-1A'],\n",
      "  'service_features': {'esi': {'has_formats': False,\n",
      "                               'has_spatial_subsetting': False,\n",
      "                               'has_temporal_subsetting': False,\n",
      "                               'has_transforms': False,\n",
      "                               'has_variables': False},\n",
      "                       'harmony': {'has_formats': False,\n",
      "                                   'has_spatial_subsetting': False,\n",
      "                                   'has_temporal_subsetting': False,\n",
      "                                   'has_transforms': False,\n",
      "                                   'has_variables': False},\n",
      "                       'opendap': {'has_formats': False,\n",
      "                                   'has_spatial_subsetting': False,\n",
      "                                   'has_temporal_subsetting': False,\n",
      "                                   'has_transforms': False,\n",
      "                                   'has_variables': False}},\n",
      "  'short_name': 'SENTINEL-1A_DP_META_GRD_MEDIUM',\n",
      "  'summary': 'Sentinel-1A Dual-pol ground projected medium resolution metadata',\n",
      "  'time_start': '2014-04-03T00:00:00.000Z',\n",
      "  'title': 'SENTINEL-1A_DUAL_POL_METADATA_GRD_MEDIUM_RES',\n",
      "  'updated': '2021-07-15T19:16:07.000Z',\n",
      "  'version_id': '1'}]\n"
     ]
    }
   ],
   "source": [
    "CMR_OPS = 'https://cmr.earthdata.nasa.gov/search'\n",
    "url = f'{CMR_OPS}/{\"collections\"}'\n",
    "\n",
    "response = requests.get(url, \n",
    "                        params={\n",
    "                            'concept_id': 'C1214472336-ASF',\n",
    "                            'cloud_hosted': 'True',\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "collections = response.json()['feed']['entry']\n",
    "pprint(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try ICESat-2, setting the `cloud_hosted` parameter to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'archive_center': 'NASA NSIDC DAAC',\n",
      "  'associations': {'services': ['S1568899363-NSIDC_ECS',\n",
      "                                'S1613689509-NSIDC_ECS',\n",
      "                                'S1977894169-NSIDC_ECS',\n",
      "                                'S2013502342-NSIDC_ECS'],\n",
      "                   'tools': ['TL1950215144-NSIDC_ECS',\n",
      "                             'TL1977971361-NSIDC_ECS',\n",
      "                             'TL1993837300-NSIDC_ECS',\n",
      "                             'TL1952642907-NSIDC_ECS']},\n",
      "  'boxes': ['-90 -180 90 180'],\n",
      "  'browse_flag': False,\n",
      "  'coordinate_system': 'CARTESIAN',\n",
      "  'data_center': 'NSIDC_ECS',\n",
      "  'dataset_id': 'ATLAS/ICESat-2 L2A Global Geolocated Photon Data V004',\n",
      "  'has_formats': True,\n",
      "  'has_spatial_subsetting': True,\n",
      "  'has_temporal_subsetting': True,\n",
      "  'has_transforms': False,\n",
      "  'has_variables': True,\n",
      "  'id': 'C1997321091-NSIDC_ECS',\n",
      "  'links': [{'href': 'https://n5eil01u.ecs.nsidc.org/ATLAS/ATL03.004/',\n",
      "             'hreflang': 'en-US',\n",
      "             'length': '0.0KB',\n",
      "             'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n",
      "            {'href': 'https://search.earthdata.nasa.gov/search/granules?p=C1997321091-NSIDC_ECS&pg[0][gsk]=-start_date&q=atl03%20v004&tl=1602518008!4!!&m=-9.278314769606354!-105.46875!1!1!0!0%2C2',\n",
      "             'hreflang': 'en-US',\n",
      "             'length': '0.0KB',\n",
      "             'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n",
      "            {'href': 'http://openaltimetry.org/',\n",
      "             'hreflang': 'en-US',\n",
      "             'length': '0.0KB',\n",
      "             'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n",
      "            {'href': 'https://nsidc.org/data/data-access-tool/ATL03/versions/4/',\n",
      "             'hreflang': 'en-US',\n",
      "             'length': '0.0KB',\n",
      "             'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n",
      "            {'href': 'https://doi.org/10.5067/ATLAS/ATL03.004',\n",
      "             'hreflang': 'en-US',\n",
      "             'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#'},\n",
      "            {'href': 'https://doi.org/10.5067/ATLAS/ATL03.004',\n",
      "             'hreflang': 'en-US',\n",
      "             'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'}],\n",
      "  'online_access_flag': True,\n",
      "  'orbit_parameters': {'inclination_angle': '92.0',\n",
      "                       'number_of_orbits': '0.071428571',\n",
      "                       'period': '96.8',\n",
      "                       'start_circular_latitude': '0.0',\n",
      "                       'swath_width': '36.0'},\n",
      "  'organizations': ['NASA NSIDC DAAC', 'NASA/GSFC/EOS/ESDIS'],\n",
      "  'original_format': 'ISO19115',\n",
      "  'platforms': ['ICESat-2'],\n",
      "  'processing_level_id': 'Level 2A',\n",
      "  'service_features': {'esi': {'has_formats': True,\n",
      "                               'has_spatial_subsetting': True,\n",
      "                               'has_temporal_subsetting': True,\n",
      "                               'has_transforms': False,\n",
      "                               'has_variables': True},\n",
      "                       'harmony': {'has_formats': False,\n",
      "                                   'has_spatial_subsetting': False,\n",
      "                                   'has_temporal_subsetting': False,\n",
      "                                   'has_transforms': False,\n",
      "                                   'has_variables': False},\n",
      "                       'opendap': {'has_formats': False,\n",
      "                                   'has_spatial_subsetting': False,\n",
      "                                   'has_temporal_subsetting': False,\n",
      "                                   'has_transforms': False,\n",
      "                                   'has_variables': False}},\n",
      "  'short_name': 'ATL03',\n",
      "  'summary': 'This data set (ATL03) contains height above the WGS 84 ellipsoid '\n",
      "             '(ITRF2014 reference frame), latitude, longitude, and time for '\n",
      "             'all photons downlinked by the Advanced Topographic Laser '\n",
      "             'Altimeter System (ATLAS) instrument on board the Ice, Cloud and '\n",
      "             'land Elevation Satellite-2 (ICESat-2) observatory. The ATL03 '\n",
      "             'product was designed to be a single source for all photon data '\n",
      "             'and ancillary information needed by higher-level ATLAS/ICESat-2 '\n",
      "             'products. As such, it also includes spacecraft and instrument '\n",
      "             'parameters and ancillary data not explicitly required for ATL03.',\n",
      "  'time_start': '2018-10-13T00:00:00.000Z',\n",
      "  'title': 'ATLAS/ICESat-2 L2A Global Geolocated Photon Data V004',\n",
      "  'version_id': '004'}]\n"
     ]
    }
   ],
   "source": [
    "CMR_OPS = 'https://cmr.earthdata.nasa.gov/search'\n",
    "url = f'{CMR_OPS}/{\"collections\"}'\n",
    "\n",
    "response = requests.get(url, \n",
    "                        params={\n",
    "                            'concept_id': 'C1997321091-NSIDC_ECS',\n",
    "#                            'cloud_hosted': 'True',\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "collections = response.json()['feed']['entry']\n",
    "pprint(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we comment out this parameter? Do we see results returned? \n",
    "[TODO: Add instructions on how to comment lines using command slash]\n",
    "\n",
    "Now we have determined that our Sentinel dataset is provided in the cloud, whereas the ICESat-2 dataset remains \"on premise\", residing in a local data center. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine size of ATL03 data over area of interest \n",
    "(determine large size; need to subset by geographic region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine time and area of interest \n",
    "\n",
    "These `bounding_box` and `temporal` variables will be used for data search, subset, and access below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding Box spatial parameter in decimal degree 'W,S,E,N' format. TODO: Show on a simple map??\n",
    "bounding_box = '-31.68073,61.21566,-12.15967,83.56771'\n",
    "\n",
    "# Each date in yyyy-MM-ddTHH:mm:ssZ format; date range in start,end format\n",
    "temporal = '2021-01-01T00:00:00Z,2021-01-31T23:59:59Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine size and number of granules\n",
    "\n",
    "# TODO: Need to pair down bounding box/time; we get 186 granules back in EDSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine subsetting capabilities of ATL03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Subset': {'SpatialSubset': {'BoundingBox': {'AllowMultipleValues': False},\n",
      "                              'Circle': {'AllowMultipleValues': False},\n",
      "                              'Point': {'AllowMultipleValues': False},\n",
      "                              'Polygon': {'AllowMultipleValues': False},\n",
      "                              'Shapefile': [{'Format': 'ESRI'},\n",
      "                                            {'Format': 'GeoJSON'},\n",
      "                                            {'Format': 'KML'}]},\n",
      "            'TemporalSubset': {'AllowMultipleValues': False},\n",
      "            'VariableSubset': {'AllowMultipleValues': False}},\n",
      " 'SupportedReformattings': [{'SupportedInputFormat': 'HDF5',\n",
      "                             'SupportedOutputFormats': ['ASCII',\n",
      "                                                        'HDF5',\n",
      "                                                        'NETCDF-3',\n",
      "                                                        'NETCDF-4']}]}\n"
     ]
    }
   ],
   "source": [
    "CMR_OPS = 'https://cmr.earthdata.nasa.gov/search'\n",
    "url = f'{CMR_OPS}/{\"collections\"}'\n",
    "\n",
    "response = requests.get(url, \n",
    "                        params={\n",
    "                            'concept_id': 'C1997321091-NSIDC_ECS',\n",
    "#                            'cloud_hosted': 'True',\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "response = response.json()\n",
    "services = response['feed']['entry'][0]['associations']['services']\n",
    "output_format = \"umm_json\"\n",
    "service_url = \"https://cmr.earthdata.nasa.gov/search/services\"\n",
    "for i in range(len(services)):\n",
    "    response = requests.get(f\"{service_url}.{output_format}?concept-id={services[i]}\")\n",
    "    response = response.json()\n",
    "    if 'ServiceOptions' in response['items'][0]['umm']: pprint(response['items'][0]['umm']['ServiceOptions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset and download ATL03 \n",
    "\n",
    "(Describe that this is being \"downloaded\" to our cloud environment - what does that mean in terms of cost, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://n5eil02u.ecs.nsidc.org/egi/request?short_name=ATL03&version=004&temporal=2021-01-01T00:00:00Z,2021-01-31T23:59:59Z&bounding_box=-31.68073,61.21566,-12.15967,83.56771&bbox=-31.68073,61.21566,-12.15967,83.56771&coverage=/gt1r/heights/h_ph,/gt1l/heights/h_ph,/gt2r/heights/h_ph,/gt2l/heights/h_ph,/gt1r/heights/lat_ph,/gt1l/heights/lat_ph,/gt2r/heights/lat_ph,/gt2l/heights/lat_ph,/gt1r/heights/lon_ph,/gt1l/heights/lon_ph,/gt2r/heights/lon_ph,/gt2l/heights/lon_ph&page_size=10&request_mode=async\n"
     ]
    }
   ],
   "source": [
    "#Set NSIDC data access base URL\n",
    "base_url = 'https://n5eil02u.ecs.nsidc.org/egi/request'\n",
    "\n",
    "# bounding box search and subset:\n",
    "param_dict = {'short_name': 'ATL03', \n",
    "              'version': '004', \n",
    "              'temporal': temporal, \n",
    "              'bounding_box': bounding_box, \n",
    "              'bbox': bounding_box, \n",
    "              'coverage': '/gt1r/heights/h_ph,/gt1l/heights/h_ph,/gt2r/heights/h_ph,/gt2l/heights/h_ph,/gt1r/heights/lat_ph,/gt1l/heights/lat_ph,/gt2r/heights/lat_ph,/gt2l/heights/lat_ph,/gt1r/heights/lon_ph,/gt1l/heights/lon_ph,/gt2r/heights/lon_ph,/gt2l/heights/lon_ph',\n",
    "              'page_size': '10', \n",
    "              'request_mode': 'async',\n",
    "#              'token' : _token,\n",
    "             }\n",
    "\n",
    "#Remove blank key-value-pairs\n",
    "param_dict = {k: v for k, v in param_dict.items() if v != ''}\n",
    "\n",
    "#Convert to string\n",
    "param_string = '&'.join(\"{!s}={!r}\".format(k,v) for (k,v) in param_dict.items())\n",
    "param_string = param_string.replace(\"'\",\"\")\n",
    "\n",
    "API_request = api_request = f'{base_url}?{param_string}'\n",
    "print(API_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Need to make code much simpler!!\n",
    "\n",
    "# Create an output folder if the folder does not already exist.\n",
    "\n",
    "path = str(os.getcwd() + '/Outputs')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "# For all requests other than spatial file upload, use get function\n",
    "session = requests.session()\n",
    "request = session.get(base_url, params=param_dict)\n",
    "\n",
    "print('Request HTTP response: ', request.status_code)\n",
    "\n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "request.raise_for_status()\n",
    "print('Order request URL: ', request.url)\n",
    "esir_root = ET.fromstring(request.content)\n",
    "print('Order request response XML content: ', request.content)\n",
    "\n",
    "#Look up order ID\n",
    "orderlist = []   \n",
    "for order in esir_root.findall(\"./order/\"):\n",
    "    orderlist.append(order.text)\n",
    "orderID = orderlist[0]\n",
    "print('order ID: ', orderID)\n",
    "\n",
    "#Create status URL\n",
    "statusURL = base_url + '/' + orderID\n",
    "print('status URL: ', statusURL)\n",
    "\n",
    "#Find order status\n",
    "request_response = session.get(statusURL)    \n",
    "print('HTTP response from order response URL: ', request_response.status_code)\n",
    "\n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "request_response.raise_for_status()\n",
    "request_root = ET.fromstring(request_response.content)\n",
    "statuslist = []\n",
    "for status in request_root.findall(\"./requestStatus/\"):\n",
    "    statuslist.append(status.text)\n",
    "status = statuslist[0]\n",
    "print('Data request is submitting...')\n",
    "print('Initial request status is ', status)\n",
    "\n",
    "#Continue loop while request is still processing\n",
    "while status == 'pending' or status == 'processing': \n",
    "    print('Status is not complete. Trying again.')\n",
    "    time.sleep(10)\n",
    "    loop_response = session.get(statusURL)\n",
    "\n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "    loop_response.raise_for_status()\n",
    "    loop_root = ET.fromstring(loop_response.content)\n",
    "\n",
    "#find status\n",
    "    statuslist = []\n",
    "    for status in loop_root.findall(\"./requestStatus/\"):\n",
    "        statuslist.append(status.text)\n",
    "    status = statuslist[0]\n",
    "    print('Retry request status is: ', status)\n",
    "    if status == 'pending' or status == 'processing':\n",
    "        continue\n",
    "\n",
    "#Order can either complete, complete_with_errors, or fail:\n",
    "# Provide complete_with_errors error message:\n",
    "if status == 'complete_with_errors' or status == 'failed':\n",
    "    messagelist = []\n",
    "    for message in loop_root.findall(\"./processInfo/\"):\n",
    "        messagelist.append(message.text)\n",
    "    print('error messages:')\n",
    "    pprint.pprint(messagelist)\n",
    "\n",
    "# Download zipped order if status is complete or complete_with_errors\n",
    "if status == 'complete' or status == 'complete_with_errors':\n",
    "    downloadURL = 'https://n5eil02u.ecs.nsidc.org/esir/' + orderID + '.zip'\n",
    "    print('Zip download URL: ', downloadURL)\n",
    "    print('Beginning download of zipped output...')\n",
    "    zip_response = session.get(downloadURL)\n",
    "    # Raise bad request: Loop will stop for bad response code.\n",
    "    zip_response.raise_for_status()\n",
    "    with zipfile.ZipFile(io.BytesIO(zip_response.content)) as z:\n",
    "        z.extractall(path)\n",
    "    print('Data request is complete.')\n",
    "else: print('Request failed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up Outputs folder by removing individual granule folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(path, topdown=False):\n",
    "    for file in files:\n",
    "        try:\n",
    "            shutil.move(os.path.join(root, file), path)\n",
    "        except OSError:\n",
    "            pass\n",
    "    for name in dirs:\n",
    "        os.rmdir(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine size of SAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMR_OPS = 'https://cmr.earthdata.nasa.gov/search'\n",
    "url = f'{CMR_OPS}/{\"granules\"}'\n",
    "\n",
    "response = requests.get(url, \n",
    "                        params={\n",
    "                            'concept_id': 'C1214472336-ASF',\n",
    "#                             'concept_id': 'C1997321091-NSIDC_ECS',\n",
    "                            'bounding_box': bounding_box,\n",
    "                            'temporal': temporal,\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "granules = response.json()['feed']['entry']\n",
    "#pprint(granules)\n",
    "\n",
    "results = json.loads(response.content)\n",
    "granules = []\n",
    "granules.extend(results['feed']['entry'])\n",
    "hits = int(response.headers['CMR-Hits'])\n",
    "print(f\"Found {hits} files\")\n",
    "granule_sizes = [float(granule['granule_size']) for granule in granules]\n",
    "print(f\"The total size of all files is {sum(granule_sizes):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine variables of interest: SST, ocean color, chemistry...\n",
    "\n",
    "Is this now no longer needed since it's just a single variable??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull those variables into xarray \"in place\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use geolocation of ICESat-2 to define the single transect used to pull coincident ocean data out from array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a plot of the single transect of gridded data \n",
    "\n",
    "(bonus: time series) - describe what this means to egress out of the cloud versus pulling the original data down (benefit to processing in the cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe an exercise that builds off of previous tutorials? Discover services or storage in CMR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
