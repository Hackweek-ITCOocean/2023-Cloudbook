{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmonizing data located within and outside of the NASA Earthdata Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing\n",
    "\n",
    "- Exercise: 45 min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial will combine several workflow steps and components from the previous days, demonstrating the process of using the geolocation of data available outside of the Earthdata Cloud to then access coincident variables of cloud-accessible data. This may be a common use case as NASA Earthdata continues to migrate to the cloud, producing a \"hybrid\" data archive across Amazon Web Services (AWS) and original on-premise data storage systems. Additionally, you may also want to combine field measurements with remote sensing data available on the Earthdata Cloud.\n",
    "\n",
    "This specific example explores the harmonization of the ICESat-2 ATL03 data product, currently (as of November 2021) available publicly via direct download at the NSIDC DAAC, with Sea Surface Temperature variables available from PO.DAAC on the Earthdata Cloud. \n",
    "\n",
    "\n",
    "### Objectives\n",
    "\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import netrc\n",
    "from pprint import pprint\n",
    "import os\n",
    "from pathlib import Path\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Determine storage location of datasets of interest\n",
    "\n",
    "First, let's see whether our datasets of interest reside in the Earthdata Cloud or whether they reside on premise, or \"on prem\" at a local data center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are building off of the CMR introductory tutorial, beginning with a collection search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmr_search_url = 'https://cmr.earthdata.nasa.gov/search'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to search by collection to inspect the access and service options that exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmr_collection_url = f'{cmr_search_url}/{\"collections\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the CMR introduction tutorial, we explored cloud-hosted collections from different DAAC providers, and identified the CMR concept-id for a given dataset id (also referred to as a short_name). Here we'll start with two datasets that we want to explore over a coincident area and time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_name = 'MODIS_A-JPL-L2P-v2019.0'\n",
    "icesat2_name = 'ATL03'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Like in the intro tutorial, we're going to first determine what concept-ids are returned for the MODIS dataset. First, retrieve collection results based on the MODIS `short_name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(cmr_collection_url, \n",
    "                        params={\n",
    "                            'short_name': modis_name,\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each collection result, print out the CMR concept-id and version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1940473819-POCLOUD version:2019.0\n",
      "C1693233348-PODAAC version:2019.0\n"
     ]
    }
   ],
   "source": [
    "collections = response['feed']['entry']\n",
    "\n",
    "for collection in collections:\n",
    "    print(f'{collection[\"id\"]} {\"version:\"}{collection[\"version_id\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two collections are returned, both at version 2019.0. We can see from the suffix of the id that one is associated with \"POCLOUD\" versus \"PODAAC\". That gives us a clue in terms of where the data are hosted, but we can also use the `cloud_hosted` parameter set to True to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(cmr_collection_url, \n",
    "                        params={\n",
    "                            'short_name': modis_name,\n",
    "                            'cloud_hosted': 'True',\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1940473819-POCLOUD version:2019.0\n"
     ]
    }
   ],
   "source": [
    "collections = response['feed']['entry']\n",
    "\n",
    "for collection in collections:\n",
    "    print(f'{collection[\"id\"]} {\"version:\"}{collection[\"version_id\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save this concept-id to use later on when we access the data granules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_concept_id = collections[0][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try our ICESat-2 dataset to see what id's are returned for a given dataset name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(cmr_collection_url, \n",
    "                        params={\n",
    "                            'short_name': icesat2_name,\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1705401930-NSIDC_ECS version:003\n",
      "C1997321091-NSIDC_ECS version:004\n"
     ]
    }
   ],
   "source": [
    "collections = response['feed']['entry']\n",
    "\n",
    "for collection in collections:\n",
    "    print(f'{collection[\"id\"]} {\"version:\"}{collection[\"version_id\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two separate datasets exist in the CMR, one at version 3 and one at version 4. Let's see if these are `cloud_hosted`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(cmr_collection_url, \n",
    "                        params={\n",
    "                            'short_name': icesat2_name,\n",
    "                            'cloud_hosted': 'False',\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1997321091-NSIDC_ECS version:004\n",
      "C1705401930-NSIDC_ECS version:003\n"
     ]
    }
   ],
   "source": [
    "collections = response['feed']['entry']\n",
    "\n",
    "for collection in collections:\n",
    "    print(f'{collection[\"id\"]} {\"version:\"}{collection[\"version_id\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When set to `False`, we get our collections back. We have now determined that we have a copy of the MODIS dataset in the cloud, whereas the ICESat-2 dataset (both versions) remains \"on premise\", residing in a local data center. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the ATL03 concept ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "icesat2_concept_id = collections[0][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Specify time range and area of interest \n",
    "\n",
    "We are going to focus on getting data for an area north of Greenland for a single day in June.\n",
    "\n",
    "These `bounding_box` and `temporal` variables will be used for data search, subset, and access below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding Box spatial parameter in decimal degree 'W,S,E,N' format.\n",
    "bounding_box = '-62.8,81.7,-56.4,83'\n",
    "\n",
    "# Each date in yyyy-MM-ddTHH:mm:ssZ format; date range in start,end format\n",
    "temporal = '2019-06-22T00:00:00Z,2019-06-22T23:59:59Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a granule search over our time and area of interest. How many granules are returned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "granule_url = f'{cmr_search_url}/{\"granules\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(granule_url, \n",
    "                        params={\n",
    "                            'concept_id': icesat2_concept_id,\n",
    "                            'temporal': temporal,\n",
    "                            'bounding_box': bounding_box,\n",
    "                            'page_size': 200,\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "print(response.headers['CMR-Hits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the file names, size, and links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL03_20190622061415_12980304_004_01.h5 1825.3746356964 https://n5eil01u.ecs.nsidc.org/DP9/ATLAS/ATL03.004/2019.06.22/ATL03_20190622061415_12980304_004_01.h5\n",
      "ATL03_20190622202251_13070304_004_01.h5 3035.5987443924 https://n5eil01u.ecs.nsidc.org/DP9/ATLAS/ATL03.004/2019.06.22/ATL03_20190622202251_13070304_004_01.h5\n"
     ]
    }
   ],
   "source": [
    "granules = response.json()['feed']['entry']\n",
    "\n",
    "for granule in granules:\n",
    "    print(f'{granule[\"producer_granule_id\"]} {granule[\"granule_size\"]} {granule[\"links\"][0][\"href\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download ICESat-2 ATL03 granule\n",
    "[TODO] Describe what services are available, including icepyx (provide references), but just direct download for simplicity. Describe that this is being \"downloaded\" to our cloud environment - what does that mean in terms of cost, etc.\n",
    "\n",
    "We've found 2 granules.  We'll download the first one and write it to a file with the same name as the `producer_granule_id`.\n",
    "\n",
    "We need the url for the granule as well.  This is `href` links we printed out above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "icesat_id = granules[0][\"producer_granule_id\"]\n",
    "icesat_url = granules[0]['links'][0]['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the granule data, we use the `requests.get()` method, which will utilize the .netrc file on the backend to authenticate the request against Earthdata Login.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(icesat_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response returned by requests has the same structure as all the other responses: a header and contents.  The header information has information about the response, including the size of the data we downloaded in bytes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: Wed, 10 Nov 2021 04:39:52 GMT\n",
      "Server: Apache\n",
      "Vary: User-Agent\n",
      "Content-Disposition: attachment\n",
      "Content-Length: 1914044034\n",
      "Keep-Alive: timeout=15, max=100\n",
      "Connection: Keep-Alive\n"
     ]
    }
   ],
   "source": [
    "for k, v in r.headers.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents needs to be saved to a file.  To keep the directory clean, we will create a `downloads` directory to store the file.  We can use a shell command to do this or use the `mkdir` method from the `os` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('downloads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a `downloads` directory in the file browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write the data to a file, we use `open` to open a file.  We need to specify that the file is open for writing by using the _write-mode_ `w`.  We also need to specify that we want to write bytes by setting the _binary-mode_ `b`.  This is important because the response contents are bytes.  The default mode for `open` is `text-mode`. So make sure you use `b`.\n",
    "\n",
    "We'll use the `with` statement _context-manager_ to open the file, write the contents of the response, and then close the file.  Once the data in `r.content` is written sucessfully to the file, or if there is an error, the file is closed by the _context-manager_.\n",
    "\n",
    "We also need to prepend the `downloads` path to the filename.  We do this using `Path` from the `pathlib` package in the standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = Path('downloads', icesat_id)\n",
    "with open(outfile, 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure it is downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1869184\n",
      "-rw-r--r-- 1 jovyan jovyan 1914044034 Nov 10 04:50 ATL03_20190622061415_12980304_004_01.h5\n"
     ]
    }
   ],
   "source": [
    "ls -l ./downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ATL03_20190622061415_12980304_004_01.h5` is an HDF5 file.  `xarray` can open this but you need to tell it which group to read the data from.  In this case we read the height data for ground-track 1 left-beam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy', 'rasterio', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttp://xarray.pydata.org/en/stable/getting-started-guide/installing.html\nhttp://xarray.pydata.org/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21/2626646783.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'downloads'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0micesat_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0micesat_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/gt1l/heights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, backend_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguess_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/plugins.py\u001b[0m in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    146\u001b[0m         )\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy', 'rasterio', 'zarr']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttp://xarray.pydata.org/en/stable/getting-started-guide/installing.html\nhttp://xarray.pydata.org/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "outfile = Path('downloads', icesat_id)\n",
    "ds = xr.open_dataset(icesat_id, group='/gt1l/heights')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine variables of interest: SST, ocean color, chemistry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sses_standard_deviation_4um'\n",
      "'l2p_flags'\n",
      "'time'\n",
      "'dt_analysis'\n",
      "'sses_standard_deviation'\n",
      "'sst_dtime'\n",
      "'sses_bias_4um'\n",
      "'lat'\n",
      "'sea_surface_temperature_4um'\n",
      "'sses_bias'\n",
      "'lon'\n",
      "'sea_surface_temperature'\n",
      "'quality_level'\n",
      "'wind_speed'\n",
      "'quality_level_4um'\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(cmr_collection_url, \n",
    "                        params={\n",
    "                            'concept_id': modis_concept_id,\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "response = response.json()\n",
    "variables = response['feed']['entry'][0]['associations']['variables']\n",
    "output_format = \"umm_json\"\n",
    "var_url = \"https://cmr.earthdata.nasa.gov/search/variables\"\n",
    "for i in range(len(variables)):\n",
    "    response = requests.get(f\"{var_url}.{output_format}?concept-id={variables[i]}\")\n",
    "    response = response.json()\n",
    "    # print(response['items'][0]['umm'])\n",
    "    if 'Name' in response['items'][0]['umm']: pprint(response['items'][0]['umm']['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull those variables into xarray \"in place\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we need to determine the granules returned from our time and area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(granule_url, \n",
    "                        params={\n",
    "                            'concept_id': 'C1940475563-POCLOUD',\n",
    "                            'temporal': temporal,\n",
    "                            'bounding_box': bounding_box,\n",
    "                            'page_size': 200,\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "print(response.status_code)\n",
    "print(response.headers['CMR-Hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['63.232 157.13 88.897 180', '63.232 -180 88.897 -49.902']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190622061001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc\n",
      "['68.267 -74.33 89.998 104.028']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-public/MODIS_T-JPL-L2P-v2019.0/20190622093001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc.md5\n",
      "['68.29 -100.13 89.998 79.455']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190622111001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc\n",
      "['65.983 -125.049 89.998 54.765']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190622125000-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc\n",
      "['64.671 -149.702 89.996 30.029']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190622142500-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc\n",
      "['63.327 -130.186 89.093 27.231']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190622143000-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc\n",
      "['67.198 -173.585 89.996 5.195']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190622160501-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc\n",
      "['60.312 -112.093 85.084 -9.865']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-public/MODIS_T-JPL-L2P-v2019.0/20190622161000-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc.md5\n",
      "['69.227 170.467 89.994 180', '69.227 -180 89.994 -27.697']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190622174501-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc\n",
      "['67.177 144.606 89.998 180', '67.177 -180 89.998 -53.628']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-public/MODIS_T-JPL-L2P-v2019.0/20190622192501-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc.md5\n",
      "['63.354 -65.91 89.07 91.026']\n",
      "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-public/MODIS_T-JPL-L2P-v2019.0/20190622210001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc.md5\n"
     ]
    }
   ],
   "source": [
    "modis_granules_meta = response.json()['feed']['entry']\n",
    "for granule_meta in modis_granules_meta:\n",
    "    print(granule_meta['boxes'])\n",
    "    print(granule_meta['links'][0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': ['63.232 157.13 88.897 180', '63.232 -180 88.897 -49.902'],\n",
       " 'time_start': '2019-06-22T06:10:01.000Z',\n",
       " 'updated': '2021-08-02T03:36:16.284Z',\n",
       " 'dataset_id': 'GHRSST Level 2P Global Sea Surface Skin Temperature from the Moderate Resolution Imaging Spectroradiometer (MODIS) on the NASA Terra satellite (GDS2)',\n",
       " 'data_center': 'POCLOUD',\n",
       " 'title': '20190622061001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0',\n",
       " 'coordinate_system': 'CARTESIAN',\n",
       " 'day_night_flag': 'UNSPECIFIED',\n",
       " 'time_end': '2019-06-22T06:14:59.000Z',\n",
       " 'id': 'G1956337241-POCLOUD',\n",
       " 'original_format': 'UMM_JSON',\n",
       " 'granule_size': '9.34600830078125E-5',\n",
       " 'browse_flag': False,\n",
       " 'collection_concept_id': 'C1940475563-POCLOUD',\n",
       " 'online_access_flag': True,\n",
       " 'links': [{'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "   'title': 'Download 20190622061001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190622061001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc'},\n",
       "  {'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n",
       "   'title': 'Download 20190622061001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc.md5',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-public/MODIS_T-JPL-L2P-v2019.0/20190622061001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc.md5'},\n",
       "  {'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n",
       "   'title': 'api endpoint to retrieve temporary credentials valid for same-region direct s3 access',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://archive.podaac.earthdata.nasa.gov/s3credentials'},\n",
       "  {'rel': 'http://esipfed.org/ns/fedsearch/1.1/service#',\n",
       "   'title': 'OPeNDAP request URL',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://opendap.earthdata.nasa.gov/collections/C1940475563-POCLOUD/granules/20190622061001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://podaac-tools.jpl.nasa.gov/drive/files/OceanTemperature/ghrsst/docs/GDS20r5.pdf'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://oceancolor.gsfc.nasa.gov/atbd/sst4/'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://oceancolor.gsfc.nasa.gov/reprocessing/r2019/sst/'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://oceancolor.gsfc.nasa.gov/atbd/sst/flag/'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://ghrsst.jpl.nasa.gov'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://modis.gsfc.nasa.gov/data/atbd/atbd_mod25.pdf'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://podaac.jpl.nasa.gov/forum/viewforum.php?f=18&sid=e2d67e5a01815fc6e39fcd2087ed8bc8'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://oceancolor.gsfc.nasa.gov/atbd/sst/'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://github.com/podaac/data-readers'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'http://www.ghrsst.org'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://podaac.jpl.nasa.gov/CitingPODAAC'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': ' https://cmr.earthdata.nasa.gov/virtual-directory/collections/C1940475563-POCLOUD'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://github.com/podaac/tutorials/blob/master/notebooks/MODIS_L2P_SST_DataCube.ipynb'},\n",
       "  {'inherited': True,\n",
       "   'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "   'hreflang': 'en-US',\n",
       "   'href': 'https://search.earthdata.nasa.gov/search/granules?p=C1940475563-POCLOUD'}]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modis_granules_meta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://podaac-ops-cumulus-protected/MODIS_T-JPL-L2P-v2019.0/20190622061001-JPL-L2P_GHRSST-SSTskin-MODIS_T-D-v02.0-fv01.0.nc'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "https_link = modis_granules_meta[0]['links'][0]['href']\n",
    "s3_link = https_link.replace('https://archive.podaac.earthdata.nasa.gov/','s3://')\n",
    "s3_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get S3 credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_credentials = requests.get('https://archive.podaac.earthdata.nasa.gov/s3credentials').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_fs = s3fs.S3FileSystem(\n",
    "    key=s3_credentials[\"accessKeyId\"],\n",
    "    secret=s3_credentials[\"secretAccessKey\"],\n",
    "    token=s3_credentials[\"sessionToken\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a s3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = s3_fs.open(s3_link)\n",
    "ds = xr.open_dataset(f, engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use geolocation of ICESat-2 to define the single transect used to pull coincident ocean data out from array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a plot of the single transect of gridded data \n",
    "\n",
    "(bonus: time series) - describe what this means to egress out of the cloud versus pulling the original data down (benefit to processing in the cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MODIS GHRSST data from Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_proj = ccrs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_geometry(boxs, t_crs=ccrs.NorthPolarStereo()):\n",
    "    '''Generates a shapely.geometry.box object from boxes metadata'''\n",
    "    lat_min, lon_min, lat_max, lon_max = [float(v) for v in bbox.split()]\n",
    "    x_min, y_min = t_crs.transform_point(lon_min, lat_min, ccrs.PlateCarree())\n",
    "    x_max, y_max = t_crs.transform_point(lon_max, lat_max, ccrs.PlateCarree())\n",
    "    return box(x_min, y_min, x_max, y_max)\n",
    "\n",
    "bbox_features = []\n",
    "for granule in modis_granules_meta:\n",
    "    for bbox in granule['boxes']:\n",
    "        bbox_features.append(bbox_geometry(bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(projection=ccrs.NorthPolarStereo())\n",
    "ax.set_extent([-180.,180.,60.,90.], ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.add_geometries([bbox_features[0]], crs=map_proj, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
