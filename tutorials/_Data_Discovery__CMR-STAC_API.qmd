---
jupyter: python3
---

# Data Discovery: CMR-STAC API

---

## Timing

- Exercise: 30 min

---

## Summary

In this example we will access the NASA's Harmonized Landsat Sentinel-2 (HLS) version 2 assets, which are archived in cloud optimized geoTIFF (COG) format in the LP DAAC Cumulus cloud space. The COGs can be used like any other geoTIFF file, but have some added features that make them more efficient within the cloud data access paradigm. These features include: overviews and internal tiling. Below we will demonstrate how to leverage these features.

### Objective

- Connect to NASA CMR-STAC API using Python's `pystac-client`
- Navigate CMR-STAC records
- Use the CMR-STAC API to search for data
- Perform post search filtering of CMR-STAC API search result
- Extract and save data access URLs for geospatial assets that we define with our geojson file using `geoviews`

### But first, what is STAC?  

[SpatioTemporal Asset Catalog (STAC)](https://stacspec.org/) is a specification that provides a common language for interpreting geospatial information in order to standardize indexing and discovering data.  

The [STAC specification](https://stacspec.org/core.html) is made up of a collection of related, yet independent specifications that when used together provide search and discovery capabilities for remove assets.

#### Four STAC Specifications  
                                                                                                                  
[STAC Item](https://github.com/radiantearth/stac-spec/blob/master/item-spec/item-spec.md) (aka Granule)  
[STAC Catalog](https://github.com/radiantearth/stac-spec/blob/master/catalog-spec/catalog-spec.md) (aka DAAC Archive)  
[STAC Collection](https://github.com/radiantearth/stac-spec/blob/master/collection-spec/collection-spec.md) (aka Data Product)  
[STAC API](https://github.com/radiantearth/stac-api-spec)  

In the following sections, we will explore each of STAC element using NASA's Common Metadata Repository (CMR) STAC application programming interface (API), or [CMR-STAC API](https://github.com/nasa/cmr-stac) for short.  

### CMR-STAC API  

The [CMR-STAC](https://github.com/nasa/cmr-stac) API is NASA's implementation of the STAC API specification for all NASA data holdings within EOSDIS. The current implementation does not allow for querries accross the entire NASA catalog. Users must execute searches within provider catalogs (e.g., LPCLOUD) to find the STAC Items they are searching for. All the providers can be found at the CMR-STAC endpoint here: <https://cmr.earthdata.nasa.gov/stac/>.  

In this exercise, we will query the **LPCLOUD** provider to identify STAC Items from the Harmonized Landsat Sentinel-2 (HLS) collection that fall within our region of interest (ROI) and within our specified time range. 

**Let's get started!**

---

## Import Required Packages

```{python}
from pystac_client import Client       # https://pystac-client.readthedocs.io/en/latest/index.html  
from collections import defaultdict    
import json
import geopandas
import geoviews as gv
from cartopy import crs
gv.extension('bokeh', 'matplotlib')
```

## Explored available NASA Providers  

```{python}
STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'
```

### Connect to the CMR-STAC API

```{python}
provider_cat = Client.open(STAC_URL)
```

```{python}
providers = [p for p in provider_cat.get_children()]

for count, provider in enumerate(providers):
    print(f'{count} - {provider.title}')
```

## Connect to the `LPCLOUD` Provider/STAC Catalog

For this next step we need the `provider title` (e.g., LPCLOUD) from above. We will add the provider to the end of the CMR-STAC API URL (i.e., `https://cmr.earthdata.nasa.gov/stac/`) to connect to the LPCLOUD STAC Catalog.

```{python}
catalog = Client.open(f'{STAC_URL}/LPCLOUD/')
```

## List STAC Collections

We'll create a `products` variable to view deeper in the STAC Catalog - subcategories are referred to as "children". 

```{python}
products = [c for c in catalog.get_children()]
```

### Print one of the STAC Collection records

To view the `products` variable we just created, let's look at one entry as a dictionary. 

```{python}
products[1].to_dict()
```

### Print the STAC Collection `id`s with their `title`

In the above output, `id` and `title` are two elements of interest that we can print for all `products` using a for loop. 

TODO: pystac/pystac-client objects

```{python}
for p in products: 
    print(f"{p.id}: {p.title}")
```

## Search for Granules/STAC Items - Set up query parameters to submit to the CMR-STAC API

We will define our region of interest (ROI) using the geojson file from the previous exercise, while also specifying the data collections and time range of needed for our example.

### Read in a geojson file

Reading in a geojson file with geopandas will return the geometry of our polygon (our ROI).

```{python}
field = geopandas.read_file('./data/ne_w_agfields.geojson')
field
```

### Visualize contents of geojson file

We can use that geometry to visualize the polygon: here, a square. But wait for it â€“

```{python}
fieldShape = field['geometry'][0]
fieldShape
```

We can plot the polygon using the `geoviews` package that we imported as `gv` with 'bokeh' and 'matplotlib' extensions. The following has reasonable width, height, color, and line widths to view our polygon when it is overlayed on a base tile map. 

```{python}
base = gv.tile_sources.EsriImagery.opts(width=650, height=500)
farmField = gv.Polygons(fieldShape).opts(line_color='yellow', line_width=10, color=None)
base * farmField
```

We will now start to specify the search criteria we are interested in, i.e, the **date range**, the **region of interest** (ROI), and the **data collections**, that we will pass to the STAC API.

### Extract the coordinates for the region of interest (ROI)

```{python}
roi = json.loads(field.to_json())['features'][0]['geometry']
roi
```

So, what just happen there? Let's take a quick detour to break it down.

|   |   |
|---|---|
|field.to_json() | geojson representation as a string|  
|json.loads()    | parse a json string into a Python Dictionary|
|features         | Dictionary key that contrains the geometry object with coordinates (returned as a list)|
|geometry        | Dictionary key that contains the coordinates for the ROI|

### Specify date range

Next up is to specify our date range using [ISO_8601 date formatting](https://en.wikipedia.org/wiki/ISO_8601). 

```{python}
#date_range = "2021-05-01T00:00:00Z/2021-08-30T23:59:59Z"    # closed interval
#date_range = "2021-05-01T00:00:00Z/.."                      # open interval - does not currently work with the CMR-STAC API
date_range = "2021-05/2021-08"
```

### Specify the STAC Collections

STAC Collection is synonomous with what we usually consider a NASA data product. Desired STAC Collections are submitted to the search API as a list containing the collection `id`. We can use the `id`s that we printed from our `products` for loop above. Let's focus on S30 and L30 collections. 

```{python}
collections = ['HLSL30.v1.5', 'HLSS30.v1.5']
collections
```

## Search the CMR-STAC API with our search criteria

Now we can put all our search criteria together using `catalog.search` from the `pystac_client` package.

```{python}
search = catalog.search(
    collections=collections,
    intersects=roi,
    datetime=date_range,
    limit=100
)
```


### Print out how many STAC Items match our search query

```{python}
search.matched()
```

We now have a search object containing the STAC Items that matched our query. Now, let's pull out all of the STAC Items (as a PySTAC ItemCollection object) and explore the contents (i.e., the STAC Items)

```{python}
#| tags: []
item_collection = search.get_all_items()
```

Let's list a few of these `item_collection`s:

```{python}
list(item_collection)[0:5]
```

### Print an item as a dictionary

We can view a single item as a dictionary, as we did above with `products`.

```{python}
item_collection[0].to_dict()
```

TODO Aaron: identify a few things of note 

## Filtering STAC Items

While the CMR-STAC API is a powerful search and discovery utility, it is still maturing and currently does not have the full gamut of filtering capabilities that the STAC API specification allows for. Hence, additional filtering is required if we want to filter by a property, for example cloud cover. Below we will loop through and filter the item_collection by a specified cloud cover as well as extract the band we'd need to do an Enhanced Vegetation Index (EVI) calculation for a future analysis.

We'll make a `cloudcover` variable where we will set the maximum allowable cloud cover and extract the band links for those Items that match or are less than the max cloud cover.

```{python}
cloudcover = 25
```

We will also specify the STAC Assets (i.e., bands/layers) of interest for both the S30 and L30 collections (also in our `collections` variable above).

*TODO Aaron*. We'll set these bands that are reasonable for EVI calculations: read more about B8A and friends here: TODO.

```{python}
s30_bands = ['B8A', 'B04', 'B02', 'Fmask']    # S30 bands for EVI calculation and quality filtering -> NIR, RED, BLUE, Quality 
l30_bands = ['B05', 'B04', 'B02', 'Fmask']    # L30 bands for EVI calculation and quality filtering -> NIR, RED, BLUE, Quality 
```

And now to loop through and filter the `item_collection` by cloud cover and bands:

```{python}
#| tags: []
evi_band_links = []

for i in item_collection:
    if i.properties['eo:cloud_cover'] <= cloudcover:
        if i.collection_id == 'HLSS30.v1.5':
            #print(i.properties['eo:cloud_cover'])
            evi_bands = s30_bands
        elif i.collection_id == 'HLSL30.v1.5':
            #print(i.properties['eo:cloud_cover'])
            evi_bands = l30_bands

        for a in i.assets:
            if any(b==a for b in evi_bands):
                evi_band_links.append(i.assets[a].href)
```

The filtering done in the previous steps produces a list of links to STAC Assets. Let's print out the first ten links.

```{python}
evi_band_links[:10]
```

**NOTICE** that in the list of links that we have multiple tiles, i.e. **T14TKL** & **T13TGF**, that intersect with our region of interest. TODO: We can notice this by HOW. 

These two tiles represent neighboring Universal Transverse Mercator (UTM) zones. We will split the list of links into separate lists for each tile. 

We now have a list of links to data assets that meet our search and filtering criteria. The commands that follow will split this list into logical groupings using python routines.

## Split Data Links List into Logical Groupings

TODO Aaron: a bit more description about what all these steps do :)

Split by UTM tile specified in the file name (e.g., T14TKL & T13TGF)

```{python}
tile_dicts = defaultdict(list)    # https://stackoverflow.com/questions/26367812/appending-to-list-in-python-dictionary
```

```{python}
for l in evi_band_links:
    tile = l.split('.')[-6]
    tile_dicts[tile].append(l)
```

### Print dictionary keys and values, i.e. the data links

```{python}
tile_dicts.keys()
```

```{python}
tile_dicts['T13TGF'][:5]
```

Now we will create a separate list of data links for each tile

```{python}
tile_links_T14TKL = tile_dicts['T14TKL']
tile_links_T13TGF = tile_dicts['T13TGF']
```

### Print band/layer links for HLS tile T13TGF

```{python}
# tile_links_T13TGF[:10]
```

### Split the links by band

```{python}
bands_dicts = defaultdict(list)
```

```{python}
for b in tile_links_T13TGF:
    band = b.split('.')[-2]
    bands_dicts[band].append(b)
```

```{python}
bands_dicts.keys()
```

```{python}
bands_dicts['B04']
```

## Save links to a text file

To complete this exercise, we will save the individual link lists as separate text files with descriptive names.

### Write links from CMR-STAC API to a file

```{python}
for k, v in bands_dicts.items():
    name = (f'HTTPS_T12TGF_{k}_Links.txt')
    with open(f'./data/{name}', 'w') as f:
        for l in v:
            f.write(f"{l}" + '\n')
```

### Write links to file for S3 access

```{python}
for k, v in bands_dicts.items():
    name = (f'S3_T12TGF_{k}_Links.txt')
    with open(f'./data/{name}', 'w') as f:
        for l in v:
            s3l = l.replace('https://data.lpdaac.earthdatacloud.nasa.gov/', 's3://')
            f.write(f"{s3l}" + '\n')
```

---

## Resources

- https://github.com/nasa/cmr-stac
- https://stacspec.org/
- https://stackoverflow.com/questions/26367812/appending-to-list-in-python-dictionary
- https://pystac-client.readthedocs.io/en/latest/index.html
- https://pystac.readthedocs.io/en/1.0/

