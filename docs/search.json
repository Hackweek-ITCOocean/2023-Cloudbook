[
  {
    "objectID": "cloud-paradigm.html",
    "href": "cloud-paradigm.html",
    "title": "Cloud Paradigm",
    "section": "",
    "text": "Slides that introduce NASA Earthdata Cloud & the Cloud Paradigm."
  },
  {
    "objectID": "further-resources.html",
    "href": "further-resources.html",
    "title": "Additional resources",
    "section": "",
    "text": "NASA Earthdata: How to Cloud\nUSGS Eyes on Earth Podcast: Satellites and Cloud Computing - with Aaron Friesz (LP DAAC!)\nPO.DAAC Cloud Data Page\nPO.DAAC Earthdata Webinar (Aug 2021): Surfing Ocean Data in the Cloud - The Beginner’s Guide to PO.DAAC in the NASA Earthdata Cloud\nPO.DAAC Github Repository\nNASA Earthdata Cloud Primer -AWS cloud primer: helpful tutorials for how to set up your own EC2 cloud instance in AWS, attach storeage, move files back and forth, and more.\nSetting up Jupyter Notebooks in a user EC2 instance in AWS - helpful blog post for setting up jupyter notebooks in an EC2 instance in AWS. (Builds on the Cloud Primer tutorials, which are missing that next step)\nRunning the NASA Cloud Workshop notebooks with mybinder.org - by Eli Holmes, 2021 Cloud Hackathon Participant who then set up working in Binder"
  },
  {
    "objectID": "further-resources.html#a-growing-list-of-resources",
    "href": "further-resources.html#a-growing-list-of-resources",
    "title": "Additional resources",
    "section": "",
    "text": "NASA Earthdata: How to Cloud\nUSGS Eyes on Earth Podcast: Satellites and Cloud Computing - with Aaron Friesz (LP DAAC!)\nPO.DAAC Cloud Data Page\nPO.DAAC Earthdata Webinar (Aug 2021): Surfing Ocean Data in the Cloud - The Beginner’s Guide to PO.DAAC in the NASA Earthdata Cloud\nPO.DAAC Github Repository\nNASA Earthdata Cloud Primer -AWS cloud primer: helpful tutorials for how to set up your own EC2 cloud instance in AWS, attach storeage, move files back and forth, and more.\nSetting up Jupyter Notebooks in a user EC2 instance in AWS - helpful blog post for setting up jupyter notebooks in an EC2 instance in AWS. (Builds on the Cloud Primer tutorials, which are missing that next step)\nRunning the NASA Cloud Workshop notebooks with mybinder.org - by Eli Holmes, 2021 Cloud Hackathon Participant who then set up working in Binder"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning based Species Distribution Modelling",
    "section": "",
    "text": "Welcome to the Sept 2023 training course on Machine Learning based Species Distribution Modelling hosted by the International Training Centre for Operational Oceanography (ITCOocean), ESSO-INCOIS, Hyderabad, India.\nThe course and hackweek will take place at the ITCOocean training centre in Hyderabad, India from September 11-22, 2023. The event is free to attend, but an application is required. Please see the course announcement for details on the course and application."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Machine Learning based Species Distribution Modelling",
    "section": "",
    "text": "Welcome to the Sept 2023 training course on Machine Learning based Species Distribution Modelling hosted by the International Training Centre for Operational Oceanography (ITCOocean), ESSO-INCOIS, Hyderabad, India.\nThe course and hackweek will take place at the ITCOocean training centre in Hyderabad, India from September 11-22, 2023. The event is free to attend, but an application is required. Please see the course announcement for details on the course and application."
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Machine Learning based Species Distribution Modelling",
    "section": "Overview",
    "text": "Overview\nThe the era of big data in the earth sciences is here and learning how to effectively use oceanographic remote-sensing data, both in the cloud and on your computer, is a core skill for modern fisheries science and management. Learning how to access cloud-based data, visualize these data, use these data in models, and use the tools of modern reproducible and collaborative science is the main goal of this course. Through the course, participants will gain experience with assessing remote-sensing data in the cloud, R and RStudio, and collaborating with Git and GitHub. Python users: Python is also very heavily used in big data geosciences. The course tutorials will focus on R, however you are welcome to use Python during the course if you are more comfortable with that.\n\nHackweek focus: species distribution modelling\nIn depth understanding of machine learning for species (macrofauna) distribution modelling (SDM) is needed by many young ecosystem researchers. SDMs are an important class of models used to understand species association with the environment. SDMs are widely used to understand how species distributions are changing with ocean climate change and are also used to estimate abundance over large ocean regions from fisheries survey data. This course is devised to familiarize the young professionals in the Indian Ocean-rim (IOR) countries with the latest developments in this field.\nThis course does not aim to teach ecology and habitat to the oceanographers/modellers/machine learning experts, rather it aims to teach machine learning and coding (and its relevance to fisheries) to fishery professionals."
  },
  {
    "objectID": "index.html#aims-and-objectives",
    "href": "index.html#aims-and-objectives",
    "title": "Machine Learning based Species Distribution Modelling",
    "section": "Aims and Objectives",
    "text": "Aims and Objectives\n\nLearn how to discover and use oceanographic remote-sensing data for species distribution modeling and other fisheries applications\nFamiliarize participants with using remote-sensing data in R within models. Note participants who are more familiar with Python are welcome to use Python also.\nIntroduce the participants to machine learning models used in species distribution modelling.\nObtain hands-on experience in using species distribution modelling and machine-learning with remote-sensing data.\nWork on a group project using species distribution modelling to estimate habitat associations or obtain a stock estimate using a species distribution model.\n\nNote, there are many ways that participants can study aspects of species distribution using remote-sensing data. During the hackweek portion of the course, participants will jointly develop project to work on and in order to learn by diving into a specific project. Species location will not be specifically required in order to engage in the projects.\n\nWhat is a hackweek?\nHackweeks are widely used in data science to teach new skills in an immersive peer-learning format. From the eScience Institute at the University of Washington, Seattle USA:\nA hackweek is a participant-driven workshop that blends data science education, community building, and project work over a short period of time (one to two weeks). The events are highly immersive and allow participants to work directly with data science professionals to co-shape projects and educational outcomes. Hackweeks often help individuals and teams engage more effectively in open and reproducible science. - eScience Institute, University of Washington\nExamples of recent hackweeks:\n\nNASA Cloud EarthData 2022:\n\nhttps://nasa-openscapes.github.io/2021-Cloud-Hackathon/\n\nOceanHackWeek 2022:\n\nhttps://oceanhackweek.org/ohw-resources/\n\nICESat-2 2022 eScience Institute, University of Washington:\n\nhttps://icesat-2-2022.hackweek.io/intro.html\n\n\n\n\nWhat to expect\n\nDuring the first week of the ITCOocean course, participants will work on learning how to access, visualize and manipulate remote-sensing data in R. Participants will develop familiarity with the R language, with RStudio, and with Git and GitHub for collaboration.\nThe course is an open science event: all tutorials and examples are developed openly and will be publicly available during and following the course. Participants will strengthen their practice of open science, using open source code and collaborating on their projects with course peers.\n\nIn the two to three weeks leading up to the course, participants are encouraged to review background resources that will facilitate a more effective experience.\n\n\nIndian Ocean and Bay of Bengal Data\nStudents will learn how to access remote-sensing data in the cloud (meaning on-line), but we have also prepared an “analysis ready” data set for students. This will be available on a shared drive and we will introduce the students to the techniques for accessing large datasets without loading them into memory.\n\n\nBounding box\n\nlatitude: -12deg to 32deg\nlongitude: 42deg to 102deg\ngrid: 0.25 deg\ncenters: 0, 0.25, 0.5., 0.75\n\n\n\nDatasets: ERA5\n\nu wind\nv wind\nwind speed\nwind direction\nair temperature @ 2m\nsea surface temperature\n\n\n\nCopernicus\n\nsea level anomaly\nchlorophyll concentration\n\n\n\nSRTM30_PLUS\n\nBathymetry\n\nReferences\n\nhttps://topex.ucsd.edu/WWW_html/srtm30_plus.html\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/usgsCeSrtm30v6.html\n\n\n\n1-km MUR SST\n\nsea surface temperature"
  },
  {
    "objectID": "index.html#code-of-conduct",
    "href": "index.html#code-of-conduct",
    "title": "Machine Learning based Species Distribution Modelling",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nThe 2023 ITCOocean Hackweek is a safe learning space and all participants are required to abide by our Code of Conduct."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Machine Learning based Species Distribution Modelling",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThank you to the open science community that has created software, teaching resources, and workflows that we have been able to build heavily from! These include:\n\nNASA Openscapes\nOceanHackWeek\nSnowEx Hackweek\neScience Institute, University of Washington\nICESat-2 Hackweek\n\nThis online book is made with quarto."
  },
  {
    "objectID": "logistics/index.html",
    "href": "logistics/index.html",
    "title": "Logistics overview",
    "section": "",
    "text": "Before the course, please do the following (20 minutes). All software is free. If you are attending the pre-clinic, please do this in advance.\n\nGitHub username Create a GitHub account (if you don’t already have one) at https://github.com.\n\nEarthdata Login account Create an Earthdata Login account (if you don’t already have one) at https://urs.earthdata.nasa.gov\nSlack Join our Slack workspace (invite sent via email).\nPre-course questionaire Complete the pre-course questionaire(link sent via email)."
  },
  {
    "objectID": "logistics/index.html#prerequisites",
    "href": "logistics/index.html#prerequisites",
    "title": "Logistics overview",
    "section": "",
    "text": "Before the course, please do the following (20 minutes). All software is free. If you are attending the pre-clinic, please do this in advance.\n\nGitHub username Create a GitHub account (if you don’t already have one) at https://github.com.\n\nEarthdata Login account Create an Earthdata Login account (if you don’t already have one) at https://urs.earthdata.nasa.gov\nSlack Join our Slack workspace (invite sent via email).\nPre-course questionaire Complete the pre-course questionaire(link sent via email)."
  },
  {
    "objectID": "logistics/index.html#slack",
    "href": "logistics/index.html#slack",
    "title": "Logistics overview",
    "section": "Slack",
    "text": "Slack\nYou will be invited to the Slack organization, where we have a number of private channels for the course. Slack will allow you to ask questions and get help from instructors and the fellow course participants.\n\nGitHub\nCourse GitHub org: https://github.com/Hackweek-ITCOocean\n\nParticipants will create their own private repos in this org.\n\nCourse book with tutorials: https://github.com/Hackweek-ITCOocean/2023-Cloudbook\n\nParticipants will clone the Cloudbook repo to get the tutorials on their local computer. They will need to make copies of tutorials in order to save work."
  },
  {
    "objectID": "logistics/schedule.html",
    "href": "logistics/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "11-22 September 11-22 2023"
  },
  {
    "objectID": "logistics/schedule.html#draft-schedule",
    "href": "logistics/schedule.html#draft-schedule",
    "title": "Schedule",
    "section": "Draft schedule",
    "text": "Draft schedule"
  },
  {
    "objectID": "logistics/schedule.html#pre-course-clinic-learn-basics-of-r",
    "href": "logistics/schedule.html#pre-course-clinic-learn-basics-of-r",
    "title": "Schedule",
    "section": "Pre-course clinic: learn basics of R",
    "text": "Pre-course clinic: learn basics of R\nIt is important that you come into the course with a basic understanding of R. There are many free courses.\n\nIf you have never used R or RStudio and have not done much programming, start with this 4 hour course: Basics of R and installing RStudio https://www.udemy.com/course/r-basics/\nIf you know the basics of R but have never done modeling, then you can start with this 2.5 hour course that covers basic linear regression with R and plotting with ggplot2: https://www.udemy.com/course/machlearn1\nFor a longer free course, you can do this one. Note this is 20 hours. You do NOT need to do this whole course before the hackweek! https://www.codecademy.com/learn/learn-r\nOne of the best free R courses is https://www.coursera.org/learn/r-programming. You can see the lectures for free. Make sure to click AUDIT when it asks you to sign up for a 7-day trial. You do not need to sign up for anything to go through the material."
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html",
    "href": "nasa-tutorials/00_Setup.html",
    "title": "00. Setup for tutorials",
    "section": "",
    "text": "This tutorial will help you set up your JupyterHub (or Hub) with tutorials and other materials from our Cloud Hackathon github repository and connect your github account."
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html#step-1.-login-to-the-hub",
    "href": "nasa-tutorials/00_Setup.html#step-1.-login-to-the-hub",
    "title": "00. Setup for tutorials",
    "section": "Step 1. Login to the Hub",
    "text": "Step 1. Login to the Hub\nPlease go to the Openscapes Jupyter Hub. Log in with your GitHub Account, and select “Small”.\n\n\nNote: It takes a few minutes for the Hub to load. Please be patient!\n\nWhile the Hub loads, we’ll:\n\nDiscuss cloud environments\nSee how my Desktop is setup\nFork the Hackathon repository at github.com\nDiscuss python and conda environments\n\nThen, when the Hub is loaded, we’ll get oriented in the Hub and clone the forked repository into our cloud environment."
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html#discussion-cloud-environment",
    "href": "nasa-tutorials/00_Setup.html#discussion-cloud-environment",
    "title": "00. Setup for tutorials",
    "section": "Discussion: Cloud environment",
    "text": "Discussion: Cloud environment\nA brief overview about the NASA Openscapes Cloud Environment (following lessons from the Clinic).\n\nCloud infrastructure\n\nCloud: AWS us-west-2\n\nData: AWS S3 (cloud) and NASA DAAC data centers (on-prem).\nCloud compute environment: 2i2c Jupyterhub deployment\n\nIDE: JupyterLab"
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html#discussion-my-desktop-setup",
    "href": "nasa-tutorials/00_Setup.html#discussion-my-desktop-setup",
    "title": "00. Setup for tutorials",
    "section": "Discussion: My desktop setup",
    "text": "Discussion: My desktop setup\nI’ll screenshare to show and/or talk through how I have oriented the following software we’re using:\n\n2i2c Jupyterhub (our main workspace)\nHackathon Repo &lt;&gt; Hackathon Book (my teaching notes, your reference material)\nZoom Chat\nSlack"
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html#step-2.-fork-the-hackathon-github-repository",
    "href": "nasa-tutorials/00_Setup.html#step-2.-fork-the-hackathon-github-repository",
    "title": "00. Setup for tutorials",
    "section": "Step 2. Fork the Hackathon GitHub repository",
    "text": "Step 2. Fork the Hackathon GitHub repository\n“How do I get the tutorial repository into the Hub?”. There are 2 steps. The first is from GitHub.com to fork the tutorial repository so that there is a connected copy in your user account that you can edit and push changes that won’t affect the nasa-openscapes copy.\nGo to https://github.com/nasa-openscapes/2021-Cloud-Hackathon and fork the repository.\n\nNote: if you’ve already done this in the Pre-Hackathon Clinic, you’ll need to make sure you have the latest, following the daily setup instructions."
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html#discussion-python-and-conda-environments",
    "href": "nasa-tutorials/00_Setup.html#discussion-python-and-conda-environments",
    "title": "00. Setup for tutorials",
    "section": "Discussion: Python and Conda environments",
    "text": "Discussion: Python and Conda environments\nWhy Python?\n\n\n\nPython Data Stack. Source: Jake VanderPlas, “The State of the Stack,” SciPy Keynote (SciPy 2015).\n\n\nDefault Python Environment:\nWe’ve set up the Python environment with conda.\n\n\n\n\n\n\nConda environment\n\n\n\n\n\nname: openscapes\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.9\n  - pangeo-notebook\n  - awscli~=1.20\n  - boto3~=1.19\n  - gdal~=3.3\n  - rioxarray~=0.8\n  - xarray~=0.19\n  - h5netcdf~=0.11\n  - netcdf4~=1.5\n  - h5py~=2.10\n  - geoviews~=1.9\n  - matplotlib-base~=3.4\n  - hvplot~=0.7\n  - pyproj~=3.2\n  - bqplot~=0.12\n  - geopandas~=0.10\n  - zarr~=2.10\n  - cartopy~=0.20\n  - shapely==1.7.1\n  - pyresample~=1.22\n  - joblib~=1.1\n  - pystac-client~=0.3\n  - s3fs~=2021.7\n  - ipyleaflet~=0.14\n  - sidecar~=0.5\n  - jupyterlab-geojson~=3.1\n  - jupyterlab-git\n  - jupyter-resource-usage\n  - ipympl~=0.6\n  - conda-lock~=0.12\n  - pooch~=1.5\n  - pip\n  - pip:\n    - tqdm\n    - harmony-py\n    - earthdata\n    - zarr-eosdis-store\n\n\n\n\nBash terminal and installed software\nLibraries that are available from the terminal\n\ngdal 3.3 commands ( gdalinfo, gdaltransform…)\nhdf5 commands ( h5dump, h5ls..)\nnetcdf4 commands (ncdump, ncinfo …)\njq (parsing json files or streams from curl)\ncurl (fetch resources from the web)\nawscli (AWS API client, to interact with AWS cloud services)\nvim (editor)\ntree ( directory tree)\nmore …\n\n\n\nUpdating the environment\nScientific Python is a vast space and we only included libraries that are needed in our tutorials. Our default environment can be updated to include any Python library that’s available on pip or conda.\nThe project used to create our default environment is called corn (as it can include many Python kernels).\nIf we want to update a library or install a whole new environment we need to open an issue on this repository. We can help your teams do this during project hacktime.\n\n\ncorn 🌽"
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html#step-3.-jupyterhub-orientation",
    "href": "nasa-tutorials/00_Setup.html#step-3.-jupyterhub-orientation",
    "title": "00. Setup for tutorials",
    "section": "Step 3. JupyterHub orientation",
    "text": "Step 3. JupyterHub orientation\nNow that the Hub is loaded, let’s get oriented.\n\n\n\n\n\n\nFirst impressions\n\nLauncher & the big blue button\n“home directory”"
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html#step-4.-clone-the-hackathon-github-repository",
    "href": "nasa-tutorials/00_Setup.html#step-4.-clone-the-hackathon-github-repository",
    "title": "00. Setup for tutorials",
    "section": "Step 4. Clone the Hackathon GitHub repository",
    "text": "Step 4. Clone the Hackathon GitHub repository\nNow we’ll clone the GitHub repository, using a git extension for the JupyterHub. Go to your github account, and navigate to the repository that you just created by forking from the Openscapes repository.\nClick to copy the url for cloning the repository.\n\nNow, go to JupyterHub and click on the git extension in the left panel and then click the blue button “Clone a Repository”.\n\nThen, paste the repository link to the forked repository that you copied from your github account into the “Clone a repo” pop up window. Then click the blue “CLONE” button. It will take a few moments to clone the repository into your Hub.\nYour link should look like https://github.com/YOUR-USERNAME/2021-Cloud-Hackathon. For example, the link is https://github.com/virdi/2021-Cloud-Hackathon. Note that it include your github username in the repo link.\n\nAlternatively, you can use the terminal (command line) as per github workflows: first-time setup.\nOnce the repository is cloned, you will see a new directory in the “File Browser” panel on the left named “2021-Cloud-Hackathon”. In this directory, you have all hackathon material including the tutorials and this book to follow along during other Tutorials. You are all set.\n\n\nREMEMBER: This is your copy (or fork) of the hackathon materials and jupyter notebooks. So feel free to make any changes to the content of this repository."
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html#jupyter-notebooks",
    "href": "nasa-tutorials/00_Setup.html#jupyter-notebooks",
    "title": "00. Setup for tutorials",
    "section": "Jupyter notebooks",
    "text": "Jupyter notebooks\nLet’s get oriented to Jupyter notebooks, which we’ll use in all the tutorials."
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html#how-do-i-end-my-session",
    "href": "nasa-tutorials/00_Setup.html#how-do-i-end-my-session",
    "title": "00. Setup for tutorials",
    "section": "How do I end my session?",
    "text": "How do I end my session?\n(Also see How do I end my Openscapes session? Will I lose all of my work?)\nWhen you are finished working for the day it is important to explicitly log out of your Openscapes session. The reason for this is it will save us a bit of money! When you keep a session active it uses up AWS resources and keeps a series of virtual machines deployed.\nStopping the server happens automatically when you log out, so navigate to “File -&gt; Log Out” and just click “Log Out”!\n!!! NOTE “logging out” - Logging out will NOT cause any of your work to be lost or deleted. It simply shuts down some resources. It would be equivalent to turning off your desktop computer at the end of the day."
  },
  {
    "objectID": "nasa-tutorials/00_Setup.html#step-5.-tracking-changes-optional",
    "href": "nasa-tutorials/00_Setup.html#step-5.-tracking-changes-optional",
    "title": "00. Setup for tutorials",
    "section": "Step 5. Tracking changes (Optional)",
    "text": "Step 5. Tracking changes (Optional)\nNow that you have forked and cloned the repository in your Hub, you can make changes (edit, add, and/or delete content) and track these files using git. In this step, we will provide an overview of how to use git using the graphical interface (the JupyterLab git extension).\n\nStep 5.1. Configure Git (git config)\nConfigure git with your name and email address as shown here.\ngit config --global user.name \"Makhan Virdi\"\ngit config --global user.email \"Makhan.Virdi@gmail.com\"\nOpen a new terminal: File &gt;&gt; New &gt;&gt; Terminal\n\nConfigure git to store your github credentials to avoid having to enter your github username and token each time you push changes to your repository(in Step 5.5, we will describe how to use github token instead of a password)\ngit config --global credential.helper store\n\n\nStep 5.2. Create a new file\nLet’s create a new file: In the left panel on your Hub, click on the “directory” icon and then double click on “2021-Cloud-Hackathon” directory. Then, create a new file using the text editor in your 2i2c JupyterHub (File &gt;&gt; New &gt;&gt; Text File). Add some text to this file, for example: A test file. Save this file and rename it to test.txt.\n\n\n\nStep 5.3. Track the changes to the new file (git add)\nClick the git icon in the left panel. You can see that the newly added file is in the “Untracked” section. You can click the + icon next to the file name to let git track this file for changes.\n\n\n\nStep 5.4. Commit the changes to the new file (git commit)\nNow, you will see that the file is Staged, which means that git is ready to take a snapshot of this file (and the repository) with the changes that you made. This snapshot is called a commit. To commit the changes, add a note (called a commit message) by typing in the text box that say “Summary”.\nNow, click the blue “COMMIT” button to commit this change.\n\nNote: A short message indicating the type of change to this file is a good practice. Optionally, a longer description may be added to the “Description” field.\n\n\n\n\nStep 5.5. Transmit committed changes to your github (git push)\nAt this stage, you have committed the changes to your git repository on your Hub. However, these changes are still on your Hub and needs to be transmitted to your repository on github (so that both the local copy on the JupyterHub and the remote copy on github are in sync).\nAs seen in the picture below, the git extension indicates (with an orange dot on the cloud icon) that it is ready to push your changes to the remote (remote = your repository on github.com). To push to github, click the cloud button with an up arrow (circled in red in the picture).\n\nWhen you push for the first time, it will ask that you input your credentials. You will need to set this up with your Personal Access Token (PAT), explained next.\n\n\nStep 5.6. Setup your Personal Access Token (PAT)\nWhen you see the following screenshot, GitHub is asking for you to input your credentials. (Note: you see this screenshot when you have committed work to push to GitHub.com, as detailed above).\n\nThe git extension in the Hub is prompting you to enter your github.com credentials. Enter you github.com username and a Personal Access Token (PAT); DO NOT use your password.\nTo create a PAT, visit https://github.com/settings/tokens/new and create a new token with the permission as per the image below and specify its validity for 90 days.\n\nIMPORTANT: You will see this token only once, so be sure to copy this. If you do not copy your token at this stage, you will need to generate a new token.\n\nOnce you generate the token, copy it and paste in the Hub window that prompted you to enter the “Personal Access Token”.\n\nGit will show a message at the bottom right telling that the changes were “Successfully pushed”. Also, you will see that the “cloud icon with an up arrow” no longer has an orange dot, indicating that there are no more committed changes to push to the remote (github.com).\n\nNote: You have configured git extension to store your credentials. You will not be prompted for your login/token again!\n\n\nThat’s all. You can use the same workflow (add &gt; commit &gt; push) for any other new or modified files!\n\n\nNote: If you are comfortable with the command line, you can use the Terminal (In Hub, New &gt; Terminal) and follow the steps outlined in the Clinic section."
  },
  {
    "objectID": "nasa-tutorials/index.html",
    "href": "nasa-tutorials/index.html",
    "title": "Tutorials Overview",
    "section": "",
    "text": "These tutorials are written in RMarkdown (R) and Jupyter Notebooks (Python)."
  },
  {
    "objectID": "nasa-tutorials/index.html#rmarkdown",
    "href": "nasa-tutorials/index.html#rmarkdown",
    "title": "Tutorials Overview",
    "section": "RMarkdown",
    "text": "RMarkdown\n\nOpen in RStudio\nRun code by clicking on the Run icon above a code chunk"
  },
  {
    "objectID": "nasa-tutorials/index.html#jupyter-notebook",
    "href": "nasa-tutorials/index.html#jupyter-notebook",
    "title": "Tutorials Overview",
    "section": "Jupyter Notebook",
    "text": "Jupyter Notebook\n\nOpen in Jupyter Notebook\nRun code by clicking on the code and clicking the little arrow at the top or by typing shift-return."
  },
  {
    "objectID": "notebooks/01_NASA_Earthdata_Authentication.html",
    "href": "notebooks/01_NASA_Earthdata_Authentication.html",
    "title": "04. Authentication for NASA Earthdata",
    "section": "",
    "text": "This notebook creates a hidden .netrc file (_netrc for Window OS) with Earthdata login credentials in your home directory. This file is needed to access NASA Earthdata assets from a scripting environment like Python.\n\n\nAn Earthdata Login account is required to access data, as well as discover restricted data, from the NASA Earthdata system. Thus, to access NASA data, you need Earthdata Login. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up.\n\n\n\nYou will need a netrc file containing your NASA Earthdata Login credentials in order to execute the notebooks. A netrc file can be created manually within text editor and saved to your home directory. An example of the required content is below.\nmachine urs.earthdata.nasa.gov\nlogin &lt;USERNAME&gt;\npassword &lt;PASSWORD&gt;\n&lt;USERNAME&gt; and &lt;PASSWORD&gt; would be replaced by your actual Earthdata Login username and password respectively."
  },
  {
    "objectID": "notebooks/01_NASA_Earthdata_Authentication.html#summary",
    "href": "notebooks/01_NASA_Earthdata_Authentication.html#summary",
    "title": "04. Authentication for NASA Earthdata",
    "section": "",
    "text": "This notebook creates a hidden .netrc file (_netrc for Window OS) with Earthdata login credentials in your home directory. This file is needed to access NASA Earthdata assets from a scripting environment like Python.\n\n\nAn Earthdata Login account is required to access data, as well as discover restricted data, from the NASA Earthdata system. Thus, to access NASA data, you need Earthdata Login. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up.\n\n\n\nYou will need a netrc file containing your NASA Earthdata Login credentials in order to execute the notebooks. A netrc file can be created manually within text editor and saved to your home directory. An example of the required content is below.\nmachine urs.earthdata.nasa.gov\nlogin &lt;USERNAME&gt;\npassword &lt;PASSWORD&gt;\n&lt;USERNAME&gt; and &lt;PASSWORD&gt; would be replaced by your actual Earthdata Login username and password respectively."
  },
  {
    "objectID": "notebooks/01_NASA_Earthdata_Authentication.html#import-required-packages",
    "href": "notebooks/01_NASA_Earthdata_Authentication.html#import-required-packages",
    "title": "04. Authentication for NASA Earthdata",
    "section": "Import Required Packages",
    "text": "Import Required Packages\n\nfrom netrc import netrc\nfrom subprocess import Popen\nfrom platform import system\nfrom getpass import getpass\nimport os\n\nThe code below will:\n\ncheck what operating system (OS) is being used to determine which netrc file to check for/create (.netrc or _netrc)\ncheck if you have an netrc file, and if so, varify if those credentials are for the Earthdata endpoint\ncreate a netrc file if a netrc file is not present.\n\n\nurs = 'urs.earthdata.nasa.gov'    # Earthdata URL endpoint for authentication\nprompts = ['Enter NASA Earthdata Login Username: ',\n           'Enter NASA Earthdata Login Password: ']\n\n# Determine the OS (Windows machines usually use an '_netrc' file)\nnetrc_name = \"_netrc\" if system()==\"Windows\" else \".netrc\"\n\n# Determine if netrc file exists, and if so, if it includes NASA Earthdata Login Credentials\ntry:\n    netrcDir = os.path.expanduser(f\"~/{netrc_name}\")\n    netrc(netrcDir).authenticators(urs)[0]\n\n# Below, create a netrc file and prompt user for NASA Earthdata Login Username and Password\nexcept FileNotFoundError:\n    homeDir = os.path.expanduser(\"~\")\n    Popen('touch {0}{2} | echo machine {1} &gt;&gt; {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n    Popen('echo login {} &gt;&gt; {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n    Popen('echo \\'password {} \\'&gt;&gt; {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)\n    # Set restrictive permissions\n    Popen('chmod 0600 {0}{1}'.format(homeDir + os.sep, netrc_name), shell=True)\n\n    # Determine OS and edit netrc file if it exists but is not set up for NASA Earthdata Login\nexcept TypeError:\n    homeDir = os.path.expanduser(\"~\")\n    Popen('echo machine {1} &gt;&gt; {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n    Popen('echo login {} &gt;&gt; {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n    Popen('echo \\'password {} \\'&gt;&gt; {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)\n\n\nSee if the file was created\nIf the file was created, we’ll see a .netrc file (_netrc for Window OS) in the list printed below. To view the contents from a Jupyter environment, click File on the top toolbar, select Open from Path…, type .netrc, and click Open. The .netrc file will open within the text editor.\n\n!!! Beware, your password will be visible if the .netrc file is opened in the text editor.\n\n\n!ls -al ~/"
  },
  {
    "objectID": "notebooks/03_Xarray.html",
    "href": "notebooks/03_Xarray.html",
    "title": "03. Introduction to xarray",
    "section": "",
    "text": "As Geoscientists, we often work with time series of data with two or more dimensions: a time series of calibrated, orthorectified satellite images; two-dimensional grids of surface air temperature from an atmospheric reanalysis; or three-dimensional (level, x, y) cubes of ocean salinity from an ocean model. These data are often provided in GeoTIFF, NetCDF or HDF format with rich and useful metadata that we want to retain, or even use in our analysis. Common analyses include calculating means, standard deviations and anomalies over time or one or more spatial dimensions (e.g. zonal means). Model output often includes multiple variables that you want to apply similar analyses to.\n\n\n\nA schematic of multi-dimensional data\n\n\nThe schematic above shows a typical data structure for multi-dimensional data. There are two data cubes, one for temperature and one for precipitation. Common coordinate variables, in this case latitude, longitude and time are associated with each variable. Each variable, including coordinate variables, will have a set of attributes: name, units, missing value, etc. The file containing the data may also have attributes: source of the data, model name coordinate reference system if the data are projected. Writing code using low-level packages such as netcdf4 and numpy to read the data, then perform analysis, and write the results to file is time consuming and prone to errors."
  },
  {
    "objectID": "notebooks/03_Xarray.html#why-do-we-need-xarray",
    "href": "notebooks/03_Xarray.html#why-do-we-need-xarray",
    "title": "03. Introduction to xarray",
    "section": "",
    "text": "As Geoscientists, we often work with time series of data with two or more dimensions: a time series of calibrated, orthorectified satellite images; two-dimensional grids of surface air temperature from an atmospheric reanalysis; or three-dimensional (level, x, y) cubes of ocean salinity from an ocean model. These data are often provided in GeoTIFF, NetCDF or HDF format with rich and useful metadata that we want to retain, or even use in our analysis. Common analyses include calculating means, standard deviations and anomalies over time or one or more spatial dimensions (e.g. zonal means). Model output often includes multiple variables that you want to apply similar analyses to.\n\n\n\nA schematic of multi-dimensional data\n\n\nThe schematic above shows a typical data structure for multi-dimensional data. There are two data cubes, one for temperature and one for precipitation. Common coordinate variables, in this case latitude, longitude and time are associated with each variable. Each variable, including coordinate variables, will have a set of attributes: name, units, missing value, etc. The file containing the data may also have attributes: source of the data, model name coordinate reference system if the data are projected. Writing code using low-level packages such as netcdf4 and numpy to read the data, then perform analysis, and write the results to file is time consuming and prone to errors."
  },
  {
    "objectID": "notebooks/03_Xarray.html#what-is-xarray",
    "href": "notebooks/03_Xarray.html#what-is-xarray",
    "title": "03. Introduction to xarray",
    "section": "What is xarray",
    "text": "What is xarray\nxarray is an open-source project and python package to work with labelled multi-dimensional arrays. It is leverages numpy, pandas, matplotlib and dask to build Dataset and DataArray objects with built-in methods to subset, analyze, interpolate, and plot multi-dimensional data. It makes working with multi-dimensional data cubes efficient and fun. It will change your life for the better. You’ll be more attractive, more interesting, and better equiped to take on lifes challenges."
  },
  {
    "objectID": "notebooks/03_Xarray.html#what-you-will-learn-from-this-tutorial",
    "href": "notebooks/03_Xarray.html#what-you-will-learn-from-this-tutorial",
    "title": "03. Introduction to xarray",
    "section": "What you will learn from this tutorial",
    "text": "What you will learn from this tutorial\nIn this tutorial you will learn how to:\n\nload a netcdf file into xarray\ninterrogate the Dataset and understand the difference between DataArray and Dataset\nsubset a Dataset\ncalculate annual and monthly mean fields\ncalculate a time series of zonal means\nplot these results\n\nAs always, we’ll start by importing xarray. We’ll follow convention by giving the module the shortname xr\n\nimport xarray as xr\nxr.set_options(keep_attrs=True)\n\nI’m going to use one of xarray’s tutorial datasets. In this case, air temperature from the NCEP reanalysis. I’ll assign the result of the open_dataset to ds. I may change this to access a dataset directly\n\nds = xr.tutorial.open_dataset(\"air_temperature\")\n\nAs we are in an interactive environment, we can just type ds to see what we have.\n\nds\n\nFirst thing to notice is that ds is an xarray.Dataset object. It has dimensions, lat, lon, and time. It also has coordinate variables with the same names as these dimensions. These coordinate variables are 1-dimensional. This is a NetCDF convention. The Dataset contains one data variable, air. This has dimensions (time, lat, lon).\nClicking on the document icon reveals attributes for each variable. Clicking on the disk icon reveals a representation of the data.\nEach of the data and coordinate variables can be accessed and examined using the variable name as a key.\n\nds.air\n\n\nds['air']\n\nThese are xarray.DataArray objects. This is the basic building block for xarray.\nVariables can also be accessed as attributes of ds.\n\nds.time\n\nA major difference between accessing a variable as an attribute versus using a key is that the attribute is read-only but the key method can be used to update the variable. For example, if I want to convert the units of air from Kelvin to degrees Celsius.\n\nds['air'] = ds.air - 273.15\n\nThis approach can also be used to add new variables\n\nds['air_kelvin'] = ds.air + 273.15\n\nIt is helpful to update attributes such as units, this saves time, confusion and mistakes, especially when you save the dataset.\n\nds['air'].attrs['units'] = 'degC'\n\n\nds"
  },
  {
    "objectID": "notebooks/03_Xarray.html#subsetting-and-indexing",
    "href": "notebooks/03_Xarray.html#subsetting-and-indexing",
    "title": "03. Introduction to xarray",
    "section": "Subsetting and Indexing",
    "text": "Subsetting and Indexing\nSubsetting and indexing methods depend on whether you are working with a Dataset or DataArray. A DataArray can be accessed using positional indexing just like a numpy array. To access the temperature field for the first time step, you do the following.\n\nds['air'][0,:,:]\n\nNote this returns a DataArray with coordinates but not attributes.\nHowever, the real power is being able to access variables using coordinate variables. I can get the same subset using the following. (It’s also more explicit about what is being selected and robust in case I modify the DataArray and expect the same output.)\n\nds['air'].sel(time='2013-01-01').time\n\n\nds.air.sel(time='2013-01-01')\n\nI can also do slices. I’ll extract temperatures for the state of Colorado. The bounding box for the state is [-109 E, -102 E, 37 N, 41 N].\nIn the code below, pay attention to both the order of the coordinates and the range of values. The first value of the lat coordinate variable is 41 N, the second value is 37 N. Unfortunately, xarray expects slices of coordinates to be in the same order as the coordinates. Note lon is 0 to 360 not -180 to 180, and I let python calculate it for me within the slice.\n\nds.air.sel(lat=slice(41.,37.), lon=slice(360-109,360-102))\n\nWhat if we want temperature for a point, for example Denver, CO (39.72510678889283 N, -104.98785545855408 E). xarray can handle this! If we just want data from the nearest grid point, we can use sel and specify the method as “nearest”.\n\ndenver_lat, denver_lon = 39.72510678889283, -104.98785545855408\n\n\nds.air.sel(lat=denver_lat, lon=360+denver_lon, method='nearest')\n\nIf we want to interpolate, we can use interp(). In this case I use linear or bilinear interpolation.\ninterp() can also be used to resample data to a new grid and even reproject data\n\nds.air.interp(lat=denver_lat, lon=360+denver_lon, method='linear')\n\nsel() and interp() can also be used on Dataset objects.\n\nds.sel(lat=slice(41.,37.), lon=slice(360-109,360-102))\n\n\nds.interp(lat=denver_lat, lon=360+denver_lon, method='linear')"
  },
  {
    "objectID": "notebooks/03_Xarray.html#analysis",
    "href": "notebooks/03_Xarray.html#analysis",
    "title": "03. Introduction to xarray",
    "section": "Analysis",
    "text": "Analysis\nAs a simple example, let’s try to calculate a mean field for the whole time range.\n\nds.mean(dim='time')\n\nWe can also calculate a zonal mean (averaging over longitude)\n\nds.mean(dim='lon')\n\nOther aggregation methods include min(), max(), std(), along with others.\n\nds.std(dim='time')\n\nThe data we have are in 6h timesteps. This can be resampled to daily or monthly. If you are familiar with pandas, xarray uses the same methods.\n\nds.resample(time='M').mean()\n\n\nds_mon = ds.resample(time='M').mean()\nds_mon\n\nThis is a really short time series but as an example, let’s calculate a monthly climatology (at least for 2 months). For this we can use groupby()\n\nds_clim = ds_mon.groupby(ds_mon.time.dt.month).mean()"
  },
  {
    "objectID": "notebooks/03_Xarray.html#plot-results",
    "href": "notebooks/03_Xarray.html#plot-results",
    "title": "03. Introduction to xarray",
    "section": "Plot results",
    "text": "Plot results\nFinally, let’s plot the results! This will plot the lat/lon axes of the original ds DataArray.\n\nds_clim.air.sel(month=10).plot()"
  },
  {
    "objectID": "notebooks/03_Xarray_hvplot.html",
    "href": "notebooks/03_Xarray_hvplot.html",
    "title": "03. Introduction to xarray",
    "section": "",
    "text": "As Geoscientists, we often work with time series of data with two or more dimensions: a time series of calibrated, orthorectified satellite images; two-dimensional grids of surface air temperature from an atmospheric reanalysis; or three-dimensional (level, x, y) cubes of ocean salinity from an ocean model. These data are often provided in GeoTIFF, NetCDF or HDF format with rich and useful metadata that we want to retain, or even use in our analysis. Common analyses include calculating means, standard deviations and anomalies over time or one or more spatial dimensions (e.g. zonal means). Model output often includes multiple variables that you want to apply similar analyses to.\n\n\n\nA schematic of multi-dimensional data\n\n\nThe schematic above shows a typical data structure for multi-dimensional data. There are two data cubes, one for temperature and one for precipitation. Common coordinate variables, in this case latitude, longitude and time are associated with each variable. Each variable, including coordinate variables, will have a set of attributes: name, units, missing value, etc. The file containing the data may also have attributes: source of the data, model name coordinate reference system if the data are projected. Writing code using low-level packages such as netcdf4 and numpy to read the data, then perform analysis, and write the results to file is time consuming and prone to errors."
  },
  {
    "objectID": "notebooks/03_Xarray_hvplot.html#why-do-we-need-xarray",
    "href": "notebooks/03_Xarray_hvplot.html#why-do-we-need-xarray",
    "title": "03. Introduction to xarray",
    "section": "",
    "text": "As Geoscientists, we often work with time series of data with two or more dimensions: a time series of calibrated, orthorectified satellite images; two-dimensional grids of surface air temperature from an atmospheric reanalysis; or three-dimensional (level, x, y) cubes of ocean salinity from an ocean model. These data are often provided in GeoTIFF, NetCDF or HDF format with rich and useful metadata that we want to retain, or even use in our analysis. Common analyses include calculating means, standard deviations and anomalies over time or one or more spatial dimensions (e.g. zonal means). Model output often includes multiple variables that you want to apply similar analyses to.\n\n\n\nA schematic of multi-dimensional data\n\n\nThe schematic above shows a typical data structure for multi-dimensional data. There are two data cubes, one for temperature and one for precipitation. Common coordinate variables, in this case latitude, longitude and time are associated with each variable. Each variable, including coordinate variables, will have a set of attributes: name, units, missing value, etc. The file containing the data may also have attributes: source of the data, model name coordinate reference system if the data are projected. Writing code using low-level packages such as netcdf4 and numpy to read the data, then perform analysis, and write the results to file is time consuming and prone to errors."
  },
  {
    "objectID": "notebooks/03_Xarray_hvplot.html#what-is-xarray",
    "href": "notebooks/03_Xarray_hvplot.html#what-is-xarray",
    "title": "03. Introduction to xarray",
    "section": "What is xarray",
    "text": "What is xarray\nxarray is an open-source project and python package to work with labelled multi-dimensional arrays. It is leverages numpy, pandas, matplotlib and dask to build Dataset and DataArray objects with built-in methods to subset, analyze, interpolate, and plot multi-dimensional data. It makes working with multi-dimensional data cubes efficient and fun. It will change your life for the better. You’ll be more attractive, more interesting, and better equiped to take on lifes challenges."
  },
  {
    "objectID": "notebooks/03_Xarray_hvplot.html#what-you-will-learn-from-this-tutorial",
    "href": "notebooks/03_Xarray_hvplot.html#what-you-will-learn-from-this-tutorial",
    "title": "03. Introduction to xarray",
    "section": "What you will learn from this tutorial",
    "text": "What you will learn from this tutorial\nIn this tutorial you will learn how to:\n\nload a netcdf file into xarray\ninterrogate the Dataset and understand the difference between DataArray and Dataset\nsubset a Dataset\ncalculate annual and monthly mean fields\ncalculate a time series of zonal means\nplot these results\n\nAs always, we’ll start by importing xarray. We’ll follow convention by giving the module the shortname xr\n\nimport xarray as xr\nxr.set_options(keep_attrs=True)\nimport hvplot.xarray\n\n\n\n\n\n\n\n\n\n\n\nI’m going to use one of xarray’s tutorial datasets. In this case, air temperature from the NCEP reanalysis. I’ll assign the result of the open_dataset to ds. I may change this to access a dataset directly\n\nds = xr.tutorial.open_dataset(\"air_temperature\")\n\nAs we are in an interactive environment, we can just type ds to see what we have.\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 2920, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nData variables:\n    air      (time, lat, lon) float32 ...\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...xarray.DatasetDimensions:lat: 25time: 2920lon: 53Coordinates: (3)lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (1)air(time, lat, lon)float32...long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ][3869000 values with dtype=float32]Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis\n(4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html\n\n\nFirst thing to notice is that ds is an xarray.Dataset object. It has dimensions, lat, lon, and time. It also has coordinate variables with the same names as these dimensions. These coordinate variables are 1-dimensional. This is a NetCDF convention. The Dataset contains one data variable, air. This has dimensions (time, lat, lon).\nClicking on the document icon reveals attributes for each variable. Clicking on the disk icon reveals a representation of the data.\nEach of the data and coordinate variables can be accessed and examined using the variable name as a key.\n\nds.air\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'air' (time: 2920, lat: 25, lon: 53)&gt;\n[3869000 values with dtype=float32]\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]xarray.DataArray'air'time: 2920lat: 25lon: 53...[3869000 values with dtype=float32]Coordinates: (3)lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')Attributes: (11)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]\n\n\n\nds['air']\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'air' (time: 2920, lat: 25, lon: 53)&gt;\n[3869000 values with dtype=float32]\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]xarray.DataArray'air'time: 2920lat: 25lon: 53...[3869000 values with dtype=float32]Coordinates: (3)lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')Attributes: (11)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]\n\n\nThese are xarray.DataArray objects. This is the basic building block for xarray.\nVariables can also be accessed as attributes of ds.\n\nds.time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 2920)&gt;\narray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    standard_name:  time\n    long_name:      Timexarray.DataArray'time'time: 29202013-01-01 2013-01-01T06:00:00 ... 2014-12-31T18:00:00array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')Attributes: (2)standard_name :timelong_name :Time\n\n\nA major difference between accessing a variable as an attribute versus using a key is that the attribute is read-only but the key method can be used to update the variable. For example, if I want to convert the units of air from Kelvin to degrees Celsius.\n\nds['air'] = ds.air - 273.15\n\nThis approach can also be used to add new variables\n\nds['air_kelvin'] = ds.air + 273.15\n\nIt is helpful to update attributes such as units, this saves time, confusion and mistakes, especially when you save the dataset.\n\nds['air'].attrs['units'] = 'degC'\n\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:     (lat: 25, time: 2920, lon: 53)\nCoordinates:\n  * lat         (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 22.5 20.0 17.5 15.0\n  * lon         (lon) float32 200.0 202.5 205.0 207.5 ... 325.0 327.5 330.0\n  * time        (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nData variables:\n    air         (time, lat, lon) float32 -31.95 -30.65 -29.65 ... 23.04 22.54\n    air_kelvin  (time, lat, lon) float32 241.2 242.5 243.5 ... 296.5 296.2 295.7\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...xarray.DatasetDimensions:lat: 25time: 2920lon: 53Coordinates: (3)lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (2)air(time, lat, lon)float32-31.95 -30.65 ... 23.04 22.54long_name :4xDaily Air temperature at sigma level 995units :degCprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]array([[[-31.949997, -30.649994, -29.649994, ..., -40.350006,\n         -37.649994, -34.550003],\n        [-29.350006, -28.649994, -28.449997, ..., -40.350006,\n         -37.850006, -33.850006],\n        [-23.149994, -23.350006, -24.259995, ..., -39.949997,\n         -36.759995, -31.449997],\n        ...,\n        [ 23.450012,  23.049988,  23.25    , ...,  22.25    ,\n          21.950012,  21.549988],\n        [ 22.75    ,  23.049988,  23.640015, ...,  22.75    ,\n          22.75    ,  22.049988],\n        [ 23.140015,  23.640015,  23.950012, ...,  23.75    ,\n          23.640015,  23.450012]],\n\n       [[-31.050003, -30.449997, -30.050003, ..., -41.149994,\n         -39.550003, -37.350006],\n        [-29.550003, -29.050003, -28.949997, ..., -42.149994,\n         -40.649994, -37.449997],\n        [-19.949997, -20.259995, -21.050003, ..., -42.350006,\n         -39.759995, -34.649994],\n...\n        [ 20.540009,  20.73999 ,  22.23999 , ...,  21.940002,\n          21.540009,  21.140015],\n        [ 23.140015,  24.040009,  24.440002, ...,  22.140015,\n          21.940002,  21.23999 ],\n        [ 24.640015,  25.23999 ,  25.339996, ...,  22.540009,\n          22.339996,  22.040009]],\n\n       [[-28.059998, -28.86    , -29.86    , ..., -31.460007,\n         -31.660004, -31.36    ],\n        [-23.259995, -23.86    , -24.759995, ..., -33.559998,\n         -32.86    , -31.460007],\n        [-10.160004, -10.959991, -11.76001 , ..., -33.259995,\n         -30.559998, -26.86    ],\n        ...,\n        [ 20.640015,  20.540009,  21.940002, ...,  22.140015,\n          21.940002,  21.540009],\n        [ 22.940002,  23.73999 ,  24.040009, ...,  22.540009,\n          22.540009,  22.040009],\n        [ 24.540009,  24.940002,  24.940002, ...,  23.339996,\n          23.040009,  22.540009]]], dtype=float32)air_kelvin(time, lat, lon)float32241.2 242.5 243.5 ... 296.2 295.7long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis\n(4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html"
  },
  {
    "objectID": "notebooks/03_Xarray_hvplot.html#subsetting-and-indexing",
    "href": "notebooks/03_Xarray_hvplot.html#subsetting-and-indexing",
    "title": "03. Introduction to xarray",
    "section": "Subsetting and Indexing",
    "text": "Subsetting and Indexing\nSubsetting and indexing methods depend on whether you are working with a Dataset or DataArray. A DataArray can be accessed using positional indexing just like a numpy array. To access the temperature field for the first time step, you do the following.\n\nds['air'][0,:,:]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'air' (lat: 25, lon: 53)&gt;\narray([[-31.949997, -30.649994, -29.649994, ..., -40.350006, -37.649994,\n        -34.550003],\n       [-29.350006, -28.649994, -28.449997, ..., -40.350006, -37.850006,\n        -33.850006],\n       [-23.149994, -23.350006, -24.259995, ..., -39.949997, -36.759995,\n        -31.449997],\n       ...,\n       [ 23.450012,  23.049988,  23.25    , ...,  22.25    ,  21.950012,\n         21.549988],\n       [ 22.75    ,  23.049988,  23.640015, ...,  22.75    ,  22.75    ,\n         22.049988],\n       [ 23.140015,  23.640015,  23.950012, ...,  23.75    ,  23.640015,\n         23.450012]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n    time     datetime64[ns] 2013-01-01\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degC\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]xarray.DataArray'air'lat: 25lon: 53-31.95 -30.65 -29.65 -29.15 -29.05 ... 24.64 24.45 23.75 23.64 23.45array([[-31.949997, -30.649994, -29.649994, ..., -40.350006, -37.649994,\n        -34.550003],\n       [-29.350006, -28.649994, -28.449997, ..., -40.350006, -37.850006,\n        -33.850006],\n       [-23.149994, -23.350006, -24.259995, ..., -39.949997, -36.759995,\n        -31.449997],\n       ...,\n       [ 23.450012,  23.049988,  23.25    , ...,  22.25    ,  21.950012,\n         21.549988],\n       [ 22.75    ,  23.049988,  23.640015, ...,  22.75    ,  22.75    ,\n         22.049988],\n       [ 23.140015,  23.640015,  23.950012, ...,  23.75    ,  23.640015,\n         23.450012]], dtype=float32)Coordinates: (3)lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)time()datetime64[ns]2013-01-01standard_name :timelong_name :Timearray('2013-01-01T00:00:00.000000000', dtype='datetime64[ns]')Attributes: (11)long_name :4xDaily Air temperature at sigma level 995units :degCprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]\n\n\nNote this returns a DataArray with coordinates but not attributes.\nHowever, the real power is being able to access variables using coordinate variables. I can get the same subset using the following. (It’s also more explicit about what is being selected and robust in case I modify the DataArray and expect the same output.)\n\nds['air'].sel(time='2013-01-01').time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'time' (time: 4)&gt;\narray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', '2013-01-01T18:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 2013-01-01 ... 2013-01-01T18:00:00\nAttributes:\n    standard_name:  time\n    long_name:      Timexarray.DataArray'time'time: 42013-01-01 2013-01-01T06:00:00 2013-01-01T12:00:00 2013-01-01T18:00:00array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', '2013-01-01T18:00:00.000000000'],\n      dtype='datetime64[ns]')Coordinates: (1)time(time)datetime64[ns]2013-01-01 ... 2013-01-01T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', '2013-01-01T18:00:00.000000000'],\n      dtype='datetime64[ns]')Attributes: (2)standard_name :timelong_name :Time\n\n\n\nds.air.sel(time='2013-01-01')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'air' (time: 4, lat: 25, lon: 53)&gt;\narray([[[-31.949997, -30.649994, -29.649994, ..., -40.350006,\n         -37.649994, -34.550003],\n        [-29.350006, -28.649994, -28.449997, ..., -40.350006,\n         -37.850006, -33.850006],\n        [-23.149994, -23.350006, -24.259995, ..., -39.949997,\n         -36.759995, -31.449997],\n        ...,\n        [ 23.450012,  23.049988,  23.25    , ...,  22.25    ,\n          21.950012,  21.549988],\n        [ 22.75    ,  23.049988,  23.640015, ...,  22.75    ,\n          22.75    ,  22.049988],\n        [ 23.140015,  23.640015,  23.950012, ...,  23.75    ,\n          23.640015,  23.450012]],\n\n       [[-31.050003, -30.449997, -30.050003, ..., -41.149994,\n         -39.550003, -37.350006],\n        [-29.550003, -29.050003, -28.949997, ..., -42.149994,\n         -40.649994, -37.449997],\n        [-19.949997, -20.259995, -21.050003, ..., -42.350006,\n         -39.759995, -34.649994],\n...\n        [ 22.450012,  22.25    ,  22.25    , ...,  23.140015,\n          22.140015,  21.850006],\n        [ 23.049988,  23.350006,  23.140015, ...,  23.25    ,\n          22.850006,  22.450012],\n        [ 23.25    ,  23.140015,  23.25    , ...,  23.850006,\n          23.850006,  23.640015]],\n\n       [[-31.259995, -31.350006, -31.350006, ..., -38.759995,\n         -37.649994, -35.550003],\n        [-26.850006, -27.850006, -28.949997, ..., -42.259995,\n         -41.649994, -38.649994],\n        [-16.549988, -18.449997, -21.050003, ..., -42.449997,\n         -41.350006, -37.050003],\n        ...,\n        [ 23.450012,  23.25    ,  22.850006, ...,  23.350006,\n          22.640015,  22.140015],\n        [ 23.850006,  24.350006,  23.950012, ...,  23.640015,\n          23.450012,  23.140015],\n        [ 24.350006,  24.549988,  24.350006, ...,  24.640015,\n          24.850006,  24.75    ]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2013-01-01T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degC\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]xarray.DataArray'air'time: 4lat: 25lon: 53-31.95 -30.65 -29.65 -29.15 -29.05 ... 25.45 25.05 24.64 24.85 24.75array([[[-31.949997, -30.649994, -29.649994, ..., -40.350006,\n         -37.649994, -34.550003],\n        [-29.350006, -28.649994, -28.449997, ..., -40.350006,\n         -37.850006, -33.850006],\n        [-23.149994, -23.350006, -24.259995, ..., -39.949997,\n         -36.759995, -31.449997],\n        ...,\n        [ 23.450012,  23.049988,  23.25    , ...,  22.25    ,\n          21.950012,  21.549988],\n        [ 22.75    ,  23.049988,  23.640015, ...,  22.75    ,\n          22.75    ,  22.049988],\n        [ 23.140015,  23.640015,  23.950012, ...,  23.75    ,\n          23.640015,  23.450012]],\n\n       [[-31.050003, -30.449997, -30.050003, ..., -41.149994,\n         -39.550003, -37.350006],\n        [-29.550003, -29.050003, -28.949997, ..., -42.149994,\n         -40.649994, -37.449997],\n        [-19.949997, -20.259995, -21.050003, ..., -42.350006,\n         -39.759995, -34.649994],\n...\n        [ 22.450012,  22.25    ,  22.25    , ...,  23.140015,\n          22.140015,  21.850006],\n        [ 23.049988,  23.350006,  23.140015, ...,  23.25    ,\n          22.850006,  22.450012],\n        [ 23.25    ,  23.140015,  23.25    , ...,  23.850006,\n          23.850006,  23.640015]],\n\n       [[-31.259995, -31.350006, -31.350006, ..., -38.759995,\n         -37.649994, -35.550003],\n        [-26.850006, -27.850006, -28.949997, ..., -42.259995,\n         -41.649994, -38.649994],\n        [-16.549988, -18.449997, -21.050003, ..., -42.449997,\n         -41.350006, -37.050003],\n        ...,\n        [ 23.450012,  23.25    ,  22.850006, ...,  23.350006,\n          22.640015,  22.140015],\n        [ 23.850006,  24.350006,  23.950012, ...,  23.640015,\n          23.450012,  23.140015],\n        [ 24.350006,  24.549988,  24.350006, ...,  24.640015,\n          24.850006,  24.75    ]]], dtype=float32)Coordinates: (3)lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)time(time)datetime64[ns]2013-01-01 ... 2013-01-01T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', '2013-01-01T18:00:00.000000000'],\n      dtype='datetime64[ns]')Attributes: (11)long_name :4xDaily Air temperature at sigma level 995units :degCprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]\n\n\nI can also do slices. I’ll extract temperatures for the state of Colorado. The bounding box for the state is [-109 E, -102 E, 37 N, 41 N].\nIn the code below, pay attention to both the order of the coordinates and the range of values. The first value of the lat coordinate variable is 41 N, the second value is 37 N. Unfortunately, xarray expects slices of coordinates to be in the same order as the coordinates. Note lon is 0 to 360 not -180 to 180, and I let python calculate it for me within the slice.\n\nds.air.sel(lat=slice(41.,37.), lon=slice(360-109,360-102))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'air' (time: 2920, lat: 2, lon: 3)&gt;\narray([[[-10.049988 ,  -9.25     ,  -8.75     ],\n        [ -6.25     ,  -6.549988 ,  -6.3599854]],\n\n       [[-18.149994 , -14.950012 ,  -9.950012 ],\n        [-13.649994 , -11.049988 ,  -7.25     ]],\n\n       [[-20.449997 , -18.649994 , -13.359985 ],\n        [-19.350006 , -16.950012 , -11.25     ]],\n\n       ...,\n\n       [[-24.460007 , -28.259995 , -25.759995 ],\n        [-16.959991 , -24.059998 , -24.059998 ]],\n\n       [[-24.36     , -26.160004 , -23.460007 ],\n        [-15.959991 , -22.86     , -22.960007 ]],\n\n       [[-17.559998 , -15.359985 , -13.660004 ],\n        [-13.76001  , -15.959991 , -14.459991 ]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 40.0 37.5\n  * lon      (lon) float32 252.5 255.0 257.5\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degC\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]xarray.DataArray'air'time: 2920lat: 2lon: 3-10.05 -9.25 -8.75 -6.25 -6.55 ... -15.36 -13.66 -13.76 -15.96 -14.46array([[[-10.049988 ,  -9.25     ,  -8.75     ],\n        [ -6.25     ,  -6.549988 ,  -6.3599854]],\n\n       [[-18.149994 , -14.950012 ,  -9.950012 ],\n        [-13.649994 , -11.049988 ,  -7.25     ]],\n\n       [[-20.449997 , -18.649994 , -13.359985 ],\n        [-19.350006 , -16.950012 , -11.25     ]],\n\n       ...,\n\n       [[-24.460007 , -28.259995 , -25.759995 ],\n        [-16.959991 , -24.059998 , -24.059998 ]],\n\n       [[-24.36     , -26.160004 , -23.460007 ],\n        [-15.959991 , -22.86     , -22.960007 ]],\n\n       [[-17.559998 , -15.359985 , -13.660004 ],\n        [-13.76001  , -15.959991 , -14.459991 ]]], dtype=float32)Coordinates: (3)lat(lat)float3240.0 37.5standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray([40. , 37.5], dtype=float32)lon(lon)float32252.5 255.0 257.5standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray([252.5, 255. , 257.5], dtype=float32)time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')Attributes: (11)long_name :4xDaily Air temperature at sigma level 995units :degCprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]\n\n\nWhat if we want temperature for a point, for example Denver, CO (39.72510678889283 N, -104.98785545855408 E). xarray can handle this! If we just want data from the nearest grid point, we can use sel and specify the method as “nearest”.\n\ndenver_lat, denver_lon = 39.72510678889283, -104.98785545855408\n\n\nds.air.sel(lat=denver_lat, lon=360+denver_lon, method='nearest').hvplot()\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nIf we want to interpolate, we can use interp(). In this case I use linear or bilinear interpolation.\ninterp() can also be used to resample data to a new grid and even reproject data\n\nds.air.interp(lat=denver_lat, lon=360+denver_lon, method='linear')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'air' (time: 2920)&gt;\narray([ -8.95085077, -14.49752791, -18.43715163, ..., -27.78736503,\n       -25.78552388, -15.41780902])\nCoordinates:\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\n    lat      float64 39.73\n    lon      float64 255.0\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degC\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]xarray.DataArray'air'time: 2920-8.951 -14.5 -18.44 -11.33 -8.942 ... -22.4 -27.79 -25.79 -15.42array([ -8.95085077, -14.49752791, -18.43715163, ..., -27.78736503,\n       -25.78552388, -15.41780902])Coordinates: (3)time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')lat()float6439.73standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray(39.72510679)lon()float64255.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray(255.01214454)Attributes: (11)long_name :4xDaily Air temperature at sigma level 995units :degCprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]\n\n\nsel() and interp() can also be used on Dataset objects.\n\nds.sel(lat=slice(41,37), lon=slice(360-109,360-102))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:     (lat: 2, time: 2920, lon: 3)\nCoordinates:\n  * lat         (lat) float32 40.0 37.5\n  * lon         (lon) float32 252.5 255.0 257.5\n  * time        (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nData variables:\n    air         (time, lat, lon) float32 -10.05 -9.25 -8.75 ... -15.96 -14.46\n    air_kelvin  (time, lat, lon) float32 263.1 263.9 264.4 ... 259.4 257.2 258.7\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...xarray.DatasetDimensions:lat: 2time: 2920lon: 3Coordinates: (3)lat(lat)float3240.0 37.5standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray([40. , 37.5], dtype=float32)lon(lon)float32252.5 255.0 257.5standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray([252.5, 255. , 257.5], dtype=float32)time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (2)air(time, lat, lon)float32-10.05 -9.25 ... -15.96 -14.46long_name :4xDaily Air temperature at sigma level 995units :degCprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]array([[[-10.049988 ,  -9.25     ,  -8.75     ],\n        [ -6.25     ,  -6.549988 ,  -6.3599854]],\n\n       [[-18.149994 , -14.950012 ,  -9.950012 ],\n        [-13.649994 , -11.049988 ,  -7.25     ]],\n\n       [[-20.449997 , -18.649994 , -13.359985 ],\n        [-19.350006 , -16.950012 , -11.25     ]],\n\n       ...,\n\n       [[-24.460007 , -28.259995 , -25.759995 ],\n        [-16.959991 , -24.059998 , -24.059998 ]],\n\n       [[-24.36     , -26.160004 , -23.460007 ],\n        [-15.959991 , -22.86     , -22.960007 ]],\n\n       [[-17.559998 , -15.359985 , -13.660004 ],\n        [-13.76001  , -15.959991 , -14.459991 ]]], dtype=float32)air_kelvin(time, lat, lon)float32263.1 263.9 264.4 ... 257.2 258.7long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]array([[[263.1    , 263.9    , 264.4    ],\n        [266.9    , 266.6    , 266.79   ]],\n\n       [[255.     , 258.19998, 263.19998],\n        [259.5    , 262.1    , 265.9    ]],\n\n       [[252.7    , 254.5    , 259.79   ],\n        [253.79999, 256.19998, 261.9    ]],\n\n       ...,\n\n       [[248.68999, 244.89   , 247.39   ],\n        [256.19   , 249.09   , 249.09   ]],\n\n       [[248.79   , 246.98999, 249.68999],\n        [257.19   , 250.29   , 250.18999]],\n\n       [[255.59   , 257.79   , 259.49   ],\n        [259.38998, 257.19   , 258.69   ]]], dtype=float32)Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis\n(4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html\n\n\n\nds.interp(lat=denver_lat, lon=360+denver_lon, method='linear')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:     (time: 2920)\nCoordinates:\n  * time        (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\n    lat         float64 39.73\n    lon         float64 255.0\nData variables:\n    air         (time) float64 -8.951 -14.5 -18.44 ... -27.79 -25.79 -15.42\n    air_kelvin  (time) float64 264.2 258.7 254.7 261.8 ... 245.4 247.4 257.7\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...xarray.DatasetDimensions:time: 2920Coordinates: (3)time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Timearray(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')lat()float6439.73standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray(39.72510679)lon()float64255.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray(255.01214454)Data variables: (2)air(time)float64-8.951 -14.5 ... -25.79 -15.42long_name :4xDaily Air temperature at sigma level 995units :degCprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]array([ -8.95085077, -14.49752791, -18.43715163, ..., -27.78736503,\n       -25.78552388, -15.41780902])air_kelvin(time)float64264.2 258.7 254.7 ... 247.4 257.7long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]array([264.19914312, 258.65246598, 254.71284227, ..., 245.36262886,\n       247.36447002, 257.73218487])Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis\n(4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html"
  },
  {
    "objectID": "notebooks/03_Xarray_hvplot.html#analysis",
    "href": "notebooks/03_Xarray_hvplot.html#analysis",
    "title": "03. Introduction to xarray",
    "section": "Analysis",
    "text": "Analysis\nAs a simple example, let’s try to calculate a mean field for the whole time range.\n\nds.mean(dim='time').hvplot()\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nWe can also calculate a zonal mean (averaging over longitude)\n\nds.mean(dim='lon').hvplot()\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nOther aggregation methods include min(), max(), std(), along with others.\n\nds.std(dim='time').hvplot()\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nThe data we have are in 6h timesteps. This can be resampled to daily or monthly. If you are familiar with pandas, xarray uses the same methods.\n\nds.resample(time='M').mean().hvplot()\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\nds_mon = ds.resample(time='M').mean()\nds_mon\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:     (time: 24, lat: 25, lon: 53)\nCoordinates:\n  * time        (time) datetime64[ns] 2013-01-31 2013-02-28 ... 2014-12-31\n  * lat         (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 22.5 20.0 17.5 15.0\n  * lon         (lon) float32 200.0 202.5 205.0 207.5 ... 325.0 327.5 330.0\nData variables:\n    air         (time, lat, lon) float32 -28.68 -28.49 -28.48 ... 24.57 24.56\n    air_kelvin  (time, lat, lon) float32 244.5 244.7 244.7 ... 297.7 297.7 297.7\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...xarray.DatasetDimensions:time: 24lat: 25lon: 53Coordinates: (3)time(time)datetime64[ns]2013-01-31 ... 2014-12-31array(['2013-01-31T00:00:00.000000000', '2013-02-28T00:00:00.000000000',\n       '2013-03-31T00:00:00.000000000', '2013-04-30T00:00:00.000000000',\n       '2013-05-31T00:00:00.000000000', '2013-06-30T00:00:00.000000000',\n       '2013-07-31T00:00:00.000000000', '2013-08-31T00:00:00.000000000',\n       '2013-09-30T00:00:00.000000000', '2013-10-31T00:00:00.000000000',\n       '2013-11-30T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-01-31T00:00:00.000000000', '2014-02-28T00:00:00.000000000',\n       '2014-03-31T00:00:00.000000000', '2014-04-30T00:00:00.000000000',\n       '2014-05-31T00:00:00.000000000', '2014-06-30T00:00:00.000000000',\n       '2014-07-31T00:00:00.000000000', '2014-08-31T00:00:00.000000000',\n       '2014-09-30T00:00:00.000000000', '2014-10-31T00:00:00.000000000',\n       '2014-11-30T00:00:00.000000000', '2014-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Yarray([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :Xarray([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)Data variables: (2)air(time, lat, lon)float32-28.68 -28.49 ... 24.57 24.56long_name :4xDaily Air temperature at sigma level 995units :degCprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]array([[[-28.68323  , -28.486452 , -28.479755 , ..., -30.658554 ,\n         -29.743628 , -28.474194 ],\n        [-26.076784 , -26.127504 , -26.4225   , ..., -32.5679   ,\n         -31.105167 , -28.442825 ],\n        [-22.770565 , -23.31516  , -24.042498 , ..., -31.165657 ,\n         -28.38291  , -24.144924 ],\n        ...,\n        [ 22.688152 ,  22.00097  ,  21.773153 , ...,  22.218397 ,\n          21.734531 ,  21.118395 ],\n        [ 23.31952  ,  23.16702  ,  22.698233 , ...,  22.43775  ,\n          22.190727 ,  21.715578 ],\n        [ 23.903486 ,  23.89203  ,  23.585333 , ...,  23.154608 ,\n          22.947426 ,  22.889124 ]],\n\n       [[-32.41607  , -32.44866  , -32.738483 , ..., -31.54482  ,\n         -30.430185 , -29.205448 ],\n        [-31.216885 , -31.08063  , -31.236965 , ..., -32.135708 ,\n         -30.825186 , -28.42241  ],\n        [-27.826433 , -28.123934 , -28.78045  , ..., -29.734114 ,\n         -27.383936 , -23.491434 ],\n...\n        [ 24.899088 ,  24.200085 ,  24.072004 , ...,  24.861843 ,\n          24.510258 ,  23.995668 ],\n        [ 25.815008 ,  25.661922 ,  25.121607 , ...,  24.954088 ,\n          25.071083 ,  24.735588 ],\n        [ 26.023424 ,  26.06767  ,  25.74576  , ...,  25.566338 ,\n          25.591848 ,  25.630259 ]],\n\n       [[-26.348473 , -26.260897 , -26.380894 , ..., -33.07903  ,\n         -32.067986 , -30.868315 ],\n        [-25.419994 , -24.849277 , -24.405483 , ..., -34.531376 ,\n         -32.82783  , -30.179682 ],\n        [-23.181051 , -23.56476  , -23.574757 , ..., -35.446938 ,\n         -31.91259  , -26.923311 ],\n        ...,\n        [ 23.299198 ,  22.541454 ,  22.60839  , ...,  23.378307 ,\n          23.067505 ,  22.662996 ],\n        [ 24.295895 ,  24.286139 ,  24.031782 , ...,  23.80259  ,\n          23.908312 ,  23.579037 ],\n        [ 24.897346 ,  25.076134 ,  24.909689 , ...,  24.547583 ,\n          24.573233 ,  24.560413 ]]], dtype=float32)air_kelvin(time, lat, lon)float32244.5 244.7 244.7 ... 297.7 297.7long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]array([[[244.4667 , 244.66354, 244.67027, ..., 242.49142, 243.40633,\n         244.67577],\n        [247.07323, 247.02248, 246.7275 , ..., 240.58205, 242.04489,\n         244.70726],\n        [250.37941, 249.83484, 249.10748, ..., 241.98434, 244.76712,\n         249.00505],\n        ...,\n        [295.83795, 295.15085, 294.9229 , ..., 295.36826, 294.88437,\n         294.26828],\n        [296.46942, 296.31686, 295.84802, ..., 295.5876 , 295.34058,\n         294.86536],\n        [297.05316, 297.0418 , 296.73517, ..., 296.30438, 296.09732,\n         296.0389 ]],\n\n       [[240.73384, 240.7013 , 240.4115 , ..., 241.60518, 242.71988,\n         243.94455],\n        [241.93309, 242.06935, 241.913  , ..., 241.01428, 242.32481,\n         244.72758],\n        [245.32361, 245.0261 , 244.36955, ..., 243.41588, 245.7661 ,\n         249.65858],\n...\n        [298.04895, 297.35007, 297.22195, ..., 298.01172, 297.66013,\n         297.14554],\n        [298.96484, 298.81186, 298.27136, ..., 298.10403, 298.22104,\n         297.88547],\n        [299.17334, 299.2175 , 298.89566, ..., 298.71625, 298.74167,\n         298.7802 ]],\n\n       [[246.80156, 246.88907, 246.76907, ..., 240.07089, 241.08206,\n         242.2817 ],\n        [247.72998, 248.30064, 248.74443, ..., 238.61859, 240.3222 ,\n         242.97026],\n        [249.96893, 249.58516, 249.57521, ..., 237.70308, 241.23743,\n         246.22667],\n        ...,\n        [296.4491 , 295.6914 , 295.75824, ..., 296.52817, 296.21747,\n         295.8128 ],\n        [297.44586, 297.43613, 297.1817 , ..., 296.95242, 297.05823,\n         296.72897],\n        [298.0472 , 298.22598, 298.0595 , ..., 297.6975 , 297.72318,\n         297.71024]]], dtype=float32)Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis\n(4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html\n\n\nThis is a really short time series but as an example, let’s calculate a monthly climatology (at least for 2 months). For this we can use groupby()\n\nds_clim = ds_mon.groupby(ds_mon.time.dt.month).mean()"
  },
  {
    "objectID": "notebooks/03_Xarray_hvplot.html#plot-results",
    "href": "notebooks/03_Xarray_hvplot.html#plot-results",
    "title": "03. Introduction to xarray",
    "section": "Plot results",
    "text": "Plot results\nFinally, let’s plot the results! This will plot the lat/lon axes of the original ds DataArray.\n\nds_clim.air.sel(month=10).plot()\n\n&lt;matplotlib.collections.QuadMesh at 0x7f22bb7acd90&gt;"
  },
  {
    "objectID": "notebooks/09_Zarr_Access.html",
    "href": "notebooks/09_Zarr_Access.html",
    "title": "09. Zarr Access for NetCDF4 files",
    "section": "",
    "text": "Exercise: 45 minutes"
  },
  {
    "objectID": "notebooks/09_Zarr_Access.html#timing",
    "href": "notebooks/09_Zarr_Access.html#timing",
    "title": "09. Zarr Access for NetCDF4 files",
    "section": "",
    "text": "Exercise: 45 minutes"
  },
  {
    "objectID": "notebooks/09_Zarr_Access.html#summary",
    "href": "notebooks/09_Zarr_Access.html#summary",
    "title": "09. Zarr Access for NetCDF4 files",
    "section": "Summary",
    "text": "Summary\nZarr is an open source library for storing N-dimensional array data. It supports multidimensional arrays with attributes and dimensions similar to NetCDF4, and it can be read by XArray. Zarr is often used for data held in cloud object storage (like Amazon S3), because it is better optimized for these situations than NetCDF4.\nThe zarr-eosdis-store library allows NASA EOSDIS NetCDF4 files to be read more efficiently by transferring only file metadata and data needed for computation in a small number of requests, rather than moving the whole file or making many small requests. It works by making the files directly readable by the Zarr Python library and XArray across a network. To use it, files must have a corresponding metadata file ending in .dmrpp, which increasingly true for cloud-accessible EOSDIS data. https://github.com/nasa/zarr-eosdis-store\nThe zarr-eosdis-store library provides several benefits over downloading EOSDIS data files and accessing them using XArray, NetCDF4, or HDF5 Python libraries:\n\nIt only downloads the chunks of data you actually read, so if you don’t read all variables or the full spatiotemporal extent of a file, you usually won’t spend time downloading those portions of the file\nIt parallelizes and optimizes downloads for the portions of files you do read, so download speeds can be faster in general\nIt automatically interoperates with Earthdata Login if you have a .netrc file set up\nIt is aware of some EOSDIS cloud implementation quirks and provides caching that can save time for repeated requests to individual files\n\nIt can also be faster than using XArray pointing NetCDF4 files with s3:// URLs, depending on the file’s internal structure, and is often more convenient.\nConsider using this library when: 1. The portion of the data file you need to use is much smaller than the full file, e.g. in cases of spatial subsets or reading a single variable from a file containing several 1. s3:// URLs are not readily available 1. Code need to run outside of the AWS cloud or us-west-2 region or in a hybrid cloud / non-cloud manner 1. s3:// access using XArray seems slower than you would expect (possibly due to unoptimized internal file structure) 1. No readily-available, public, cloud-optimized version of the data exists already. The example we show is also available as an AWS Public Dataset: https://registry.opendata.aws/mur/ 1. Adding “.dmrpp” to the end of a data URL returns a file\n\nObjectives\n\nBuild on prior knowledge from CMR and Earthdata Login tutorials\nWork through an example of using the EOSDIS Zarr Store to access data using XArray\nLearn about the Zarr format and library for accessing data in the cloud"
  },
  {
    "objectID": "notebooks/09_Zarr_Access.html#exercise",
    "href": "notebooks/09_Zarr_Access.html#exercise",
    "title": "09. Zarr Access for NetCDF4 files",
    "section": "Exercise",
    "text": "Exercise\nIn this exercise, we will be using the eosdis-zarr-store library to aggregate and analyze a month of sea surface temperature for the Great Lakes region\n\nSet up\n\nImport Required Packages\n\n# Core libraries for this tutorial\n# Available via `pip install zarr zarr-eosdis-store`\nfrom eosdis_store import EosdisStore\nimport xarray as xr\n\n# Other Python libraries\nimport requests\nfrom pqdm.threads import pqdm\nfrom matplotlib import animation, pyplot as plt\nfrom IPython.core.display import display, HTML\n\n# Python standard library imports\nfrom pprint import pprint\n\nAlso set the width / height for plots we show\n\nplt.rcParams['figure.figsize'] = 12, 6\n\n\n\nSet Dataset, Time, and Region of Interest\nLook in PO.DAAC’s cloud archive for Group for High Resolution Sea Surface Temperature (GHRSST) Level 4 Multiscale Ultrahigh Resolution (MUR) data\n\ndata_provider = 'POCLOUD'\nmur_short_name = 'MUR-JPL-L4-GLOB-v4.1'\n\nLooking for data from the month of September over the Great Lakes\n\nstart_time = '2021-09-01T21:00:00Z'\nend_time = '2021-09-30T20:59:59Z'\n\n# Bounding box around the Great Lakes\nlats = slice(41, 49)\nlons = slice(-93, -76)\n\n# Some other possibly interesting bounding boxes:\n\n# Hawaiian Islands\n# lats = slice(18, 22.5)\n# lons = slice(-161, -154)\n\n# Mediterranean Sea\n# lats = slice(29, 45)\n# lons = slice(-7, 37)\n\n\n\n\nFind URLs for the dataset and AOI\nSet up a CMR granules search for our area of interest, as we saw in prior tutorials\n\ncmr_url = 'https://cmr.earthdata.nasa.gov/search/granules.json'\n\nSearch for granules in our area of interest, expecting one granule per day of September\n\nresponse = requests.get(cmr_url, \n                        params={\n                            'provider': data_provider,\n                            'short_name': mur_short_name, \n                            'temporal': f'{start_time},{end_time}',\n                            'bounding_box': f'{lons.start},{lats.start},{lons.stop},{lats.stop}',\n                            'page_size': 2000,\n                            }\n                       )\n\n\ngranules = response.json()['feed']['entry']\n\nfor granule in granules:\n    print(granule['title'])\n\n20210901090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210902090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210903090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210904090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210905090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210906090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210907090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210908090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210909090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210910090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210911090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210912090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210913090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210914090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210915090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210916090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210917090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210918090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210919090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210920090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210921090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210922090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210923090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210924090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210925090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210926090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210927090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210928090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210929090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n20210930090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1\n\n\n\npprint(granules[0])\n\n{'boxes': ['-90 -180 90 180'],\n 'browse_flag': False,\n 'collection_concept_id': 'C1996881146-POCLOUD',\n 'coordinate_system': 'CARTESIAN',\n 'data_center': 'POCLOUD',\n 'dataset_id': 'GHRSST Level 4 MUR Global Foundation Sea Surface Temperature '\n               'Analysis (v4.1)',\n 'day_night_flag': 'UNSPECIFIED',\n 'granule_size': '9.059906005859375E-5',\n 'id': 'G2113241213-POCLOUD',\n 'links': [{'href': 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210901090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n            'hreflang': 'en-US',\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/s3#',\n            'title': 'This link provides direct download access via S3 to the '\n                     'granule.'},\n           {'href': 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210901090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n            'hreflang': 'en-US',\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n            'title': 'Download '\n                     '20210901090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc'},\n           {'href': 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-public/MUR-JPL-L4-GLOB-v4.1/20210901090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc.md5',\n            'hreflang': 'en-US',\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n            'title': 'Download '\n                     '20210901090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc.md5'},\n           {'href': 'https://archive.podaac.earthdata.nasa.gov/s3credentials',\n            'hreflang': 'en-US',\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n            'title': 'api endpoint to retrieve temporary credentials valid for '\n                     'same-region direct s3 access'},\n           {'href': 'https://opendap.earthdata.nasa.gov/collections/C1996881146-POCLOUD/granules/20210901090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1',\n            'hreflang': 'en-US',\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/service#',\n            'title': 'OPeNDAP request URL'},\n           {'href': 'https://github.com/nasa/podaac_tools_and_services/tree/master/subset_opendap',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'},\n           {'href': 'https://ghrsst.jpl.nasa.gov',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'},\n           {'href': 'https://earthdata.nasa.gov/esds/competitive-programs/measures/mur-sst',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#'},\n           {'href': 'http://journals.ametsoc.org/doi/abs/10.1175/1520-0426%281998%29015%3C0741:BSHWSS%3E2.0.CO;2',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'},\n           {'href': 'https://podaac-tools.jpl.nasa.gov/drive/files/OceanTemperature/ghrsst/docs/GDS20r5.pdf',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'},\n           {'href': 'https://github.com/podaac/data-readers',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'},\n           {'href': 'https://doi.org/10.1016/j.rse.2017.07.029',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'},\n           {'href': 'https://registry.opendata.aws/mur/#usageexa',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#'},\n           {'href': 'http://www.ghrsst.org',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'},\n           {'href': 'https://podaac.jpl.nasa.gov/CitingPODAAC',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'},\n           {'href': 'https://cmr.earthdata.nasa.gov/virtual-directory/collections/C1996881146-POCLOUD ',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'length': '300.0MB',\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n           {'href': ' '\n                    'https://search.earthdata.nasa.gov/search/granules?p=C1996881146-POCLOUD ',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'length': '700.0MB',\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#'},\n           {'href': 'https://podaac.jpl.nasa.gov/MEaSUREs-MUR',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'},\n           {'href': 'https://github.com/podaac/tutorials/blob/master/notebooks/SWOT-EA-2021/Colocate_satellite_insitu_ocean.ipynb',\n            'hreflang': 'en-US',\n            'inherited': True,\n            'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#'}],\n 'online_access_flag': True,\n 'original_format': 'UMM_JSON',\n 'time_end': '2021-09-01T21:00:00.000Z',\n 'time_start': '2021-08-31T21:00:00.000Z',\n 'title': '20210901090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1',\n 'updated': '2021-09-10T07:29:40.511Z'}\n\n\n\nurls = []\nfor granule in granules:\n    for link in granule['links']:\n        if link['rel'].endswith('/data#'):\n            urls.append(link['href'])\n            break\npprint(urls)\n\n['https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210901090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210902090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210903090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210904090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210905090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210906090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210907090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210908090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210909090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210910090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210911090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210912090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210913090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210914090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210915090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210916090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210917090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210918090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210919090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210920090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210921090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210922090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210923090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210924090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210925090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210926090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210927090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210928090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210929090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20210930090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc']\n\n\n\n\nOpen and view our AOI without downloading a whole file\n\nCheck to see if we can use an efficient partial-access technique\n\nresponse = requests.head(f'{urls[0]}.dmrpp')\n\nprint('Can we use EosdisZarrStore and XArray to access these files more efficiently?')\nprint('Yes' if response.ok else 'No')\n\nCan we use EosdisZarrStore and XArray to access these files more efficiently?\nYes\n\n\nOpen our first URL using the Zarr library\n\nurl = urls[0]\n\nds = xr.open_zarr(EosdisStore(url), consolidated=False)\n\nThat’s it! No downloads, temporary credentials, or S3 filesystems. Hereafter, we interact with the ds variable as with any XArray dataset. We need not worry about the EosdisStore anymore.\nView the file’s variable structure\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (time: 1, lat: 17999, lon: 36000)\nCoordinates:\n  * lat               (lat) float32 -89.99 -89.98 -89.97 ... 89.97 89.98 89.99\n  * lon               (lon) float32 -180.0 -180.0 -180.0 ... 180.0 180.0 180.0\n  * time              (time) datetime64[ns] 2021-09-01T09:00:00\nData variables:\n    analysed_sst      (time, lat, lon) float32 dask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\n    analysis_error    (time, lat, lon) float32 dask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\n    dt_1km_data       (time, lat, lon) timedelta64[ns] dask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n    mask              (time, lat, lon) float32 dask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n    sea_ice_fraction  (time, lat, lon) float32 dask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n    sst_anomaly       (time, lat, lon) float32 dask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\nAttributes: (12/47)\n    Conventions:                CF-1.7\n    title:                      Daily MUR SST, Final product\n    summary:                    A merged, multi-sensor L4 Foundation SST anal...\n    references:                 http://podaac.jpl.nasa.gov/Multi-scale_Ultra-...\n    institution:                Jet Propulsion Laboratory\n    history:                    created at nominal 4-day latency; replaced nr...\n    ...                         ...\n    project:                    NASA Making Earth Science Data Records for Us...\n    publisher_name:             GHRSST Project Office\n    publisher_url:              http://www.ghrsst.org\n    publisher_email:            ghrsst-po@nceo.ac.uk\n    processing_level:           L4\n    cdm_data_type:              gridxarray.DatasetDimensions:time: 1lat: 17999lon: 36000Coordinates: (3)lat(lat)float32-89.99 -89.98 ... 89.98 89.99long_name :latitudestandard_name :latitudeaxis :Yunits :degrees_northvalid_min :-90.0valid_max :90.0comment :geolocations inherited from the input data without correctionarray([-89.99, -89.98, -89.97, ...,  89.97,  89.98,  89.99], dtype=float32)lon(lon)float32-180.0 -180.0 ... 180.0 180.0long_name :longitudestandard_name :longitudeaxis :Xunits :degrees_eastvalid_min :-180.0valid_max :180.0comment :geolocations inherited from the input data without correctionarray([-179.99, -179.98, -179.97, ...,  179.98,  179.99,  180.  ],\n      dtype=float32)time(time)datetime64[ns]2021-09-01T09:00:00long_name :reference time of sst fieldstandard_name :timeaxis :Tcomment :Nominal time of analyzed fieldsarray(['2021-09-01T09:00:00.000000000'], dtype='datetime64[ns]')Data variables: (6)analysed_sst(time, lat, lon)float32dask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;long_name :analysed sea surface temperaturestandard_name :sea_surface_foundation_temperatureunits :kelvinvalid_min :-32767valid_max :32767comment :\\\"Final\\\" version using Multi-Resolution Variational Analysis (MRVA) method for interpolationsource :MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, AVHRRMTB_G-NAVO, iQUAM-NOAA/NESDIS, Ice_Conc-OSISAF\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.41 GiB\n7.99 MiB\n\n\nShape\n(1, 17999, 36000)\n(1, 1023, 2047)\n\n\nCount\n325 Tasks\n324 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\n\nanalysis_error\n\n\n(time, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nestimated error standard deviation of analysed_sst\n\nunits :\n\nkelvin\n\nvalid_min :\n\n0\n\nvalid_max :\n\n32767\n\ncomment :\n\nuncertainty in \\\"analysed_sst\\\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.41 GiB\n7.99 MiB\n\n\nShape\n(1, 17999, 36000)\n(1, 1023, 2047)\n\n\nCount\n325 Tasks\n324 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\n\n\ndt_1km_data\n\n\n(time, lat, lon)\n\n\ntimedelta64[ns]\n\n\ndask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\ntime to most recent 1km data\n\nvalid_min :\n\n-127\n\nvalid_max :\n\n127\n\nsource :\n\nMODIS and VIIRS pixels ingested by MUR\n\ncomment :\n\nThe grid value is hours between the analysis time and the most recent MODIS or VIIRS 1km L2P datum within 0.01 degrees from the grid point. \\\"Fill value\\\" indicates absence of such 1km data at the grid point.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n4.83 GiB\n31.96 MiB\n\n\nShape\n(1, 17999, 36000)\n(1, 1447, 2895)\n\n\nCount\n170 Tasks\n169 Chunks\n\n\nType\ntimedelta64[ns]\nnumpy.ndarray\n\n\n\n\n\n\n\n\n\nmask\n\n\n(time, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nsea/land field composite mask\n\nvalid_min :\n\n1\n\nvalid_max :\n\n31\n\nflag_masks :\n\n[1, 2, 4, 8, 16]\n\nflag_meanings :\n\nopen_sea land open_lake open_sea_with_ice_in_the_grid open_lake_with_ice_in_the_grid\n\ncomment :\n\nmask can be used to further filter the data.\n\nsource :\n\nGMT \\\"grdlandmask\\\", ice flag from sea_ice_fraction data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.41 GiB\n15.98 MiB\n\n\nShape\n(1, 17999, 36000)\n(1, 1447, 2895)\n\n\nCount\n170 Tasks\n169 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\n\n\nsea_ice_fraction\n\n\n(time, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nsea ice area fraction\n\nstandard_name :\n\nsea_ice_area_fraction\n\nvalid_min :\n\n0\n\nvalid_max :\n\n100\n\nsource :\n\nEUMETSAT OSI-SAF, copyright EUMETSAT\n\ncomment :\n\nice fraction is a dimensionless quantity between 0 and 1; it has been interpolated by a nearest neighbor approach.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.41 GiB\n15.98 MiB\n\n\nShape\n(1, 17999, 36000)\n(1, 1447, 2895)\n\n\nCount\n170 Tasks\n169 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\n\n\nsst_anomaly\n\n\n(time, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nSST anomaly from a seasonal SST climatology based on the MUR data over 2003-2014 period\n\nunits :\n\nkelvin\n\nvalid_min :\n\n-32767\n\nvalid_max :\n\n32767\n\ncomment :\n\nanomaly reference to the day-of-year average between 2003 and 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.41 GiB\n7.99 MiB\n\n\nShape\n(1, 17999, 36000)\n(1, 1023, 2047)\n\n\nCount\n325 Tasks\n324 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\n\nAttributes: (47)Conventions :CF-1.7title :Daily MUR SST, Final productsummary :A merged, multi-sensor L4 Foundation SST analysis product from JPL.references :http://podaac.jpl.nasa.gov/Multi-scale_Ultra-high_Resolution_MUR-SSTinstitution :Jet Propulsion Laboratoryhistory :created at nominal 4-day latency; replaced nrt (1-day latency) version.comment :MUR = \\\"Multi-scale Ultra-high Resolution\\\"license :These data are available free of charge under data policy of JPL PO.DAAC.id :MUR-JPL-L4-GLOB-v04.1naming_authority :org.ghrsstproduct_version :04.1uuid :27665bc0-d5fc-11e1-9b23-0800200c9a66gds_version_id :2.0netcdf_version_id :4.1date_created :20210910T072132Zstart_time :20210901T090000Zstop_time :20210901T090000Ztime_coverage_start :20210831T210000Ztime_coverage_end :20210901T210000Zfile_quality_level :3source :MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, AVHRRMTB_G-NAVO, iQUAM-NOAA/NESDIS, Ice_Conc-OSISAFplatform :Terra, Aqua, GCOM-W, MetOp-A, MetOp-B, Buoys/Shipssensor :MODIS, AMSR2, AVHRR, in-situMetadata_Conventions :Unidata Observation Dataset v1.0metadata_link :http://podaac.jpl.nasa.gov/ws/metadata/dataset/?format=iso&shortName=MUR-JPL-L4-GLOB-v04.1keywords :Oceans &gt; Ocean Temperature &gt; Sea Surface Temperaturekeywords_vocabulary :NASA Global Change Master Directory (GCMD) Science Keywordsstandard_name_vocabulary :NetCDF Climate and Forecast (CF) Metadata Conventionsouthernmost_latitude :-90.0northernmost_latitude :90.0westernmost_longitude :-180.0easternmost_longitude :180.0spatial_resolution :0.01 degreesgeospatial_lat_units :degrees northgeospatial_lat_resolution :0.009999999776geospatial_lon_units :degrees eastgeospatial_lon_resolution :0.009999999776acknowledgment :Please acknowledge the use of these data with the following statement:  These data were provided by JPL under support by NASA MEaSUREs program.creator_name :JPL MUR SST projectcreator_email :ghrsst@podaac.jpl.nasa.govcreator_url :http://mur.jpl.nasa.govproject :NASA Making Earth Science Data Records for Use in Research Environments (MEaSUREs) Programpublisher_name :GHRSST Project Officepublisher_url :http://www.ghrsst.orgpublisher_email :ghrsst-po@nceo.ac.ukprocessing_level :L4cdm_data_type :grid\n\n\n\nds.analysed_sst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'analysed_sst' (time: 1, lat: 17999, lon: 36000)&gt;\ndask.array&lt;open_dataset-4d5a9a1e1fda090e80524b67b2e413c6analysed_sst, shape=(1, 17999, 36000), dtype=float32, chunksize=(1, 1023, 2047), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * lat      (lat) float32 -89.99 -89.98 -89.97 -89.96 ... 89.97 89.98 89.99\n  * lon      (lon) float32 -180.0 -180.0 -180.0 -180.0 ... 180.0 180.0 180.0\n  * time     (time) datetime64[ns] 2021-09-01T09:00:00\nAttributes:\n    long_name:      analysed sea surface temperature\n    standard_name:  sea_surface_foundation_temperature\n    units:          kelvin\n    valid_min:      -32767\n    valid_max:      32767\n    comment:        \\\"Final\\\" version using Multi-Resolution Variational Anal...\n    source:         MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, A...xarray.DataArray'analysed_sst'time: 1lat: 17999lon: 36000dask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.41 GiB\n7.99 MiB\n\n\nShape\n(1, 17999, 36000)\n(1, 1023, 2047)\n\n\nCount\n325 Tasks\n324 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (3)lat(lat)float32-89.99 -89.98 ... 89.98 89.99long_name :latitudestandard_name :latitudeaxis :Yunits :degrees_northvalid_min :-90.0valid_max :90.0comment :geolocations inherited from the input data without correctionarray([-89.99, -89.98, -89.97, ...,  89.97,  89.98,  89.99], dtype=float32)lon(lon)float32-180.0 -180.0 ... 180.0 180.0long_name :longitudestandard_name :longitudeaxis :Xunits :degrees_eastvalid_min :-180.0valid_max :180.0comment :geolocations inherited from the input data without correctionarray([-179.99, -179.98, -179.97, ...,  179.98,  179.99,  180.  ],\n      dtype=float32)time(time)datetime64[ns]2021-09-01T09:00:00long_name :reference time of sst fieldstandard_name :timeaxis :Tcomment :Nominal time of analyzed fieldsarray(['2021-09-01T09:00:00.000000000'], dtype='datetime64[ns]')Attributes: (7)long_name :analysed sea surface temperaturestandard_name :sea_surface_foundation_temperatureunits :kelvinvalid_min :-32767valid_max :32767comment :\\\"Final\\\" version using Multi-Resolution Variational Analysis (MRVA) method for interpolationsource :MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, AVHRRMTB_G-NAVO, iQUAM-NOAA/NESDIS, Ice_Conc-OSISAF\n\n\n\nsst = ds.analysed_sst.sel(lat=lats, lon=lons)\nsst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'analysed_sst' (time: 1, lat: 801, lon: 1701)&gt;\ndask.array&lt;getitem, shape=(1, 801, 1701), dtype=float32, chunksize=(1, 601, 1536), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * lat      (lat) float32 41.0 41.01 41.02 41.03 ... 48.97 48.98 48.99 49.0\n  * lon      (lon) float32 -93.0 -92.99 -92.98 -92.97 ... -76.02 -76.01 -76.0\n  * time     (time) datetime64[ns] 2021-09-01T09:00:00\nAttributes:\n    long_name:      analysed sea surface temperature\n    standard_name:  sea_surface_foundation_temperature\n    units:          kelvin\n    valid_min:      -32767\n    valid_max:      32767\n    comment:        \\\"Final\\\" version using Multi-Resolution Variational Anal...\n    source:         MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, A...xarray.DataArray'analysed_sst'time: 1lat: 801lon: 1701dask.array&lt;chunksize=(1, 200, 1536), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n5.20 MiB\n3.52 MiB\n\n\nShape\n(1, 801, 1701)\n(1, 601, 1536)\n\n\nCount\n329 Tasks\n4 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (3)lat(lat)float3241.0 41.01 41.02 ... 48.99 49.0long_name :latitudestandard_name :latitudeaxis :Yunits :degrees_northvalid_min :-90.0valid_max :90.0comment :geolocations inherited from the input data without correctionarray([41.  , 41.01, 41.02, ..., 48.98, 48.99, 49.  ], dtype=float32)lon(lon)float32-93.0 -92.99 ... -76.01 -76.0long_name :longitudestandard_name :longitudeaxis :Xunits :degrees_eastvalid_min :-180.0valid_max :180.0comment :geolocations inherited from the input data without correctionarray([-93.  , -92.99, -92.98, ..., -76.02, -76.01, -76.  ], dtype=float32)time(time)datetime64[ns]2021-09-01T09:00:00long_name :reference time of sst fieldstandard_name :timeaxis :Tcomment :Nominal time of analyzed fieldsarray(['2021-09-01T09:00:00.000000000'], dtype='datetime64[ns]')Attributes: (7)long_name :analysed sea surface temperaturestandard_name :sea_surface_foundation_temperatureunits :kelvinvalid_min :-32767valid_max :32767comment :\\\"Final\\\" version using Multi-Resolution Variational Analysis (MRVA) method for interpolationsource :MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, AVHRRMTB_G-NAVO, iQUAM-NOAA/NESDIS, Ice_Conc-OSISAF\n\n\n\nsst.plot()\n\n&lt;matplotlib.collections.QuadMesh at 0x7f2d9848d4c0&gt;\n\n\n\n\n\n\n\n\nAggregate and analyze 30 files\nSet up a function to open all of our URLs as XArrays in parallel\n\ndef open_as_zarr_xarray(url):\n    return xr.open_zarr(EosdisStore(url), consolidated=False)\n\ndatasets = pqdm(urls, open_as_zarr_xarray, n_jobs=30)\n\n\n\n\n\n\n\n\n\n\nCombine the individual file-based datasets into a single xarray dataset with a time axis\n\nds = xr.concat(datasets, 'time')\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (time: 30, lat: 17999, lon: 36000)\nCoordinates:\n  * lat               (lat) float32 -89.99 -89.98 -89.97 ... 89.97 89.98 89.99\n  * lon               (lon) float32 -180.0 -180.0 -180.0 ... 180.0 180.0 180.0\n  * time              (time) datetime64[ns] 2021-09-01T09:00:00 ... 2021-09-3...\nData variables:\n    analysed_sst      (time, lat, lon) float32 dask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\n    analysis_error    (time, lat, lon) float32 dask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\n    dt_1km_data       (time, lat, lon) timedelta64[ns] dask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n    mask              (time, lat, lon) float32 dask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n    sea_ice_fraction  (time, lat, lon) float32 dask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n    sst_anomaly       (time, lat, lon) float32 dask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\nAttributes: (12/47)\n    Conventions:                CF-1.7\n    title:                      Daily MUR SST, Final product\n    summary:                    A merged, multi-sensor L4 Foundation SST anal...\n    references:                 http://podaac.jpl.nasa.gov/Multi-scale_Ultra-...\n    institution:                Jet Propulsion Laboratory\n    history:                    created at nominal 4-day latency; replaced nr...\n    ...                         ...\n    project:                    NASA Making Earth Science Data Records for Us...\n    publisher_name:             GHRSST Project Office\n    publisher_url:              http://www.ghrsst.org\n    publisher_email:            ghrsst-po@nceo.ac.uk\n    processing_level:           L4\n    cdm_data_type:              gridxarray.DatasetDimensions:time: 30lat: 17999lon: 36000Coordinates: (3)lat(lat)float32-89.99 -89.98 ... 89.98 89.99long_name :latitudestandard_name :latitudeaxis :Yunits :degrees_northvalid_min :-90.0valid_max :90.0comment :geolocations inherited from the input data without correctionarray([-89.99, -89.98, -89.97, ...,  89.97,  89.98,  89.99], dtype=float32)lon(lon)float32-180.0 -180.0 ... 180.0 180.0long_name :longitudestandard_name :longitudeaxis :Xunits :degrees_eastvalid_min :-180.0valid_max :180.0comment :geolocations inherited from the input data without correctionarray([-179.99, -179.98, -179.97, ...,  179.98,  179.99,  180.  ],\n      dtype=float32)time(time)datetime64[ns]2021-09-01T09:00:00 ... 2021-09-...long_name :reference time of sst fieldstandard_name :timeaxis :Tcomment :Nominal time of analyzed fieldsarray(['2021-09-01T09:00:00.000000000', '2021-09-02T09:00:00.000000000',\n       '2021-09-03T09:00:00.000000000', '2021-09-04T09:00:00.000000000',\n       '2021-09-05T09:00:00.000000000', '2021-09-06T09:00:00.000000000',\n       '2021-09-07T09:00:00.000000000', '2021-09-08T09:00:00.000000000',\n       '2021-09-09T09:00:00.000000000', '2021-09-10T09:00:00.000000000',\n       '2021-09-11T09:00:00.000000000', '2021-09-12T09:00:00.000000000',\n       '2021-09-13T09:00:00.000000000', '2021-09-14T09:00:00.000000000',\n       '2021-09-15T09:00:00.000000000', '2021-09-16T09:00:00.000000000',\n       '2021-09-17T09:00:00.000000000', '2021-09-18T09:00:00.000000000',\n       '2021-09-19T09:00:00.000000000', '2021-09-20T09:00:00.000000000',\n       '2021-09-21T09:00:00.000000000', '2021-09-22T09:00:00.000000000',\n       '2021-09-23T09:00:00.000000000', '2021-09-24T09:00:00.000000000',\n       '2021-09-25T09:00:00.000000000', '2021-09-26T09:00:00.000000000',\n       '2021-09-27T09:00:00.000000000', '2021-09-28T09:00:00.000000000',\n       '2021-09-29T09:00:00.000000000', '2021-09-30T09:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (6)analysed_sst(time, lat, lon)float32dask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;long_name :analysed sea surface temperaturestandard_name :sea_surface_foundation_temperatureunits :kelvinvalid_min :-32767valid_max :32767comment :\\\"Final\\\" version using Multi-Resolution Variational Analysis (MRVA) method for interpolationsource :MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, AVHRRMTB_G-NAVO, iQUAM-NOAA/NESDIS, Ice_Conc-OSISAF\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n72.42 GiB\n7.99 MiB\n\n\nShape\n(30, 17999, 36000)\n(1, 1023, 2047)\n\n\nCount\n19470 Tasks\n9720 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\n\nanalysis_error\n\n\n(time, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nestimated error standard deviation of analysed_sst\n\nunits :\n\nkelvin\n\nvalid_min :\n\n0\n\nvalid_max :\n\n32767\n\ncomment :\n\nuncertainty in \\\"analysed_sst\\\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n72.42 GiB\n7.99 MiB\n\n\nShape\n(30, 17999, 36000)\n(1, 1023, 2047)\n\n\nCount\n19470 Tasks\n9720 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\n\n\ndt_1km_data\n\n\n(time, lat, lon)\n\n\ntimedelta64[ns]\n\n\ndask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\ntime to most recent 1km data\n\nvalid_min :\n\n-127\n\nvalid_max :\n\n127\n\nsource :\n\nMODIS and VIIRS pixels ingested by MUR\n\ncomment :\n\nThe grid value is hours between the analysis time and the most recent MODIS or VIIRS 1km L2P datum within 0.01 degrees from the grid point. \\\"Fill value\\\" indicates absence of such 1km data at the grid point.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n144.83 GiB\n31.96 MiB\n\n\nShape\n(30, 17999, 36000)\n(1, 1447, 2895)\n\n\nCount\n10170 Tasks\n5070 Chunks\n\n\nType\ntimedelta64[ns]\nnumpy.ndarray\n\n\n\n\n\n\n\n\n\nmask\n\n\n(time, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nsea/land field composite mask\n\nvalid_min :\n\n1\n\nvalid_max :\n\n31\n\nflag_masks :\n\n[1, 2, 4, 8, 16]\n\nflag_meanings :\n\nopen_sea land open_lake open_sea_with_ice_in_the_grid open_lake_with_ice_in_the_grid\n\ncomment :\n\nmask can be used to further filter the data.\n\nsource :\n\nGMT \\\"grdlandmask\\\", ice flag from sea_ice_fraction data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n72.42 GiB\n15.98 MiB\n\n\nShape\n(30, 17999, 36000)\n(1, 1447, 2895)\n\n\nCount\n10170 Tasks\n5070 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\n\n\nsea_ice_fraction\n\n\n(time, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1447, 2895), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nsea ice area fraction\n\nstandard_name :\n\nsea_ice_area_fraction\n\nvalid_min :\n\n0\n\nvalid_max :\n\n100\n\nsource :\n\nEUMETSAT OSI-SAF, copyright EUMETSAT\n\ncomment :\n\nice fraction is a dimensionless quantity between 0 and 1; it has been interpolated by a nearest neighbor approach.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n72.42 GiB\n15.98 MiB\n\n\nShape\n(30, 17999, 36000)\n(1, 1447, 2895)\n\n\nCount\n10170 Tasks\n5070 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\n\n\nsst_anomaly\n\n\n(time, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nSST anomaly from a seasonal SST climatology based on the MUR data over 2003-2014 period\n\nunits :\n\nkelvin\n\nvalid_min :\n\n-32767\n\nvalid_max :\n\n32767\n\ncomment :\n\nanomaly reference to the day-of-year average between 2003 and 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n72.42 GiB\n7.99 MiB\n\n\nShape\n(30, 17999, 36000)\n(1, 1023, 2047)\n\n\nCount\n19470 Tasks\n9720 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\n\nAttributes: (47)Conventions :CF-1.7title :Daily MUR SST, Final productsummary :A merged, multi-sensor L4 Foundation SST analysis product from JPL.references :http://podaac.jpl.nasa.gov/Multi-scale_Ultra-high_Resolution_MUR-SSTinstitution :Jet Propulsion Laboratoryhistory :created at nominal 4-day latency; replaced nrt (1-day latency) version.comment :MUR = \\\"Multi-scale Ultra-high Resolution\\\"license :These data are available free of charge under data policy of JPL PO.DAAC.id :MUR-JPL-L4-GLOB-v04.1naming_authority :org.ghrsstproduct_version :04.1uuid :27665bc0-d5fc-11e1-9b23-0800200c9a66gds_version_id :2.0netcdf_version_id :4.1date_created :20210910T072132Zstart_time :20210901T090000Zstop_time :20210901T090000Ztime_coverage_start :20210831T210000Ztime_coverage_end :20210901T210000Zfile_quality_level :3source :MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, AVHRRMTB_G-NAVO, iQUAM-NOAA/NESDIS, Ice_Conc-OSISAFplatform :Terra, Aqua, GCOM-W, MetOp-A, MetOp-B, Buoys/Shipssensor :MODIS, AMSR2, AVHRR, in-situMetadata_Conventions :Unidata Observation Dataset v1.0metadata_link :http://podaac.jpl.nasa.gov/ws/metadata/dataset/?format=iso&shortName=MUR-JPL-L4-GLOB-v04.1keywords :Oceans &gt; Ocean Temperature &gt; Sea Surface Temperaturekeywords_vocabulary :NASA Global Change Master Directory (GCMD) Science Keywordsstandard_name_vocabulary :NetCDF Climate and Forecast (CF) Metadata Conventionsouthernmost_latitude :-90.0northernmost_latitude :90.0westernmost_longitude :-180.0easternmost_longitude :180.0spatial_resolution :0.01 degreesgeospatial_lat_units :degrees northgeospatial_lat_resolution :0.009999999776geospatial_lon_units :degrees eastgeospatial_lon_resolution :0.009999999776acknowledgment :Please acknowledge the use of these data with the following statement:  These data were provided by JPL under support by NASA MEaSUREs program.creator_name :JPL MUR SST projectcreator_email :ghrsst@podaac.jpl.nasa.govcreator_url :http://mur.jpl.nasa.govproject :NASA Making Earth Science Data Records for Use in Research Environments (MEaSUREs) Programpublisher_name :GHRSST Project Officepublisher_url :http://www.ghrsst.orgpublisher_email :ghrsst-po@nceo.ac.ukprocessing_level :L4cdm_data_type :grid\n\n\nLook at the Analysed SST variable metadata\n\nall_sst = ds.analysed_sst\nall_sst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'analysed_sst' (time: 30, lat: 17999, lon: 36000)&gt;\ndask.array&lt;concatenate, shape=(30, 17999, 36000), dtype=float32, chunksize=(1, 1023, 2047), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * lat      (lat) float32 -89.99 -89.98 -89.97 -89.96 ... 89.97 89.98 89.99\n  * lon      (lon) float32 -180.0 -180.0 -180.0 -180.0 ... 180.0 180.0 180.0\n  * time     (time) datetime64[ns] 2021-09-01T09:00:00 ... 2021-09-30T09:00:00\nAttributes:\n    long_name:      analysed sea surface temperature\n    standard_name:  sea_surface_foundation_temperature\n    units:          kelvin\n    valid_min:      -32767\n    valid_max:      32767\n    comment:        \\\"Final\\\" version using Multi-Resolution Variational Anal...\n    source:         MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, A...xarray.DataArray'analysed_sst'time: 30lat: 17999lon: 36000dask.array&lt;chunksize=(1, 1023, 2047), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n72.42 GiB\n7.99 MiB\n\n\nShape\n(30, 17999, 36000)\n(1, 1023, 2047)\n\n\nCount\n19470 Tasks\n9720 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (3)lat(lat)float32-89.99 -89.98 ... 89.98 89.99long_name :latitudestandard_name :latitudeaxis :Yunits :degrees_northvalid_min :-90.0valid_max :90.0comment :geolocations inherited from the input data without correctionarray([-89.99, -89.98, -89.97, ...,  89.97,  89.98,  89.99], dtype=float32)lon(lon)float32-180.0 -180.0 ... 180.0 180.0long_name :longitudestandard_name :longitudeaxis :Xunits :degrees_eastvalid_min :-180.0valid_max :180.0comment :geolocations inherited from the input data without correctionarray([-179.99, -179.98, -179.97, ...,  179.98,  179.99,  180.  ],\n      dtype=float32)time(time)datetime64[ns]2021-09-01T09:00:00 ... 2021-09-...long_name :reference time of sst fieldstandard_name :timeaxis :Tcomment :Nominal time of analyzed fieldsarray(['2021-09-01T09:00:00.000000000', '2021-09-02T09:00:00.000000000',\n       '2021-09-03T09:00:00.000000000', '2021-09-04T09:00:00.000000000',\n       '2021-09-05T09:00:00.000000000', '2021-09-06T09:00:00.000000000',\n       '2021-09-07T09:00:00.000000000', '2021-09-08T09:00:00.000000000',\n       '2021-09-09T09:00:00.000000000', '2021-09-10T09:00:00.000000000',\n       '2021-09-11T09:00:00.000000000', '2021-09-12T09:00:00.000000000',\n       '2021-09-13T09:00:00.000000000', '2021-09-14T09:00:00.000000000',\n       '2021-09-15T09:00:00.000000000', '2021-09-16T09:00:00.000000000',\n       '2021-09-17T09:00:00.000000000', '2021-09-18T09:00:00.000000000',\n       '2021-09-19T09:00:00.000000000', '2021-09-20T09:00:00.000000000',\n       '2021-09-21T09:00:00.000000000', '2021-09-22T09:00:00.000000000',\n       '2021-09-23T09:00:00.000000000', '2021-09-24T09:00:00.000000000',\n       '2021-09-25T09:00:00.000000000', '2021-09-26T09:00:00.000000000',\n       '2021-09-27T09:00:00.000000000', '2021-09-28T09:00:00.000000000',\n       '2021-09-29T09:00:00.000000000', '2021-09-30T09:00:00.000000000'],\n      dtype='datetime64[ns]')Attributes: (7)long_name :analysed sea surface temperaturestandard_name :sea_surface_foundation_temperatureunits :kelvinvalid_min :-32767valid_max :32767comment :\\\"Final\\\" version using Multi-Resolution Variational Analysis (MRVA) method for interpolationsource :MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, AVHRRMTB_G-NAVO, iQUAM-NOAA/NESDIS, Ice_Conc-OSISAF\n\n\nCreate a dataset / variable that is only our area of interest and view its metadata\n\nsst = ds.analysed_sst.sel(lat=lats, lon=lons)\nsst\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'analysed_sst' (time: 30, lat: 801, lon: 1701)&gt;\ndask.array&lt;getitem, shape=(30, 801, 1701), dtype=float32, chunksize=(1, 601, 1536), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * lat      (lat) float32 41.0 41.01 41.02 41.03 ... 48.97 48.98 48.99 49.0\n  * lon      (lon) float32 -93.0 -92.99 -92.98 -92.97 ... -76.02 -76.01 -76.0\n  * time     (time) datetime64[ns] 2021-09-01T09:00:00 ... 2021-09-30T09:00:00\nAttributes:\n    long_name:      analysed sea surface temperature\n    standard_name:  sea_surface_foundation_temperature\n    units:          kelvin\n    valid_min:      -32767\n    valid_max:      32767\n    comment:        \\\"Final\\\" version using Multi-Resolution Variational Anal...\n    source:         MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, A...xarray.DataArray'analysed_sst'time: 30lat: 801lon: 1701dask.array&lt;chunksize=(1, 200, 1536), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n155.93 MiB\n3.52 MiB\n\n\nShape\n(30, 801, 1701)\n(1, 601, 1536)\n\n\nCount\n19590 Tasks\n120 Chunks\n\n\nType\nfloat32\nnumpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (3)lat(lat)float3241.0 41.01 41.02 ... 48.99 49.0long_name :latitudestandard_name :latitudeaxis :Yunits :degrees_northvalid_min :-90.0valid_max :90.0comment :geolocations inherited from the input data without correctionarray([41.  , 41.01, 41.02, ..., 48.98, 48.99, 49.  ], dtype=float32)lon(lon)float32-93.0 -92.99 ... -76.01 -76.0long_name :longitudestandard_name :longitudeaxis :Xunits :degrees_eastvalid_min :-180.0valid_max :180.0comment :geolocations inherited from the input data without correctionarray([-93.  , -92.99, -92.98, ..., -76.02, -76.01, -76.  ], dtype=float32)time(time)datetime64[ns]2021-09-01T09:00:00 ... 2021-09-...long_name :reference time of sst fieldstandard_name :timeaxis :Tcomment :Nominal time of analyzed fieldsarray(['2021-09-01T09:00:00.000000000', '2021-09-02T09:00:00.000000000',\n       '2021-09-03T09:00:00.000000000', '2021-09-04T09:00:00.000000000',\n       '2021-09-05T09:00:00.000000000', '2021-09-06T09:00:00.000000000',\n       '2021-09-07T09:00:00.000000000', '2021-09-08T09:00:00.000000000',\n       '2021-09-09T09:00:00.000000000', '2021-09-10T09:00:00.000000000',\n       '2021-09-11T09:00:00.000000000', '2021-09-12T09:00:00.000000000',\n       '2021-09-13T09:00:00.000000000', '2021-09-14T09:00:00.000000000',\n       '2021-09-15T09:00:00.000000000', '2021-09-16T09:00:00.000000000',\n       '2021-09-17T09:00:00.000000000', '2021-09-18T09:00:00.000000000',\n       '2021-09-19T09:00:00.000000000', '2021-09-20T09:00:00.000000000',\n       '2021-09-21T09:00:00.000000000', '2021-09-22T09:00:00.000000000',\n       '2021-09-23T09:00:00.000000000', '2021-09-24T09:00:00.000000000',\n       '2021-09-25T09:00:00.000000000', '2021-09-26T09:00:00.000000000',\n       '2021-09-27T09:00:00.000000000', '2021-09-28T09:00:00.000000000',\n       '2021-09-29T09:00:00.000000000', '2021-09-30T09:00:00.000000000'],\n      dtype='datetime64[ns]')Attributes: (7)long_name :analysed sea surface temperaturestandard_name :sea_surface_foundation_temperatureunits :kelvinvalid_min :-32767valid_max :32767comment :\\\"Final\\\" version using Multi-Resolution Variational Analysis (MRVA) method for interpolationsource :MODIS_T-JPL, MODIS_A-JPL, AMSR2-REMSS, AVHRRMTA_G-NAVO, AVHRRMTB_G-NAVO, iQUAM-NOAA/NESDIS, Ice_Conc-OSISAF\n\n\nXArray reads data lazily, i.e. only when our code actually needs it. Up to this point, we haven’t read any data values, only metadata. The next line will force XArray to read the portions of the source files containing our area of interest. Behind the scenes, the eosdis-zarr-store library is ensuring data is fetched as efficiently as possible.\nNote: This line isn’t strictly necessary, since XArray will automatically read the data we need the first time our code tries to use it, but calling this will make sure that we can read the data multiple times later on without re-fetching anything from the source files.\nThis line will take several seconds to complete, but since it is retrieving only about 50 MB of data from 22 GB of source files, several seconds constitutes a significant time, bandwidth, and disk space savings.\n\nsst.load();\n\nNow we can start looking at aggregations across the time dimension. In this case, plot the standard deviation of the temperature at each point to get a visual sense of how much temperatures fluctuate over the course of the month.\n\n# We expect a warning here, from finding the standard deviation of arrays that contain all N/A values.\n# numpy produces N/A for these points, though, which is exactly what we want.\nstdev_sst = sst.std('time')\nstdev_sst.name = 'stdev of analysed_sst [Kelvin]'\nstdev_sst.plot();\n\n/srv/conda/envs/notebook/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1670: RuntimeWarning: Degrees of freedom &lt;= 0 for slice.\n  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\n\n\n\n\n\nInteractive animation of a month of data\nThis section isn’t as important to fully understand. It shows us a way to get an interactive animation to see what we have retrieved so far\nDefine an animation function to plot the ith time step. We need to make sure each plot is using the same color scale, set by vmin and vmax so the animation is consistent\n\nsst_min = sst.min()\nsst_max = sst.max()\n\ndef show_time_step(i):\n    plt.clf()\n    res = sst[i].plot.imshow(vmin=sst_min, vmax=sst_max)\n    return (res,)\n\nRender each time slice once and show it as an HTML animation with interactive controls\n\n#anim = animation.FuncAnimation(plt.gcf(), func=show_time_step, frames=len(sst))\n#display(HTML(anim.to_jshtml()))\n#plt.close()\n\n\n\n\nSupplemental: What’s happening here?\nFor EOSDIS data in the cloud, we have begun producing a metadata sidecar file in a format called DMR++ that extracts all of the information about arrays, variables, and dimensions from data files, as well as the byte offsets in the NetCDF4 file where data can be found. This information is sufficient to let the Zarr library read data from our NetCDF4 files, but it’s in the wrong format. zarr-eosdis-store knows how to fetch the sidecar file and transform it into something the Zarr library understands. Passing it when reading Zarr using XArray or the Zarr library lets these libraries interact with EOSDIS data exactly as if they were Zarr stores in a way that’s more optimal for reading data in the cloud. Beyond this, the zarr-eosdis-store library makes some optimizations in the way it reads data to help make up for situations where the NetCDF4 file is not internally arranged well for cloud-based access patterns."
  },
  {
    "objectID": "projects/hackathon-projects.html",
    "href": "projects/hackathon-projects.html",
    "title": "Hackathon Projects",
    "section": "",
    "text": "We will fill in the projects here at the end of week 1."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects Overview",
    "section": "",
    "text": "The following was borrowed and adapted from the excellent SnowEx Hackathon 2021\nThis section contains everything you need to know about hackweek projects."
  },
  {
    "objectID": "projects/index.html#purpose-of-the-projects",
    "href": "projects/index.html#purpose-of-the-projects",
    "title": "Projects Overview",
    "section": "Purpose of the projects:",
    "text": "Purpose of the projects:\nDuring the course we will be facilitating team hacking sessions in the second half of each day. The purpose of these sessions is for participants to gain hands-on experience in working together on a well-defined problem, in a collaborative space where you can talk things through and get help."
  },
  {
    "objectID": "projects/index.html#what-is-hacking",
    "href": "projects/index.html#what-is-hacking",
    "title": "Projects Overview",
    "section": "What is hacking?",
    "text": "What is hacking?\nHacking is a session of focused, highly collaborative work time – often involving coding – in which the group creates conditions for rapid absorption of new ideas and methods. The word “hack” or “hackathon” has many different interpretations, both positive and negative. Here our intention is to foster the idea of hacking as a fun, interactive and welcoming environment to explore and experiment with computer code."
  },
  {
    "objectID": "projects/index.html#how-will-the-projects-be-conducted",
    "href": "projects/index.html#how-will-the-projects-be-conducted",
    "title": "Projects Overview",
    "section": "How will the projects be conducted?",
    "text": "How will the projects be conducted?\nParticipants are invited to start conversations about projects in the Slack channel 2023-hackweek-projects before and during week one of the course.\n\nIf you have a project idea brewing, please pitch it in this channel. You can tag your proposed teammates if you already have that worked out.\nStart a thread with “Project idea:” and then provide a few sentences. Include whether you are looking for teammates to join this project. Others who are interested can respond in a thread.\nWe welcome a broad range of project topics. People often use project time to dig deeper into concepts introduced in tutorials, to explore problems within their own research, or to advance community data sharing and software building efforts.\nThe course team is here to help you get clear on project ideas and decide on what is possible within 5 days.\n\nAt the end of week 1 of the course we will have a “Pitchfest”” where proposer(s) can pitch their idea. At this time we will finalize the project teams for the week — however we will provide times when team members will move and work with other teams. This kind of ‘cross-pollination’ helps everyone learn and solve problems.\nTeam hacktime will begin on week 2.\nEach team is encouraged to identify a project lead, likely the person who pitched the idea, who has knowledge of the datasets and the specific problem to be explored. But roles can be assigned as the group decides to best fit skills and needs.\nOn the final day of the course, each team will present their work in a series of lightning talks."
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "Our Team",
    "section": "",
    "text": "Links: NOAA Fisheries, webpage\n\n\n\n\nLinks: INCOIS, OceanExpert page\n\n\n\n\nLinks: INCOIS, ResearchGate page"
  },
  {
    "objectID": "team.html#main-instructors-and-support",
    "href": "team.html#main-instructors-and-support",
    "title": "Our Team",
    "section": "",
    "text": "Links: NOAA Fisheries, webpage\n\n\n\n\nLinks: INCOIS, OceanExpert page\n\n\n\n\nLinks: INCOIS, ResearchGate page"
  },
  {
    "objectID": "week1-tutorials/01-AM-intro-to-regional-data.html",
    "href": "week1-tutorials/01-AM-intro-to-regional-data.html",
    "title": "Day 1 AM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week1-tutorials/01-PM-software.html",
    "href": "week1-tutorials/01-PM-software.html",
    "title": "Day 1 PM",
    "section": "",
    "text": "Get everyone set up on the needed software."
  },
  {
    "objectID": "week1-tutorials/02-AM-online-databases.html",
    "href": "week1-tutorials/02-AM-online-databases.html",
    "title": "Day 2 AM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week1-tutorials/02-PM-git-and-github.html",
    "href": "week1-tutorials/02-PM-git-and-github.html",
    "title": "Day 2 PM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week1-tutorials/03-AM-raster-and-nc-in-R.html",
    "href": "week1-tutorials/03-AM-raster-and-nc-in-R.html",
    "title": "Day 3 AM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week1-tutorials/03-PM-spatial-maps-in-R.html",
    "href": "week1-tutorials/03-PM-spatial-maps-in-R.html",
    "title": "Day 3 PM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week1-tutorials/04-AM-spatial-maps-in-R.html",
    "href": "week1-tutorials/04-AM-spatial-maps-in-R.html",
    "title": "Day 4 AM",
    "section": "",
    "text": "In the morning of day 4, participants will work on creating spatial maps for their areas and variables of interest. At the end of the morning, each group (or individual) will share what they have created."
  },
  {
    "objectID": "week1-tutorials/04-PM-intro-to-sdms.html",
    "href": "week1-tutorials/04-PM-intro-to-sdms.html",
    "title": "Day 4 PM",
    "section": "",
    "text": "Introduction and easy examples."
  },
  {
    "objectID": "week1-tutorials/05-AM-guest-lectures.html",
    "href": "week1-tutorials/05-AM-guest-lectures.html",
    "title": "Day 5 AM",
    "section": "",
    "text": "In preparation for week 2, we will have a series of guest lectures on using species distribution models (a type of machine learning) to address fisheries questions.\nLectures will be followed by Q&A with the lecturers."
  },
  {
    "objectID": "week1-tutorials/05-PM-project-brainstorming.html",
    "href": "week1-tutorials/05-PM-project-brainstorming.html",
    "title": "Day 5 PM",
    "section": "",
    "text": "Participants will pitch ideas for projects for week 2. Facilitated brainstorming sessions for each idea."
  },
  {
    "objectID": "week1-tutorials/earthdata.html",
    "href": "week1-tutorials/earthdata.html",
    "title": "Earthdata Login",
    "section": "",
    "text": "The following was borrowed from the excellent SnowEx Hackathon 2021\n\n\nNASA data are stored at one of several Distributed Active Archive Centers (DAACs). If you’re interested in available data for a given area and time of interest, the Earthdata Search portal provides a convenient web interface.\n\n\n\nEach participant will need a login. We will be teaching you ways to programmatically access NASA data from within your Python scripts. You will need to enter your Earthdata username and password in order for this to work.\n\n\n\nIf you do not already have an Earthdata login, then navigate to the Earthdata Login page, a username and password, and then record this somewhere for use during the tutorials:\n\n\n\nearthdata-login\n\n\n\n\n\nIf you use web interfaces to retrieve nasa data such as Earthdata Search you are prompted to login. We will be using software to retrieve data from NASA Servers during the hackweek, so you must store your credentials on the JupyterHub as explained in this documentation. Run the following commands on the JupyterHub in a terminal replacing your Earthdata login username and password:\necho \"machine urs.earthdata.nasa.gov login EARTHDATA_LOGIN password EARTHDATA_PASSWORD\" &gt; ~/.netrc\nchmod 0600 .netrc"
  },
  {
    "objectID": "week1-tutorials/earthdata.html#overview",
    "href": "week1-tutorials/earthdata.html#overview",
    "title": "Earthdata Login",
    "section": "",
    "text": "NASA data are stored at one of several Distributed Active Archive Centers (DAACs). If you’re interested in available data for a given area and time of interest, the Earthdata Search portal provides a convenient web interface."
  },
  {
    "objectID": "week1-tutorials/earthdata.html#why-do-i-need-an-earthdata-login",
    "href": "week1-tutorials/earthdata.html#why-do-i-need-an-earthdata-login",
    "title": "Earthdata Login",
    "section": "",
    "text": "Each participant will need a login. We will be teaching you ways to programmatically access NASA data from within your Python scripts. You will need to enter your Earthdata username and password in order for this to work."
  },
  {
    "objectID": "week1-tutorials/earthdata.html#getting-an-earthdata-login",
    "href": "week1-tutorials/earthdata.html#getting-an-earthdata-login",
    "title": "Earthdata Login",
    "section": "",
    "text": "If you do not already have an Earthdata login, then navigate to the Earthdata Login page, a username and password, and then record this somewhere for use during the tutorials:\n\n\n\nearthdata-login"
  },
  {
    "objectID": "week1-tutorials/earthdata.html#configure-programmatic-access-to-nasa-servers",
    "href": "week1-tutorials/earthdata.html#configure-programmatic-access-to-nasa-servers",
    "title": "Earthdata Login",
    "section": "",
    "text": "If you use web interfaces to retrieve nasa data such as Earthdata Search you are prompted to login. We will be using software to retrieve data from NASA Servers during the hackweek, so you must store your credentials on the JupyterHub as explained in this documentation. Run the following commands on the JupyterHub in a terminal replacing your Earthdata login username and password:\necho \"machine urs.earthdata.nasa.gov login EARTHDATA_LOGIN password EARTHDATA_PASSWORD\" &gt; ~/.netrc\nchmod 0600 .netrc"
  },
  {
    "objectID": "week1-tutorials/github-workflows.html",
    "href": "week1-tutorials/github-workflows.html",
    "title": "GitHub/Jupyter workflows",
    "section": "",
    "text": "We will be live-coding during the tutorials and collaborating during the project hack-time, using GitHub in both cases. Here is how to setup and work for each.\nNote: we’ll be using Git together with GitHub and will talk about them interchangeably."
  },
  {
    "objectID": "week1-tutorials/github-workflows.html#first-time-setup",
    "href": "week1-tutorials/github-workflows.html#first-time-setup",
    "title": "GitHub/Jupyter workflows",
    "section": "First-Time Setup",
    "text": "First-Time Setup\nWe will do these steps together during the first week of the course\n\nFork the Cloudbook repo\nGo to https://github.com/Hackweek-ITCOocean/2023-Cloudbook and fork the repository. This will enable you to follow along with the tutorials.\n\nNote: The term fork means that you are going to copy the project into your own user space in Github"
  },
  {
    "objectID": "week1-tutorials/github-workflows.html#daily-setup",
    "href": "week1-tutorials/github-workflows.html#daily-setup",
    "title": "GitHub/Jupyter workflows",
    "section": "Daily Setup",
    "text": "Daily Setup\n\nGitHub: Pull updates from the Cloudbook repo"
  },
  {
    "objectID": "week1-tutorials/github-workflows.html#adapting-the-tutorials",
    "href": "week1-tutorials/github-workflows.html#adapting-the-tutorials",
    "title": "GitHub/Jupyter workflows",
    "section": "Adapting the tutorials",
    "text": "Adapting the tutorials\nYou will need to work in a different directory than the Cloudbook repo. So if you are using a tutorial as a template, make sure to save a copy and work in the copy in a different folder."
  },
  {
    "objectID": "week1-tutorials/github.html",
    "href": "week1-tutorials/github.html",
    "title": "GitHub",
    "section": "",
    "text": "The following was borrowed from the excellent SnowEx Hackathon 2021\n\n\nGitHub is a hosting service for Git repositories, enabling us to share code across teams in a web environment.\n\n\n\nThere are three reasons you are required to have a GitHub account for the hackweek:\n\nYour GitHub accounts will give you access to the hackweek cloud computing resources\nAll hackweek tutorials will be shared on GitHub\nAll project teams will use GitHub to collaborate and work together on their code\n\n\n\n\nGo to GitHub.\n\n\n\ngithub-signup\n\n\nNext, enter your email address and click on the green ‘Sing up for GitHub’ button. You will need to answer a few required questions in the following dialogs. Be sure to save your password somewhere safe because you will need it later! The steps for doing this are also well documented on this GitHub help page.\n\n\n\nrepos-tab\n\n\nEach repository is a container for a specific subset of material for this event. For example, there is a repository for the public-facing website you used to register for this event {{website_url}}. We’ll also create new repositories for each project."
  },
  {
    "objectID": "week1-tutorials/github.html#what-is-github",
    "href": "week1-tutorials/github.html#what-is-github",
    "title": "GitHub",
    "section": "",
    "text": "GitHub is a hosting service for Git repositories, enabling us to share code across teams in a web environment."
  },
  {
    "objectID": "week1-tutorials/github.html#why-do-i-need-a-github-account",
    "href": "week1-tutorials/github.html#why-do-i-need-a-github-account",
    "title": "GitHub",
    "section": "",
    "text": "There are three reasons you are required to have a GitHub account for the hackweek:\n\nYour GitHub accounts will give you access to the hackweek cloud computing resources\nAll hackweek tutorials will be shared on GitHub\nAll project teams will use GitHub to collaborate and work together on their code"
  },
  {
    "objectID": "week1-tutorials/github.html#creating-a-github-account",
    "href": "week1-tutorials/github.html#creating-a-github-account",
    "title": "GitHub",
    "section": "",
    "text": "Go to GitHub.\n\n\n\ngithub-signup\n\n\nNext, enter your email address and click on the green ‘Sing up for GitHub’ button. You will need to answer a few required questions in the following dialogs. Be sure to save your password somewhere safe because you will need it later! The steps for doing this are also well documented on this GitHub help page.\n\n\n\nrepos-tab\n\n\nEach repository is a container for a specific subset of material for this event. For example, there is a repository for the public-facing website you used to register for this event {{website_url}}. We’ll also create new repositories for each project."
  },
  {
    "objectID": "week1-tutorials/index.html",
    "href": "week1-tutorials/index.html",
    "title": "Week 1 Tutorials",
    "section": "",
    "text": "During week 1, participants will gain experience with the platforms used in collaborative science: GitHub and RMarkdown."
  },
  {
    "objectID": "week1-tutorials/index.html#prerequisites",
    "href": "week1-tutorials/index.html#prerequisites",
    "title": "Week 1 Tutorials",
    "section": "Prerequisites",
    "text": "Prerequisites\nPlease follow the set up prerequisites"
  },
  {
    "objectID": "week1-tutorials/index.html#content",
    "href": "week1-tutorials/index.html#content",
    "title": "Week 1 Tutorials",
    "section": "Content",
    "text": "Content\n\nThe R language and RStudio\nIntro to RStudio\nIntroduction to Git and GitHub"
  },
  {
    "objectID": "week1-tutorials/jupyterhub.html",
    "href": "week1-tutorials/jupyterhub.html",
    "title": "NASA Openscapes Cloud Environment",
    "section": "",
    "text": "Summary of what we’ll cover:"
  },
  {
    "objectID": "week1-tutorials/jupyterhub.html#why-are-we-using-a-cloud-environment",
    "href": "week1-tutorials/jupyterhub.html#why-are-we-using-a-cloud-environment",
    "title": "NASA Openscapes Cloud Environment",
    "section": "Why are we using a cloud environment?",
    "text": "Why are we using a cloud environment?\n“Anyone working with large-scale Earth System data today faces the same general problems:\n\nThe data we want to work with are huge (typical analyses involve several TB at least)\nThe data we need are produced and distributed by many different organizations (NASA, NOAA, ESGF, Copernicus, etc.)\nWe want to apply a wide range of different analysis methodologies to the data, from simple statistics to signal processing to machine learning.\n\nThe community is waking up to the idea that we can’t simply expect scientists to download all this data to their personal computers for processing.”\nRyan Abernathey, Pangeo Project.\n\n\n\nDownload-based workflow. From Abernathey, Ryan (2020): Data Access Modes in Science"
  },
  {
    "objectID": "week1-tutorials/jupyterhub.html#openscapes-hub-and-cloud-infrastructure",
    "href": "week1-tutorials/jupyterhub.html#openscapes-hub-and-cloud-infrastructure",
    "title": "NASA Openscapes Cloud Environment",
    "section": "Openscapes Hub and Cloud Infrastructure",
    "text": "Openscapes Hub and Cloud Infrastructure\nThere is no cloud, it’s someone else’s computer\nGo to Openscapes Jupyter Hub. You will be asked to log in with your GitHub Account\n\n\n\nOpenscapes JupyterHub Login\n\n\nOnce we are logged with our Github account we need to select our server type. There are different hardware configurations for each profile, for the duration of the Hackweek we’ll use small instances, the option at the top.\n\n\n\nMachine Profiles\n\n\nAfter we select our server type and click on start, Jupyterhub will allocate our instance using Amazon Web Services (AWS). This may take several minutes. While we wait, we’ll get set up with GitHub and a brief overview.\n\n\n\nJupyterhub Spawning"
  },
  {
    "objectID": "week1-tutorials/jupyterhub.html#jupyter-ecosystem",
    "href": "week1-tutorials/jupyterhub.html#jupyter-ecosystem",
    "title": "NASA Openscapes Cloud Environment",
    "section": "Jupyter Ecosystem",
    "text": "Jupyter Ecosystem\n\nSource: Project Pythia"
  },
  {
    "objectID": "week1-tutorials/jupyterhub.html#pythonconda-environments",
    "href": "week1-tutorials/jupyterhub.html#pythonconda-environments",
    "title": "NASA Openscapes Cloud Environment",
    "section": "Python/Conda environments",
    "text": "Python/Conda environments\nname: nsidc\nchannels:\n  - conda-forge\ndependencies:\n  - ipykernel\n  - awscli~=1.21.4\n  - requests\n  - pip\n\nHow do I get my code in and out of the Openscapes hub?\nWhen you start your own server you will have access to your own virtual drive space. No other users will be able to see or access your data files. You can easily upload files to your virtual drive space and save files from the hub back to another location, such as GitHub or your own local laptop drive.\nHere we’ll show you how to pull (copy) some files from GitHub into your virtual drive space using git. This will be a common task during the hackweek: at the start of each tutorial we’ll ask you to “fork” (create your own copy of in your GitHub account) and “clone” (make a copy of in a computing environment, such as your local computer or Openscapes instance) the GitHub repository corresponding to the specific tutorial being taught into your Openscapes drive space.\n\n\n\nterminal-button\n\n\nThis will open a new terminal tab in your JupyterLab interface:\n\n\n\nterminal-tab\n\n\nNow you can issue any Linux commands to manage your local file system.\nYou may also upload files from your local system using the upload button (up-pointing arrow) on the top left of the JupyterHub navigation panel. Similarly, you may download files to your local system by right-clicking the file and selecting download (down-pointing arrow).\nSimple, example GitHub/git/local-workspace workflows for getting a tutorial started in your Openscapes instance and working on a group project are provided. The getting started on a tutorial workflow briefly reviews much of the information in this preliminary exercise along with steps for making and saving notes or other changes as you work through the tutorial and keeping it updated with the original, master copy. The basic git workflow for a project serves as a reminder of the git workflow for working on a group project while minimizing code conflicts that could result from multiple people making changes to the same files simultaneously."
  },
  {
    "objectID": "week1-tutorials/jupyterhub.html#how-do-i-end-my-openscapes-session",
    "href": "week1-tutorials/jupyterhub.html#how-do-i-end-my-openscapes-session",
    "title": "NASA Openscapes Cloud Environment",
    "section": "How do I end my Openscapes session?",
    "text": "How do I end my Openscapes session?\nWhen you are finished working for the day it is important to explicitly log out of your Openscapes session. The reason for this is it will save money and is a good habit to be in. When you keep a session active it uses up AWS resources and keeps a series of virtual machines deployed.\nStopping the server happens automatically when you log out, so navigate to “File -&gt; Log Out” and click “Log Out”!\n\n\n\nhub-control-panel-button\n\n\n\nWill I lose all of my work?\nLogging out will NOT cause any of your work to be lost or deleted. It simply shuts down some resources. It would be equivalent to turning off your desktop computer at the end of the day."
  },
  {
    "objectID": "week1-tutorials/jupyterhub.html#references",
    "href": "week1-tutorials/jupyterhub.html#references",
    "title": "NASA Openscapes Cloud Environment",
    "section": "References",
    "text": "References\n\nProject Pythia\nWhy Jupyter is data scientists’ computational notebook of choice\nClosed Platforms vs. Open Architectures for Cloud-Native Earth System Analytics\nIntroduction to Geospatial Concepts\n2i2c user storage\nSnowEX Hackweek"
  },
  {
    "objectID": "week1-tutorials/jupyterhub.html#faq",
    "href": "week1-tutorials/jupyterhub.html#faq",
    "title": "NASA Openscapes Cloud Environment",
    "section": "FAQ",
    "text": "FAQ\nfrom participants during our first Clinic\nI have an empty ‘shared’ folder. That’s expected. There shouldn’t be anything in the ‘shared/’ folder\nAfter the 3 months are up, what do we do with our work on the server? You’ll have them since you can back everything up with GitHub. We can follow up with more details of what happens on the 2i2c side\nCan we use Matlab with JupyterHub? You can also use Octave kernel as a Matlab replacement. It is open source and free. If you want to integrate Matlab, there is a project to do so jupyter-matlab-proxy\nWhy do we have the same home directory as /home/jovyan? /home/jovyan is the default home directory for ‘jupyter’ based images/dockers. It is the historic home directory for Jupyter deployments.\n/home/jovyan is the default home directory for jupyter-based deployments\nCan other users see the .git-credentials file in my /home/jovyan folder? No, other users can not see your creds\nHow to exit 2i2c’s terminal text editor? esc to get to the command, and then :w to save, :q to quit."
  },
  {
    "objectID": "week1-tutorials/notebooks.html",
    "href": "week1-tutorials/notebooks.html",
    "title": "RMarkdown, R, Git",
    "section": "",
    "text": "In this session, we will provide a brief introduction to:\n\nCommand line (terminal/shell)\nVersion Control (code management using git)\nProgramming in Python (using Jupyter Notebook)\nGeospatial Fundamentals (optional, self-study)\n\nYou will need a working knowledge of git and terminal for this hackathon. We will provide an overview of these topics and also share resources for self-paced learning."
  },
  {
    "objectID": "week1-tutorials/notebooks.html#summary",
    "href": "week1-tutorials/notebooks.html#summary",
    "title": "RMarkdown, R, Git",
    "section": "",
    "text": "In this session, we will provide a brief introduction to:\n\nCommand line (terminal/shell)\nVersion Control (code management using git)\nProgramming in Python (using Jupyter Notebook)\nGeospatial Fundamentals (optional, self-study)\n\nYou will need a working knowledge of git and terminal for this hackathon. We will provide an overview of these topics and also share resources for self-paced learning."
  },
  {
    "objectID": "week1-tutorials/notebooks.html#introduction-command-line-terminalshell",
    "href": "week1-tutorials/notebooks.html#introduction-command-line-terminalshell",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Command Line (Terminal/Shell)",
    "text": "Introduction :: Command Line (Terminal/Shell)\n\nShell Basics\n\nWhat is Terminal or Shell?\nNavigating Files and Directories\nWorking with Files and Directories\n\n\n\nShell: More Details\nDetailed self-paced lesson on shell: Shell Lesson from Software Carpentry"
  },
  {
    "objectID": "week1-tutorials/notebooks.html#introduction-version-control-git-and-github",
    "href": "week1-tutorials/notebooks.html#introduction-version-control-git-and-github",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Version Control (Git and Github)",
    "text": "Introduction :: Version Control (Git and Github)\n\nWhat is version control, git, github, and how to set it up?\nVersion control is managing and tracking changes to your documents (program source code, images, websites, data files, etc.). git is a popular tool used for version control of software code. github.com is popular platform that provides remote server hosting for git repositories. A repository is a collection of various files that you are tracking for changes and versions (think of it as a directory with files that are being tracked for changes, using git for taking snapshots of versions as you are developing).\nThis section is a step-by-step guide to set up git on your 2i2c JupyterHub instance (referred to as 2i2c JupyterHub in these instruction). We will also configure git to use your github.com account for managing your repositories hosted on github.com. There are 5 main steps with substeps, includes instruction for addressing github’s new approach for token authentication.\n\n\nStep 1: Create a github account\nTo complete the setup, you will need an account on github.com. If you don’t have an account, please visit github.com, create an account (free) and come back to this guide for setting up git.\n\n\nStep 2: Fork a repository\nA fork is a copy of a repository from another github account (for example NASA-Openscapes account) to your github account (for example, my account virdi) that then you have permission to edit. To help you finish this setup correctly, we have created a demo repository on Openscapes github account named check_github_setup. You can fork this repository into your github account following these steps:\n\nLog in to your github.com account\nGo to the demo repository at NASA-Openscapes github\n\nClick on the fork icon in the top right corner, as shown in the image below and click your user name if prompted to do so\n\n\n\n\nStep 3: Clone the repository that you just forked\nNow you have a fork of the demo repository in your github account that we can clone it in your 2i2c instance. In the code below, commands beginning with git is a git command for version control and synching; commands that don’t start with git are bash/linux/command line commands.\n\nStart your 2i2c JupyterHub and open a terminal\nFile &gt;&gt; New &gt;&gt; Terminal\nMake sure you are in your home directory by usingpwd command and verifying the output as below\n/home/jovyan\n\nConfigure git with your name and email address.\ngit config --global user.name \"Makhan Virdi\"\ngit config --global user.email \"Makhan.Virdi@gmail.com\"\nNote: This name and email could be different from your github.com credentials. Remember git is a program that keeps track of your changes locally (on 2i2c JupyterHub or your own computer) and github.com is a platform to host your repositories. However, since your changes are tracked by git, the email/name used in git configuration will show up next to your contributions on github.com when you push your repository to github.com (git push is discussed in a later step).\nConfigure git to store your github credentials to avoid having to enter your github username and token each time you push changes to your repository(in Step 5, we will describe how to use github token instead of a password)\ngit config --global credential.helper store\nCopy link for the demo repository from your github account. Click the green “Code” button and copy the link as shown.\n\nClone the repository using git clone command in the terminal\nTo clone a repository from github, copy the link for the repository (previous step) and use git clone:\ngit clone https://github.com/YOUR-GITHUB-USERNAME/check_github_setup\nNote: Replace YOUR-GITHUB-USERNAME here with your github.com username. For example, it is virdi for my github.com account as seen in this image.\n\nUse ls (list files) to verify the existence of the repository that you just cloned\n\nChange directory to the cloned repository using cd check_github_setup and check the current directory using pwd command (present working directory)\n\nCheck status of your git repository to confirm git set up using git status\n\nYou are all set with using git on your 2i2c JupyterHub! But the collaborative power of git through github needs some additional setup.\nIn the next step, we will create a new file in this repository, track changes to this file, and link it with your github.com account.\n\n\n\nStep 4. Creating new file and tracking changes\n\nIn the left panel on your 2i2c JupyterHub, click on the “directory” icon and then double click on “check_github_setup” directory.\n\n\nOnce you are in the check_github_setup directory, create a new file using the text editor in your 2i2c JupyterHub (File &gt;&gt; New &gt;&gt; Text File).\n\nName the file lastname.txt. For example, virdi.txt for me (use your last name). Add some content to this file (for example, I added this to my virdi.txt file: my last name is virdi).\n\nNow you should have a new file (lastname.txt) in the git repository directory check_github_setup\nCheck if git can see that you have added a new file using git status. Git reports that you have a new file that is not tracked by git yet, and suggests adding that file to the git tracking system.\n\nAs seen in this image, git suggests adding that file so it can be tracked for changes. You can add file to git for tracking changes using git add. Then, you can commit changes to this file’s content using git commit as shown in the image.\ngit add virdi.txt\ngit status\ngit commit -m \"adding a new file\"\ngit status\n\nAs seen in the image above, git is suggesting to push the change that you just committed to the remote server at github.com (so that your collaborators can also see what changes you made).\nNote: DO NOT execute push yet. Before we push to github.com, let’s configure git further and store our github.com credentials to avoid entering the credentials every time we invoke git push. For doing so, we need to create a token on github.com to be used in place of your github.com password.\n\n\n\nStep 5. Create access token on github.com\n\nGo to your github account and create a new “personal access token”: https://github.com/settings/tokens/new\n\n\n\nGenerate Personal Access Token on github.com\n\n\nEnter a description in “Note” field as seen above, select “repo” checkbox, and scroll to the bottom and click the green button “Generate Token”. Once generated, copy the token (or save it in a text file for reference).\nIMPORTANT: You will see this token only once, so be sure to copy this. If you do not copy your token at this stage, you will need to generate a new token.\n\nTo push (transfer) your changes to github, use git push in terminal. It requires you to enter your github credentials. You will be prompted to enter your github username and “password”. When prompted for your “password”, DO NOT use your github password, use the github token that was copied in the previous step.\ngit push\n\nNote: When you paste your token in the terminal window, windows users will press Ctrl+V and mac os users will press Cmd+V. If it does not work, try generating another token and use the copy icon next to the token to copy the token. Then, paste using your computer’s keyboard shortcut for paste.\nNow your password is stored in ~/.git-credentials and you will not be prompted again unless the Github token expires. You can check the presence of this git-credentials file using Terminal. Here the ~ character represents your home directory (/home/jovyan/).\nls -la ~\nThe output looks like this:\ndrwxr-xr-x 13 jovyan jovyan 6144 Oct 22 17:35 .\ndrwxr-xr-x  1 root   root   4096 Oct  4 16:21 ..\n-rw-------  1 jovyan jovyan 1754 Oct 29 18:30 .bash_history\ndrwxr-xr-x  4 jovyan jovyan 6144 Oct 29 16:38 .config\n-rw-------  1 jovyan jovyan   66 Oct 22 17:35 .git-credentials\n-rw-r--r--  1 jovyan jovyan   84 Oct 22 17:14 .gitconfig\ndrwxr-xr-x 10 jovyan jovyan 6144 Oct 21 16:19 2021-Cloud-Hackathon\nYou can also verify your git configuration\n(notebook) jovyan@jupyter-virdi:~$ git config -l\nThe output should have credential.helper = store:\nuser.email        = Makhan.Virdi@gmail.com\nuser.name         = Makhan Virdi\ncredential.helper = store\n\nNow we are all set to collaborate with github on the JupyterHub during the Cloud Hackathon!\n\n\nSummary: Git Commands\n\nCommonly used git commands (modified from source)\n\n\nGit Command\nDescription\n\n\n\n\ngit status\nShows the current state of the repository: the current working branch, files in the staging area, etc.\n\n\ngit add\nAdds a new, previously untracked file to version control and marks already tracked files to be committed with the next commit\n\n\ngit commit\nSaves the current state of the repository and creates an entry in the log\n\n\ngit log\nShows the history for the repository\n\n\ngit diff\nShows content differences between commits, branches, individual files and more\n\n\ngit clone\nCopies a repository to your local environment, including all the history\n\n\ngit pull\nGets the latest changes of a previously cloned repository\n\n\ngit push\nPushes your local changes to the remote repository, sharing them with others\n\n\n\n\n\nGit: More Details\nLesson: For a more detailed self-paced lesson on git, visit Git Lesson from Software Carpentry\nCheatsheet: Frequently used git commands\nDangit, Git!?!: If you are stuck after a git mishap, there are ready-made solutions to common problems at Dangit, Git!?!\n\n\nCloning our repository using the git Jupyter lab extension.\nIf we’re already familiar with git commands and feel more confortable using a GUI our Jupyterhub deployment comes with a git extension. This plugin allows us to operate with git using a simple user interface.\nFor example we can clone our repository using the extension.\n\n\n\ngit extension"
  },
  {
    "objectID": "week1-tutorials/notebooks.html#introduction-programming-in-python",
    "href": "week1-tutorials/notebooks.html#introduction-programming-in-python",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Programming in Python",
    "text": "Introduction :: Programming in Python"
  },
  {
    "objectID": "week1-tutorials/notebooks.html#introduction-programming-in-python-1",
    "href": "week1-tutorials/notebooks.html#introduction-programming-in-python-1",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Programming in Python",
    "text": "Introduction :: Programming in Python\nSwitch to Jupyter Notebook for an introduction to programming in Python\n\nVariables (and mathematical operations)\nData Structures (list, tuple, dict)\nFlow Control using loops (for, while)\nConditionals (if, else, elif)\nFunctions\nErrors and Exceptions (understanding and handling errors)\nUsing modules (libraries, packages)\n\npandas: high-performance, easy-to-use data structures and data analysis tools\nrioxarray: based on the rasterio package for working with rasters and xarray\n\n\n\nPython Learning Resources\nSelf-paced lesson on Programming with Python from Software Carpentry"
  },
  {
    "objectID": "week1-tutorials/notebooks.html#introduction-geospatial-fundamentals-optional",
    "href": "week1-tutorials/notebooks.html#introduction-geospatial-fundamentals-optional",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Geospatial Fundamentals (Optional)",
    "text": "Introduction :: Geospatial Fundamentals (Optional)\nDetailed self-paced lesson on Fundamentals of Geospatial Raster and Vector Data with Python from Data Carpentry\nThe end!"
  },
  {
    "objectID": "week1-tutorials/r-and-python.html",
    "href": "week1-tutorials/r-and-python.html",
    "title": "R and Python",
    "section": "",
    "text": "It is important that you come into the course with a basic understanding of R. There are many free courses.\n\nIf you have never used R or RStudio and have not done much programming, start with this 4 hour course: Basics of R and installing RStudio https://www.udemy.com/course/r-basics/\nIf you know the basics of R but have never done modeling, then you can start with this 2.5 hour course that covers basic linear regression with R and plotting with ggplot2: https://www.udemy.com/course/machlearn1\nFor a longer free course, you can do this one. Note this is 20 hours. You do NOT need to do this whole course before the hackweek! https://www.codecademy.com/learn/learn-r\nOne of the best free R courses is https://www.coursera.org/learn/r-programming. You can see the lectures for free. Make sure to click AUDIT when it asks you to sign up for a 7-day trial. You do not need to sign up for anything to go through the material."
  },
  {
    "objectID": "week1-tutorials/r-and-python.html#introduction-programming-in-r",
    "href": "week1-tutorials/r-and-python.html#introduction-programming-in-r",
    "title": "R and Python",
    "section": "",
    "text": "It is important that you come into the course with a basic understanding of R. There are many free courses.\n\nIf you have never used R or RStudio and have not done much programming, start with this 4 hour course: Basics of R and installing RStudio https://www.udemy.com/course/r-basics/\nIf you know the basics of R but have never done modeling, then you can start with this 2.5 hour course that covers basic linear regression with R and plotting with ggplot2: https://www.udemy.com/course/machlearn1\nFor a longer free course, you can do this one. Note this is 20 hours. You do NOT need to do this whole course before the hackweek! https://www.codecademy.com/learn/learn-r\nOne of the best free R courses is https://www.coursera.org/learn/r-programming. You can see the lectures for free. Make sure to click AUDIT when it asks you to sign up for a 7-day trial. You do not need to sign up for anything to go through the material."
  },
  {
    "objectID": "week1-tutorials/r-and-python.html#introduction-programming-in-python",
    "href": "week1-tutorials/r-and-python.html#introduction-programming-in-python",
    "title": "R and Python",
    "section": "Introduction :: Programming in Python",
    "text": "Introduction :: Programming in Python\nSwitch to Jupyter Notebook for an introduction to programming in Python\n\nVariables (and mathematical operations)\nData Structures (list, tuple, dict)\nFlow Control using loops (for, while)\nConditionals (if, else, elif)\nFunctions\nErrors and Exceptions (understanding and handling errors)\nUsing modules (libraries, packages)\n\npandas: high-performance, easy-to-use data structures and data analysis tools\nrioxarray: based on the rasterio package for working with rasters and xarray\n\n\n\nPython Learning Resources\nSelf-paced lesson on Programming with Python from Software Carpentry"
  },
  {
    "objectID": "week1-tutorials/r-and-python.html#introduction-geospatial-fundamentals-optional",
    "href": "week1-tutorials/r-and-python.html#introduction-geospatial-fundamentals-optional",
    "title": "R and Python",
    "section": "Introduction :: Geospatial Fundamentals (Optional)",
    "text": "Introduction :: Geospatial Fundamentals (Optional)\nDetailed self-paced lesson on Fundamentals of Geospatial Raster and Vector Data with Python from Data Carpentry\nThe end!"
  },
  {
    "objectID": "week2-tutorials/01-AM-preparing-data.html",
    "href": "week2-tutorials/01-AM-preparing-data.html",
    "title": "Day 1 AM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week2-tutorials/01-PM-project-pitches.html",
    "href": "week2-tutorials/01-PM-project-pitches.html",
    "title": "Day 1 PM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week2-tutorials/02-AM-sdm-part1.html",
    "href": "week2-tutorials/02-AM-sdm-part1.html",
    "title": "Day 2 AM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week2-tutorials/03-AM-sdm-part2.html",
    "href": "week2-tutorials/03-AM-sdm-part2.html",
    "title": "Day 3 AM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week2-tutorials/04-AM-guest-lectures.html",
    "href": "week2-tutorials/04-AM-guest-lectures.html",
    "title": "Day 4 AM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week2-tutorials/05-PM-project-presentations.html",
    "href": "week2-tutorials/05-PM-project-presentations.html",
    "title": "Day 5 PM",
    "section": "",
    "text": "Template"
  },
  {
    "objectID": "week2-tutorials/earthdata.html",
    "href": "week2-tutorials/earthdata.html",
    "title": "Earthdata Login",
    "section": "",
    "text": "The following was borrowed from the excellent SnowEx Hackathon 2021\n\n\nNASA data are stored at one of several Distributed Active Archive Centers (DAACs). If you’re interested in available data for a given area and time of interest, the Earthdata Search portal provides a convenient web interface.\n\n\n\nEach participant will need a login. We will be teaching you ways to programmatically access NASA data from within your Python scripts. You will need to enter your Earthdata username and password in order for this to work.\n\n\n\nIf you do not already have an Earthdata login, then navigate to the Earthdata Login page, a username and password, and then record this somewhere for use during the tutorials:\n\n\n\nearthdata-login\n\n\n\n\n\nIf you use web interfaces to retrieve nasa data such as Earthdata Search you are prompted to login. We will be using software to retrieve data from NASA Servers during the hackweek, so you must store your credentials on the JupyterHub as explained in this documentation. Run the following commands on the JupyterHub in a terminal replacing your Earthdata login username and password:\necho \"machine urs.earthdata.nasa.gov login EARTHDATA_LOGIN password EARTHDATA_PASSWORD\" &gt; ~/.netrc\nchmod 0600 .netrc"
  },
  {
    "objectID": "week2-tutorials/earthdata.html#overview",
    "href": "week2-tutorials/earthdata.html#overview",
    "title": "Earthdata Login",
    "section": "",
    "text": "NASA data are stored at one of several Distributed Active Archive Centers (DAACs). If you’re interested in available data for a given area and time of interest, the Earthdata Search portal provides a convenient web interface."
  },
  {
    "objectID": "week2-tutorials/earthdata.html#why-do-i-need-an-earthdata-login",
    "href": "week2-tutorials/earthdata.html#why-do-i-need-an-earthdata-login",
    "title": "Earthdata Login",
    "section": "",
    "text": "Each participant will need a login. We will be teaching you ways to programmatically access NASA data from within your Python scripts. You will need to enter your Earthdata username and password in order for this to work."
  },
  {
    "objectID": "week2-tutorials/earthdata.html#getting-an-earthdata-login",
    "href": "week2-tutorials/earthdata.html#getting-an-earthdata-login",
    "title": "Earthdata Login",
    "section": "",
    "text": "If you do not already have an Earthdata login, then navigate to the Earthdata Login page, a username and password, and then record this somewhere for use during the tutorials:\n\n\n\nearthdata-login"
  },
  {
    "objectID": "week2-tutorials/earthdata.html#configure-programmatic-access-to-nasa-servers",
    "href": "week2-tutorials/earthdata.html#configure-programmatic-access-to-nasa-servers",
    "title": "Earthdata Login",
    "section": "",
    "text": "If you use web interfaces to retrieve nasa data such as Earthdata Search you are prompted to login. We will be using software to retrieve data from NASA Servers during the hackweek, so you must store your credentials on the JupyterHub as explained in this documentation. Run the following commands on the JupyterHub in a terminal replacing your Earthdata login username and password:\necho \"machine urs.earthdata.nasa.gov login EARTHDATA_LOGIN password EARTHDATA_PASSWORD\" &gt; ~/.netrc\nchmod 0600 .netrc"
  },
  {
    "objectID": "week2-tutorials/github-workflows.html",
    "href": "week2-tutorials/github-workflows.html",
    "title": "GitHub/Jupyter workflows",
    "section": "",
    "text": "We will be live-coding during the tutorials and collaborating during the project hack-time, using GitHub in both cases. Here is how to setup and work for each.\nNote: we’ll be using Git together with GitHub and will talk about them interchangeably."
  },
  {
    "objectID": "week2-tutorials/github-workflows.html#first-time-setup",
    "href": "week2-tutorials/github-workflows.html#first-time-setup",
    "title": "GitHub/Jupyter workflows",
    "section": "First-Time Setup",
    "text": "First-Time Setup\nWe will do these steps together during the first week of the course\n\nFork the Cloudbook repo\nGo to https://github.com/Hackweek-ITCOocean/2023-Cloudbook and fork the repository. This will enable you to follow along with the tutorials.\n\nNote: The term fork means that you are going to copy the project into your own user space in Github"
  },
  {
    "objectID": "week2-tutorials/github-workflows.html#daily-setup",
    "href": "week2-tutorials/github-workflows.html#daily-setup",
    "title": "GitHub/Jupyter workflows",
    "section": "Daily Setup",
    "text": "Daily Setup\n\nGitHub: Pull updates from the Cloudbook repo"
  },
  {
    "objectID": "week2-tutorials/github-workflows.html#adapting-the-tutorials",
    "href": "week2-tutorials/github-workflows.html#adapting-the-tutorials",
    "title": "GitHub/Jupyter workflows",
    "section": "Adapting the tutorials",
    "text": "Adapting the tutorials\nYou will need to work in a different directory than the Cloudbook repo. So if you are using a tutorial as a template, make sure to save a copy and work in the copy in a different folder."
  },
  {
    "objectID": "week2-tutorials/github.html",
    "href": "week2-tutorials/github.html",
    "title": "GitHub",
    "section": "",
    "text": "The following was borrowed from the excellent SnowEx Hackathon 2021\n\n\nGitHub is a hosting service for Git repositories, enabling us to share code across teams in a web environment.\n\n\n\nThere are three reasons you are required to have a GitHub account for the hackweek:\n\nYour GitHub accounts will give you access to the hackweek cloud computing resources\nAll hackweek tutorials will be shared on GitHub\nAll project teams will use GitHub to collaborate and work together on their code\n\n\n\n\nGo to GitHub.\n\n\n\ngithub-signup\n\n\nNext, enter your email address and click on the green ‘Sing up for GitHub’ button. You will need to answer a few required questions in the following dialogs. Be sure to save your password somewhere safe because you will need it later! The steps for doing this are also well documented on this GitHub help page.\n\n\n\nrepos-tab\n\n\nEach repository is a container for a specific subset of material for this event. For example, there is a repository for the public-facing website you used to register for this event {{website_url}}. We’ll also create new repositories for each project."
  },
  {
    "objectID": "week2-tutorials/github.html#what-is-github",
    "href": "week2-tutorials/github.html#what-is-github",
    "title": "GitHub",
    "section": "",
    "text": "GitHub is a hosting service for Git repositories, enabling us to share code across teams in a web environment."
  },
  {
    "objectID": "week2-tutorials/github.html#why-do-i-need-a-github-account",
    "href": "week2-tutorials/github.html#why-do-i-need-a-github-account",
    "title": "GitHub",
    "section": "",
    "text": "There are three reasons you are required to have a GitHub account for the hackweek:\n\nYour GitHub accounts will give you access to the hackweek cloud computing resources\nAll hackweek tutorials will be shared on GitHub\nAll project teams will use GitHub to collaborate and work together on their code"
  },
  {
    "objectID": "week2-tutorials/github.html#creating-a-github-account",
    "href": "week2-tutorials/github.html#creating-a-github-account",
    "title": "GitHub",
    "section": "",
    "text": "Go to GitHub.\n\n\n\ngithub-signup\n\n\nNext, enter your email address and click on the green ‘Sing up for GitHub’ button. You will need to answer a few required questions in the following dialogs. Be sure to save your password somewhere safe because you will need it later! The steps for doing this are also well documented on this GitHub help page.\n\n\n\nrepos-tab\n\n\nEach repository is a container for a specific subset of material for this event. For example, there is a repository for the public-facing website you used to register for this event {{website_url}}. We’ll also create new repositories for each project."
  },
  {
    "objectID": "week2-tutorials/index.html",
    "href": "week2-tutorials/index.html",
    "title": "Week 1 Tutorials",
    "section": "",
    "text": "During week 1, participants will gain experience with the platforms used in collaborative science: GitHub and RMarkdown."
  },
  {
    "objectID": "week2-tutorials/index.html#prerequisites",
    "href": "week2-tutorials/index.html#prerequisites",
    "title": "Week 1 Tutorials",
    "section": "Prerequisites",
    "text": "Prerequisites\nPlease follow the set up prerequisites"
  },
  {
    "objectID": "week2-tutorials/index.html#content",
    "href": "week2-tutorials/index.html#content",
    "title": "Week 1 Tutorials",
    "section": "Content",
    "text": "Content\n\nThe R language and RStudio\nIntro to RStudio\nIntroduction to Git and GitHub"
  },
  {
    "objectID": "week2-tutorials/jupyterhub.html",
    "href": "week2-tutorials/jupyterhub.html",
    "title": "NASA Openscapes Cloud Environment",
    "section": "",
    "text": "Summary of what we’ll cover:"
  },
  {
    "objectID": "week2-tutorials/jupyterhub.html#why-are-we-using-a-cloud-environment",
    "href": "week2-tutorials/jupyterhub.html#why-are-we-using-a-cloud-environment",
    "title": "NASA Openscapes Cloud Environment",
    "section": "Why are we using a cloud environment?",
    "text": "Why are we using a cloud environment?\n“Anyone working with large-scale Earth System data today faces the same general problems:\n\nThe data we want to work with are huge (typical analyses involve several TB at least)\nThe data we need are produced and distributed by many different organizations (NASA, NOAA, ESGF, Copernicus, etc.)\nWe want to apply a wide range of different analysis methodologies to the data, from simple statistics to signal processing to machine learning.\n\nThe community is waking up to the idea that we can’t simply expect scientists to download all this data to their personal computers for processing.”\nRyan Abernathey, Pangeo Project.\n\n\n\nDownload-based workflow. From Abernathey, Ryan (2020): Data Access Modes in Science"
  },
  {
    "objectID": "week2-tutorials/jupyterhub.html#openscapes-hub-and-cloud-infrastructure",
    "href": "week2-tutorials/jupyterhub.html#openscapes-hub-and-cloud-infrastructure",
    "title": "NASA Openscapes Cloud Environment",
    "section": "Openscapes Hub and Cloud Infrastructure",
    "text": "Openscapes Hub and Cloud Infrastructure\nThere is no cloud, it’s someone else’s computer\nGo to Openscapes Jupyter Hub. You will be asked to log in with your GitHub Account\n\n\n\nOpenscapes JupyterHub Login\n\n\nOnce we are logged with our Github account we need to select our server type. There are different hardware configurations for each profile, for the duration of the Hackweek we’ll use small instances, the option at the top.\n\n\n\nMachine Profiles\n\n\nAfter we select our server type and click on start, Jupyterhub will allocate our instance using Amazon Web Services (AWS). This may take several minutes. While we wait, we’ll get set up with GitHub and a brief overview.\n\n\n\nJupyterhub Spawning"
  },
  {
    "objectID": "week2-tutorials/jupyterhub.html#jupyter-ecosystem",
    "href": "week2-tutorials/jupyterhub.html#jupyter-ecosystem",
    "title": "NASA Openscapes Cloud Environment",
    "section": "Jupyter Ecosystem",
    "text": "Jupyter Ecosystem\n\nSource: Project Pythia"
  },
  {
    "objectID": "week2-tutorials/jupyterhub.html#pythonconda-environments",
    "href": "week2-tutorials/jupyterhub.html#pythonconda-environments",
    "title": "NASA Openscapes Cloud Environment",
    "section": "Python/Conda environments",
    "text": "Python/Conda environments\nname: nsidc\nchannels:\n  - conda-forge\ndependencies:\n  - ipykernel\n  - awscli~=1.21.4\n  - requests\n  - pip\n\nHow do I get my code in and out of the Openscapes hub?\nWhen you start your own server you will have access to your own virtual drive space. No other users will be able to see or access your data files. You can easily upload files to your virtual drive space and save files from the hub back to another location, such as GitHub or your own local laptop drive.\nHere we’ll show you how to pull (copy) some files from GitHub into your virtual drive space using git. This will be a common task during the hackweek: at the start of each tutorial we’ll ask you to “fork” (create your own copy of in your GitHub account) and “clone” (make a copy of in a computing environment, such as your local computer or Openscapes instance) the GitHub repository corresponding to the specific tutorial being taught into your Openscapes drive space.\n\n\n\nterminal-button\n\n\nThis will open a new terminal tab in your JupyterLab interface:\n\n\n\nterminal-tab\n\n\nNow you can issue any Linux commands to manage your local file system.\nYou may also upload files from your local system using the upload button (up-pointing arrow) on the top left of the JupyterHub navigation panel. Similarly, you may download files to your local system by right-clicking the file and selecting download (down-pointing arrow).\nSimple, example GitHub/git/local-workspace workflows for getting a tutorial started in your Openscapes instance and working on a group project are provided. The getting started on a tutorial workflow briefly reviews much of the information in this preliminary exercise along with steps for making and saving notes or other changes as you work through the tutorial and keeping it updated with the original, master copy. The basic git workflow for a project serves as a reminder of the git workflow for working on a group project while minimizing code conflicts that could result from multiple people making changes to the same files simultaneously."
  },
  {
    "objectID": "week2-tutorials/jupyterhub.html#how-do-i-end-my-openscapes-session",
    "href": "week2-tutorials/jupyterhub.html#how-do-i-end-my-openscapes-session",
    "title": "NASA Openscapes Cloud Environment",
    "section": "How do I end my Openscapes session?",
    "text": "How do I end my Openscapes session?\nWhen you are finished working for the day it is important to explicitly log out of your Openscapes session. The reason for this is it will save money and is a good habit to be in. When you keep a session active it uses up AWS resources and keeps a series of virtual machines deployed.\nStopping the server happens automatically when you log out, so navigate to “File -&gt; Log Out” and click “Log Out”!\n\n\n\nhub-control-panel-button\n\n\n\nWill I lose all of my work?\nLogging out will NOT cause any of your work to be lost or deleted. It simply shuts down some resources. It would be equivalent to turning off your desktop computer at the end of the day."
  },
  {
    "objectID": "week2-tutorials/jupyterhub.html#references",
    "href": "week2-tutorials/jupyterhub.html#references",
    "title": "NASA Openscapes Cloud Environment",
    "section": "References",
    "text": "References\n\nProject Pythia\nWhy Jupyter is data scientists’ computational notebook of choice\nClosed Platforms vs. Open Architectures for Cloud-Native Earth System Analytics\nIntroduction to Geospatial Concepts\n2i2c user storage\nSnowEX Hackweek"
  },
  {
    "objectID": "week2-tutorials/jupyterhub.html#faq",
    "href": "week2-tutorials/jupyterhub.html#faq",
    "title": "NASA Openscapes Cloud Environment",
    "section": "FAQ",
    "text": "FAQ\nfrom participants during our first Clinic\nI have an empty ‘shared’ folder. That’s expected. There shouldn’t be anything in the ‘shared/’ folder\nAfter the 3 months are up, what do we do with our work on the server? You’ll have them since you can back everything up with GitHub. We can follow up with more details of what happens on the 2i2c side\nCan we use Matlab with JupyterHub? You can also use Octave kernel as a Matlab replacement. It is open source and free. If you want to integrate Matlab, there is a project to do so jupyter-matlab-proxy\nWhy do we have the same home directory as /home/jovyan? /home/jovyan is the default home directory for ‘jupyter’ based images/dockers. It is the historic home directory for Jupyter deployments.\n/home/jovyan is the default home directory for jupyter-based deployments\nCan other users see the .git-credentials file in my /home/jovyan folder? No, other users can not see your creds\nHow to exit 2i2c’s terminal text editor? esc to get to the command, and then :w to save, :q to quit."
  },
  {
    "objectID": "week2-tutorials/notebooks.html",
    "href": "week2-tutorials/notebooks.html",
    "title": "RMarkdown, R, Git",
    "section": "",
    "text": "In this session, we will provide a brief introduction to:\n\nCommand line (terminal/shell)\nVersion Control (code management using git)\nProgramming in Python (using Jupyter Notebook)\nGeospatial Fundamentals (optional, self-study)\n\nYou will need a working knowledge of git and terminal for this hackathon. We will provide an overview of these topics and also share resources for self-paced learning."
  },
  {
    "objectID": "week2-tutorials/notebooks.html#summary",
    "href": "week2-tutorials/notebooks.html#summary",
    "title": "RMarkdown, R, Git",
    "section": "",
    "text": "In this session, we will provide a brief introduction to:\n\nCommand line (terminal/shell)\nVersion Control (code management using git)\nProgramming in Python (using Jupyter Notebook)\nGeospatial Fundamentals (optional, self-study)\n\nYou will need a working knowledge of git and terminal for this hackathon. We will provide an overview of these topics and also share resources for self-paced learning."
  },
  {
    "objectID": "week2-tutorials/notebooks.html#introduction-command-line-terminalshell",
    "href": "week2-tutorials/notebooks.html#introduction-command-line-terminalshell",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Command Line (Terminal/Shell)",
    "text": "Introduction :: Command Line (Terminal/Shell)\n\nShell Basics\n\nWhat is Terminal or Shell?\nNavigating Files and Directories\nWorking with Files and Directories\n\n\n\nShell: More Details\nDetailed self-paced lesson on shell: Shell Lesson from Software Carpentry"
  },
  {
    "objectID": "week2-tutorials/notebooks.html#introduction-version-control-git-and-github",
    "href": "week2-tutorials/notebooks.html#introduction-version-control-git-and-github",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Version Control (Git and Github)",
    "text": "Introduction :: Version Control (Git and Github)\n\nWhat is version control, git, github, and how to set it up?\nVersion control is managing and tracking changes to your documents (program source code, images, websites, data files, etc.). git is a popular tool used for version control of software code. github.com is popular platform that provides remote server hosting for git repositories. A repository is a collection of various files that you are tracking for changes and versions (think of it as a directory with files that are being tracked for changes, using git for taking snapshots of versions as you are developing).\nThis section is a step-by-step guide to set up git on your 2i2c JupyterHub instance (referred to as 2i2c JupyterHub in these instruction). We will also configure git to use your github.com account for managing your repositories hosted on github.com. There are 5 main steps with substeps, includes instruction for addressing github’s new approach for token authentication.\n\n\nStep 1: Create a github account\nTo complete the setup, you will need an account on github.com. If you don’t have an account, please visit github.com, create an account (free) and come back to this guide for setting up git.\n\n\nStep 2: Fork a repository\nA fork is a copy of a repository from another github account (for example NASA-Openscapes account) to your github account (for example, my account virdi) that then you have permission to edit. To help you finish this setup correctly, we have created a demo repository on Openscapes github account named check_github_setup. You can fork this repository into your github account following these steps:\n\nLog in to your github.com account\nGo to the demo repository at NASA-Openscapes github\n\nClick on the fork icon in the top right corner, as shown in the image below and click your user name if prompted to do so\n\n\n\n\nStep 3: Clone the repository that you just forked\nNow you have a fork of the demo repository in your github account that we can clone it in your 2i2c instance. In the code below, commands beginning with git is a git command for version control and synching; commands that don’t start with git are bash/linux/command line commands.\n\nStart your 2i2c JupyterHub and open a terminal\nFile &gt;&gt; New &gt;&gt; Terminal\nMake sure you are in your home directory by usingpwd command and verifying the output as below\n/home/jovyan\n\nConfigure git with your name and email address.\ngit config --global user.name \"Makhan Virdi\"\ngit config --global user.email \"Makhan.Virdi@gmail.com\"\nNote: This name and email could be different from your github.com credentials. Remember git is a program that keeps track of your changes locally (on 2i2c JupyterHub or your own computer) and github.com is a platform to host your repositories. However, since your changes are tracked by git, the email/name used in git configuration will show up next to your contributions on github.com when you push your repository to github.com (git push is discussed in a later step).\nConfigure git to store your github credentials to avoid having to enter your github username and token each time you push changes to your repository(in Step 5, we will describe how to use github token instead of a password)\ngit config --global credential.helper store\nCopy link for the demo repository from your github account. Click the green “Code” button and copy the link as shown.\n\nClone the repository using git clone command in the terminal\nTo clone a repository from github, copy the link for the repository (previous step) and use git clone:\ngit clone https://github.com/YOUR-GITHUB-USERNAME/check_github_setup\nNote: Replace YOUR-GITHUB-USERNAME here with your github.com username. For example, it is virdi for my github.com account as seen in this image.\n\nUse ls (list files) to verify the existence of the repository that you just cloned\n\nChange directory to the cloned repository using cd check_github_setup and check the current directory using pwd command (present working directory)\n\nCheck status of your git repository to confirm git set up using git status\n\nYou are all set with using git on your 2i2c JupyterHub! But the collaborative power of git through github needs some additional setup.\nIn the next step, we will create a new file in this repository, track changes to this file, and link it with your github.com account.\n\n\n\nStep 4. Creating new file and tracking changes\n\nIn the left panel on your 2i2c JupyterHub, click on the “directory” icon and then double click on “check_github_setup” directory.\n\n\nOnce you are in the check_github_setup directory, create a new file using the text editor in your 2i2c JupyterHub (File &gt;&gt; New &gt;&gt; Text File).\n\nName the file lastname.txt. For example, virdi.txt for me (use your last name). Add some content to this file (for example, I added this to my virdi.txt file: my last name is virdi).\n\nNow you should have a new file (lastname.txt) in the git repository directory check_github_setup\nCheck if git can see that you have added a new file using git status. Git reports that you have a new file that is not tracked by git yet, and suggests adding that file to the git tracking system.\n\nAs seen in this image, git suggests adding that file so it can be tracked for changes. You can add file to git for tracking changes using git add. Then, you can commit changes to this file’s content using git commit as shown in the image.\ngit add virdi.txt\ngit status\ngit commit -m \"adding a new file\"\ngit status\n\nAs seen in the image above, git is suggesting to push the change that you just committed to the remote server at github.com (so that your collaborators can also see what changes you made).\nNote: DO NOT execute push yet. Before we push to github.com, let’s configure git further and store our github.com credentials to avoid entering the credentials every time we invoke git push. For doing so, we need to create a token on github.com to be used in place of your github.com password.\n\n\n\nStep 5. Create access token on github.com\n\nGo to your github account and create a new “personal access token”: https://github.com/settings/tokens/new\n\n\n\nGenerate Personal Access Token on github.com\n\n\nEnter a description in “Note” field as seen above, select “repo” checkbox, and scroll to the bottom and click the green button “Generate Token”. Once generated, copy the token (or save it in a text file for reference).\nIMPORTANT: You will see this token only once, so be sure to copy this. If you do not copy your token at this stage, you will need to generate a new token.\n\nTo push (transfer) your changes to github, use git push in terminal. It requires you to enter your github credentials. You will be prompted to enter your github username and “password”. When prompted for your “password”, DO NOT use your github password, use the github token that was copied in the previous step.\ngit push\n\nNote: When you paste your token in the terminal window, windows users will press Ctrl+V and mac os users will press Cmd+V. If it does not work, try generating another token and use the copy icon next to the token to copy the token. Then, paste using your computer’s keyboard shortcut for paste.\nNow your password is stored in ~/.git-credentials and you will not be prompted again unless the Github token expires. You can check the presence of this git-credentials file using Terminal. Here the ~ character represents your home directory (/home/jovyan/).\nls -la ~\nThe output looks like this:\ndrwxr-xr-x 13 jovyan jovyan 6144 Oct 22 17:35 .\ndrwxr-xr-x  1 root   root   4096 Oct  4 16:21 ..\n-rw-------  1 jovyan jovyan 1754 Oct 29 18:30 .bash_history\ndrwxr-xr-x  4 jovyan jovyan 6144 Oct 29 16:38 .config\n-rw-------  1 jovyan jovyan   66 Oct 22 17:35 .git-credentials\n-rw-r--r--  1 jovyan jovyan   84 Oct 22 17:14 .gitconfig\ndrwxr-xr-x 10 jovyan jovyan 6144 Oct 21 16:19 2021-Cloud-Hackathon\nYou can also verify your git configuration\n(notebook) jovyan@jupyter-virdi:~$ git config -l\nThe output should have credential.helper = store:\nuser.email        = Makhan.Virdi@gmail.com\nuser.name         = Makhan Virdi\ncredential.helper = store\n\nNow we are all set to collaborate with github on the JupyterHub during the Cloud Hackathon!\n\n\nSummary: Git Commands\n\nCommonly used git commands (modified from source)\n\n\nGit Command\nDescription\n\n\n\n\ngit status\nShows the current state of the repository: the current working branch, files in the staging area, etc.\n\n\ngit add\nAdds a new, previously untracked file to version control and marks already tracked files to be committed with the next commit\n\n\ngit commit\nSaves the current state of the repository and creates an entry in the log\n\n\ngit log\nShows the history for the repository\n\n\ngit diff\nShows content differences between commits, branches, individual files and more\n\n\ngit clone\nCopies a repository to your local environment, including all the history\n\n\ngit pull\nGets the latest changes of a previously cloned repository\n\n\ngit push\nPushes your local changes to the remote repository, sharing them with others\n\n\n\n\n\nGit: More Details\nLesson: For a more detailed self-paced lesson on git, visit Git Lesson from Software Carpentry\nCheatsheet: Frequently used git commands\nDangit, Git!?!: If you are stuck after a git mishap, there are ready-made solutions to common problems at Dangit, Git!?!\n\n\nCloning our repository using the git Jupyter lab extension.\nIf we’re already familiar with git commands and feel more confortable using a GUI our Jupyterhub deployment comes with a git extension. This plugin allows us to operate with git using a simple user interface.\nFor example we can clone our repository using the extension.\n\n\n\ngit extension"
  },
  {
    "objectID": "week2-tutorials/notebooks.html#introduction-programming-in-python",
    "href": "week2-tutorials/notebooks.html#introduction-programming-in-python",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Programming in Python",
    "text": "Introduction :: Programming in Python"
  },
  {
    "objectID": "week2-tutorials/notebooks.html#introduction-programming-in-python-1",
    "href": "week2-tutorials/notebooks.html#introduction-programming-in-python-1",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Programming in Python",
    "text": "Introduction :: Programming in Python\nSwitch to Jupyter Notebook for an introduction to programming in Python\n\nVariables (and mathematical operations)\nData Structures (list, tuple, dict)\nFlow Control using loops (for, while)\nConditionals (if, else, elif)\nFunctions\nErrors and Exceptions (understanding and handling errors)\nUsing modules (libraries, packages)\n\npandas: high-performance, easy-to-use data structures and data analysis tools\nrioxarray: based on the rasterio package for working with rasters and xarray\n\n\n\nPython Learning Resources\nSelf-paced lesson on Programming with Python from Software Carpentry"
  },
  {
    "objectID": "week2-tutorials/notebooks.html#introduction-geospatial-fundamentals-optional",
    "href": "week2-tutorials/notebooks.html#introduction-geospatial-fundamentals-optional",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Geospatial Fundamentals (Optional)",
    "text": "Introduction :: Geospatial Fundamentals (Optional)\nDetailed self-paced lesson on Fundamentals of Geospatial Raster and Vector Data with Python from Data Carpentry\nThe end!"
  },
  {
    "objectID": "week2-tutorials/r-and-python.html",
    "href": "week2-tutorials/r-and-python.html",
    "title": "R and Python",
    "section": "",
    "text": "It is important that you come into the course with a basic understanding of R. There are many free courses.\n\nIf you have never used R or RStudio and have not done much programming, start with this 4 hour course: Basics of R and installing RStudio https://www.udemy.com/course/r-basics/\nIf you know the basics of R but have never done modeling, then you can start with this 2.5 hour course that covers basic linear regression with R and plotting with ggplot2: https://www.udemy.com/course/machlearn1\nFor a longer free course, you can do this one. Note this is 20 hours. You do NOT need to do this whole course before the hackweek! https://www.codecademy.com/learn/learn-r\nOne of the best free R courses is https://www.coursera.org/learn/r-programming. You can see the lectures for free. Make sure to click AUDIT when it asks you to sign up for a 7-day trial. You do not need to sign up for anything to go through the material."
  },
  {
    "objectID": "week2-tutorials/r-and-python.html#introduction-programming-in-r",
    "href": "week2-tutorials/r-and-python.html#introduction-programming-in-r",
    "title": "R and Python",
    "section": "",
    "text": "It is important that you come into the course with a basic understanding of R. There are many free courses.\n\nIf you have never used R or RStudio and have not done much programming, start with this 4 hour course: Basics of R and installing RStudio https://www.udemy.com/course/r-basics/\nIf you know the basics of R but have never done modeling, then you can start with this 2.5 hour course that covers basic linear regression with R and plotting with ggplot2: https://www.udemy.com/course/machlearn1\nFor a longer free course, you can do this one. Note this is 20 hours. You do NOT need to do this whole course before the hackweek! https://www.codecademy.com/learn/learn-r\nOne of the best free R courses is https://www.coursera.org/learn/r-programming. You can see the lectures for free. Make sure to click AUDIT when it asks you to sign up for a 7-day trial. You do not need to sign up for anything to go through the material."
  },
  {
    "objectID": "week2-tutorials/r-and-python.html#introduction-programming-in-python",
    "href": "week2-tutorials/r-and-python.html#introduction-programming-in-python",
    "title": "R and Python",
    "section": "Introduction :: Programming in Python",
    "text": "Introduction :: Programming in Python\nSwitch to Jupyter Notebook for an introduction to programming in Python\n\nVariables (and mathematical operations)\nData Structures (list, tuple, dict)\nFlow Control using loops (for, while)\nConditionals (if, else, elif)\nFunctions\nErrors and Exceptions (understanding and handling errors)\nUsing modules (libraries, packages)\n\npandas: high-performance, easy-to-use data structures and data analysis tools\nrioxarray: based on the rasterio package for working with rasters and xarray\n\n\n\nPython Learning Resources\nSelf-paced lesson on Programming with Python from Software Carpentry"
  },
  {
    "objectID": "week2-tutorials/r-and-python.html#introduction-geospatial-fundamentals-optional",
    "href": "week2-tutorials/r-and-python.html#introduction-geospatial-fundamentals-optional",
    "title": "R and Python",
    "section": "Introduction :: Geospatial Fundamentals (Optional)",
    "text": "Introduction :: Geospatial Fundamentals (Optional)\nDetailed self-paced lesson on Fundamentals of Geospatial Raster and Vector Data with Python from Data Carpentry\nThe end!"
  }
]